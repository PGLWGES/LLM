{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMB/mln3AYmzoLkunietCdC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PGLWGES/LLM/blob/main/LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 1 requeiment"
      ],
      "metadata": {
        "id": "mLumiF7EfgcX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9R3uV_FMJg8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "199b04a1-9745-47ea-9d31-a7f0beb4b524"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting uv\n",
            "  Downloading uv-0.8.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading uv-0.8.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.8/18.8 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uv\n",
            "Successfully installed uv-0.8.4\n"
          ]
        }
      ],
      "source": [
        "!pip install uv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip install -r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/requirements.txt --system"
      ],
      "metadata": {
        "id": "Fem36eulMQbW",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef30da4c-edce-411d-af87-15282b6e688f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m149 packages\u001b[0m \u001b[2min 942ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2mfqdn                \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/8.91 KiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2mfqdn                \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 8.91 KiB/8.91 KiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2mpython-json-logger  \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/14.81 KiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2mpython-json-logger  \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/14.81 KiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2mpython-json-logger  \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/14.81 KiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2mpython-json-logger  \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/14.81 KiB\n",
            "\u001b[2moverrides           \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/17.41 KiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2mpython-json-logger   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/14.81 KiB\n",
            "\u001b[2moverrides           \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/17.41 KiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2muri-template            \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/10.88 KiB\n",
            "\u001b[2misoduration             \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/11.06 KiB\n",
            "\u001b[2mjupyter-server-terminals\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.34 KiB\n",
            "\u001b[2mtypes-python-dateutil   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/17.31 KiB\n",
            "\u001b[2moverrides               \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/17.41 KiB\n",
            "\u001b[2mjupyter-events          \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 14.94 KiB/18.97 KiB\n",
            "\u001b[2mjson5                   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/35.23 KiB\n",
            "\u001b[2mjupyterlab-server       \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/58.30 KiB\n",
            "\u001b[2mjupyter-lsp             \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/67.75 KiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2mrfc3987-syntax          \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/7.86 KiB\n",
            "\u001b[2misoduration             \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m    13 B/11.06 KiB\n",
            "\u001b[2mjupyter-server-terminals\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 13.34 KiB/13.34 KiB\n",
            "\u001b[2mtypes-python-dateutil   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 14.92 KiB/17.31 KiB\n",
            "\u001b[2moverrides               \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 14.91 KiB/17.41 KiB\n",
            "\u001b[2mjupyter-events          \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 14.94 KiB/18.97 KiB\n",
            "\u001b[2mjson5                   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/35.23 KiB\n",
            "\u001b[2mjupyterlab-server       \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 14.90 KiB/58.30 KiB\n",
            "\u001b[2marrow                   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/64.86 KiB\n",
            "\u001b[2mjupyter-lsp             \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/67.75 KiB\n",
            "\u001b[2mjupyter-client          \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/103.62 KiB\n",
            "\u001b[2mlark                    \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/108.43 KiB\n",
            "\u001b[2mjupyter-server          \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/377.84 KiB\n",
            "\u001b[2mnvidia-cuda-runtime-cu12\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/863.02 KiB\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/197.84 MiB\n",
            "\u001b[2K\u001b[23A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2mrfc3987-syntax          \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/7.86 KiB\n",
            "\u001b[2misoduration             \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m    13 B/11.06 KiB\n",
            "\u001b[2mtypes-python-dateutil   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 14.92 KiB/17.31 KiB\n",
            "\u001b[2moverrides               \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 14.91 KiB/17.41 KiB\n",
            "\u001b[2mjupyter-events          \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 14.94 KiB/18.97 KiB\n",
            "\u001b[2mjson5                   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/35.23 KiB\n",
            "\u001b[2mjupyterlab-server       \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 14.90 KiB/58.30 KiB\n",
            "\u001b[2marrow                   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/64.86 KiB\n",
            "\u001b[2mjupyter-lsp             \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/67.75 KiB\n",
            "\u001b[2mjupyter-client          \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/103.62 KiB\n",
            "\u001b[2mlark                    \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/108.43 KiB\n",
            "\u001b[2mjupyter-server          \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/377.84 KiB\n",
            "\u001b[2mnvidia-cuda-runtime-cu12\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/863.02 KiB\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/201.66 MiB\n",
            "\u001b[2K\u001b[23A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2misoduration             \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m    13 B/11.06 KiB\n",
            "\u001b[2mtypes-python-dateutil   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 14.92 KiB/17.31 KiB\n",
            "\u001b[2moverrides               \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 14.91 KiB/17.41 KiB\n",
            "\u001b[2mjupyter-events          \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 14.94 KiB/18.97 KiB\n",
            "\u001b[2mjson5                   \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 14.92 KiB/35.23 KiB\n",
            "\u001b[2mjupyterlab-server       \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 14.90 KiB/58.30 KiB\n",
            "\u001b[2marrow                   \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 14.96 KiB/64.86 KiB\n",
            "\u001b[2mjupyter-lsp             \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 14.91 KiB/67.75 KiB\n",
            "\u001b[2mjupyter-client          \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/103.62 KiB\n",
            "\u001b[2mlark                    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 14.95 KiB/108.43 KiB\n",
            "\u001b[2mjupyter-server          \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.94 KiB/377.84 KiB\n",
            "\u001b[2mnvidia-cuda-runtime-cu12\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/863.02 KiB\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.91 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.94 KiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.93 KiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.93 KiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.93 KiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.45 KiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.86 KiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/346.60 MiB\n",
            "\u001b[2K\u001b[23A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2misoduration             \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m    13 B/11.06 KiB\n",
            "\u001b[2mtypes-python-dateutil   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 14.92 KiB/17.31 KiB\n",
            "\u001b[2moverrides               \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 14.91 KiB/17.41 KiB\n",
            "\u001b[2mjupyter-events          \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 14.94 KiB/18.97 KiB\n",
            "\u001b[2mjson5                   \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 14.92 KiB/35.23 KiB\n",
            "\u001b[2mjupyterlab-server       \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 14.90 KiB/58.30 KiB\n",
            "\u001b[2marrow                   \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 14.96 KiB/64.86 KiB\n",
            "\u001b[2mjupyter-lsp             \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 14.91 KiB/67.75 KiB\n",
            "\u001b[2mjupyter-client          \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 14.91 KiB/103.62 KiB\n",
            "\u001b[2mlark                    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 14.95 KiB/108.43 KiB\n",
            "\u001b[2mjupyter-server          \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.94 KiB/377.84 KiB\n",
            "\u001b[2mnvidia-cuda-runtime-cu12\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/863.02 KiB\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.91 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.94 KiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.93 KiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.93 KiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.93 KiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.45 KiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.86 KiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.86 KiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.86 KiB/346.60 MiB\n",
            "\u001b[2K\u001b[23A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2mtypes-python-dateutil   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 14.92 KiB/17.31 KiB\n",
            "\u001b[2moverrides               \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 14.91 KiB/17.41 KiB\n",
            "\u001b[2mjupyter-events          \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 14.94 KiB/18.97 KiB\n",
            "\u001b[2mjson5                   \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 14.92 KiB/35.23 KiB\n",
            "\u001b[2mjupyterlab-server       \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 14.90 KiB/58.30 KiB\n",
            "\u001b[2marrow                   \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 14.96 KiB/64.86 KiB\n",
            "\u001b[2mjupyter-lsp             \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 14.91 KiB/67.75 KiB\n",
            "\u001b[2mjupyter-client          \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 14.91 KiB/103.62 KiB\n",
            "\u001b[2mlark                    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 14.95 KiB/108.43 KiB\n",
            "\u001b[2mjupyter-server          \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.94 KiB/377.84 KiB\n",
            "\u001b[2mnvidia-cuda-runtime-cu12\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/863.02 KiB\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.91 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.94 KiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.93 KiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.93 KiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.93 KiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.45 KiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.86 KiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.86 KiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.86 KiB/346.60 MiB\n",
            "\u001b[2K\u001b[22A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2mtypes-python-dateutil   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 14.92 KiB/17.31 KiB\n",
            "\u001b[2moverrides               \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 14.91 KiB/17.41 KiB\n",
            "\u001b[2mjson5                   \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 30.92 KiB/35.23 KiB\n",
            "\u001b[2mjupyterlab-server       \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 14.90 KiB/58.30 KiB\n",
            "\u001b[2marrow                   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 30.96 KiB/64.86 KiB\n",
            "\u001b[2mjupyter-lsp             \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 30.91 KiB/67.75 KiB\n",
            "\u001b[2mjupyter-client          \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 30.91 KiB/103.62 KiB\n",
            "\u001b[2mlark                    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 30.95 KiB/108.43 KiB\n",
            "\u001b[2mjupyter-server          \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 28.45 KiB/377.84 KiB\n",
            "\u001b[2mnvidia-cuda-runtime-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/863.02 KiB\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.91 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.94 KiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.93 KiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.31 KiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.93 KiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.45 KiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.86 KiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.86 KiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.86 KiB/346.60 MiB\n",
            "\u001b[2K\u001b[21A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2mtypes-python-dateutil   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 14.92 KiB/17.31 KiB\n",
            "\u001b[2mjson5                   \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 30.92 KiB/35.23 KiB\n",
            "\u001b[2mjupyterlab-server       \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 14.90 KiB/58.30 KiB\n",
            "\u001b[2marrow                   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 30.96 KiB/64.86 KiB\n",
            "\u001b[2mjupyter-lsp             \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 30.91 KiB/67.75 KiB\n",
            "\u001b[2mjupyter-client          \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 30.91 KiB/103.62 KiB\n",
            "\u001b[2mlark                    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 30.95 KiB/108.43 KiB\n",
            "\u001b[2mjupyter-server          \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 28.45 KiB/377.84 KiB\n",
            "\u001b[2mnvidia-cuda-runtime-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/863.02 KiB\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.91 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.94 KiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.93 KiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.31 KiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.93 KiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.45 KiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.86 KiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.86 KiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.86 KiB/346.60 MiB\n",
            "\u001b[2K\u001b[20A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2mjson5                   \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 30.92 KiB/35.23 KiB\n",
            "\u001b[2mjupyterlab-server       \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 14.90 KiB/58.30 KiB\n",
            "\u001b[2marrow                   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 30.96 KiB/64.86 KiB\n",
            "\u001b[2mjupyter-lsp             \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 30.91 KiB/67.75 KiB\n",
            "\u001b[2mjupyter-client          \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 30.91 KiB/103.62 KiB\n",
            "\u001b[2mlark                    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 30.95 KiB/108.43 KiB\n",
            "\u001b[2mjupyter-server          \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 28.45 KiB/377.84 KiB\n",
            "\u001b[2mnvidia-cuda-runtime-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/863.02 KiB\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.91 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.94 KiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.93 KiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.31 KiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.93 KiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.45 KiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.86 KiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.86 KiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.86 KiB/346.60 MiB\n",
            "\u001b[2K\u001b[19A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2mjson5                   \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 30.92 KiB/35.23 KiB\n",
            "\u001b[2marrow                   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 30.96 KiB/64.86 KiB\n",
            "\u001b[2mjupyter-lsp             \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 30.91 KiB/67.75 KiB\n",
            "\u001b[2mjupyter-client          \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 30.91 KiB/103.62 KiB\n",
            "\u001b[2mlark                    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 30.95 KiB/108.43 KiB\n",
            "\u001b[2mjupyter-server          \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 28.45 KiB/377.84 KiB\n",
            "\u001b[2mnvidia-cuda-runtime-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/863.02 KiB\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.91 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.94 KiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.93 KiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.31 KiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.93 KiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 14.93 KiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 46.86 KiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 30.86 KiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 46.86 KiB/346.60 MiB\n",
            "\u001b[2K\u001b[18A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2marrow                   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 62.96 KiB/64.86 KiB\n",
            "\u001b[2mjupyter-lsp             \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 46.91 KiB/67.75 KiB\n",
            "\u001b[2mjupyter-client          \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 46.91 KiB/103.62 KiB\n",
            "\u001b[2mlark                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 62.95 KiB/108.43 KiB\n",
            "\u001b[2mjupyter-server          \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 60.45 KiB/377.84 KiB\n",
            "\u001b[2mnvidia-cuda-runtime-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 48.00 KiB/863.02 KiB\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 62.91 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 58.51 KiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 62.93 KiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 46.31 KiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 50.54 KiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 46.93 KiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 46.86 KiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 62.86 KiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 48.00 KiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 46.86 KiB/346.60 MiB\n",
            "\u001b[2K\u001b[17A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2marrow                   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 62.96 KiB/64.86 KiB\n",
            "\u001b[2mjupyter-lsp             \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 51.40 KiB/67.75 KiB\n",
            "\u001b[2mjupyter-client          \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 62.91 KiB/103.62 KiB\n",
            "\u001b[2mlark                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 62.95 KiB/108.43 KiB\n",
            "\u001b[2mjupyter-server          \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 60.45 KiB/377.84 KiB\n",
            "\u001b[2mnvidia-cuda-runtime-cu12\u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 48.00 KiB/863.02 KiB\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 62.91 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 58.51 KiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 62.93 KiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 62.31 KiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 50.54 KiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 46.93 KiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 62.86 KiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 62.86 KiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 48.00 KiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 62.86 KiB/346.60 MiB\n",
            "\u001b[2K\u001b[17A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2marrow                   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 62.96 KiB/64.86 KiB\n",
            "\u001b[2mjupyter-lsp             \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 51.40 KiB/67.75 KiB\n",
            "\u001b[2mjupyter-client          \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 62.91 KiB/103.62 KiB\n",
            "\u001b[2mlark                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 62.95 KiB/108.43 KiB\n",
            "\u001b[2mjupyter-server          \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 60.45 KiB/377.84 KiB\n",
            "\u001b[2mnvidia-cuda-runtime-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 62.17 KiB/863.02 KiB\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 62.91 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 58.51 KiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 62.93 KiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 62.31 KiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 50.54 KiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 46.93 KiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 62.86 KiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 62.86 KiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 48.00 KiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 62.86 KiB/346.60 MiB\n",
            "\u001b[2K\u001b[17A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2mjupyter-lsp             \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 67.40 KiB/67.75 KiB\n",
            "\u001b[2mjupyter-client          \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 78.91 KiB/103.62 KiB\n",
            "\u001b[2mlark                    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 78.95 KiB/108.43 KiB\n",
            "\u001b[2mjupyter-server          \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 76.45 KiB/377.84 KiB\n",
            "\u001b[2mnvidia-cuda-runtime-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 62.17 KiB/863.02 KiB\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 77.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 63.47 KiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 62.93 KiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 65.12 KiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 50.54 KiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 62.93 KiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 62.86 KiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 62.86 KiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 60.76 KiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 75.08 KiB/346.60 MiB\n",
            "\u001b[2K\u001b[16A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2mjupyter-client          \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 78.91 KiB/103.62 KiB\n",
            "\u001b[2mlark                    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 78.95 KiB/108.43 KiB\n",
            "\u001b[2mjupyter-server          \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 76.45 KiB/377.84 KiB\n",
            "\u001b[2mnvidia-cuda-runtime-cu12\u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 62.17 KiB/863.02 KiB\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 77.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 63.47 KiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 76.03 KiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 65.12 KiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 66.54 KiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 62.93 KiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 94.86 KiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 77.86 KiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 60.76 KiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 75.08 KiB/346.60 MiB\n",
            "\u001b[2K\u001b[15A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2mjupyter-client          \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 83.54 KiB/103.62 KiB\n",
            "\u001b[2mjupyter-server          \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 92.78 KiB/377.84 KiB\n",
            "\u001b[2mnvidia-cuda-runtime-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 94.17 KiB/863.02 KiB\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 109.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 90.96 KiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 92.03 KiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 77.12 KiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 91.78 KiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 92.42 KiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 94.86 KiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 93.86 KiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 92.76 KiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 91.08 KiB/346.60 MiB\n",
            "\u001b[2K\u001b[14A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2mjupyter-server          \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 108.78 KiB/377.84 KiB\n",
            "\u001b[2mnvidia-cuda-runtime-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 126.06 KiB/863.02 KiB\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 125.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 106.96 KiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 110.43 KiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 93.12 KiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 107.78 KiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 108.42 KiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 110.75 KiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 125.86 KiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 124.76 KiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 107.08 KiB/346.60 MiB\n",
            "\u001b[2K\u001b[13A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/31)\n",
            "\u001b[2mjupyter-server          \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 124.78 KiB/377.84 KiB\n",
            "\u001b[2mnvidia-cuda-runtime-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 126.06 KiB/863.02 KiB\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 125.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 122.96 KiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 110.43 KiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 109.12 KiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 107.78 KiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 108.42 KiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 126.75 KiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 125.86 KiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 124.76 KiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 123.08 KiB/346.60 MiB\n",
            "\u001b[2K\u001b[13A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (18/31)\n",
            "\u001b[2mjupyter-server          \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 204.78 KiB/377.84 KiB\n",
            "\u001b[2mnvidia-cuda-runtime-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 222.17 KiB/863.02 KiB\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 237.75 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 202.96 KiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 204.03 KiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 205.12 KiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 203.78 KiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 204.42 KiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 206.86 KiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 237.86 KiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 220.76 KiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 203.08 KiB/346.60 MiB\n",
            "\u001b[2K\u001b[13A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (18/31)\n",
            "\u001b[2mjupyter-server          \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 316.78 KiB/377.84 KiB\n",
            "\u001b[2mnvidia-cuda-runtime-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 302.17 KiB/863.02 KiB\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 301.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 302.96 KiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 316.03 KiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 333.12 KiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 299.10 KiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 316.42 KiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 306.62 KiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 333.86 KiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 300.76 KiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 271.08 KiB/346.60 MiB\n",
            "\u001b[2K\u001b[13A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (18/31)\n",
            "\u001b[2mjupyter-server          \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 364.78 KiB/377.84 KiB\n",
            "\u001b[2mnvidia-cuda-runtime-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 398.17 KiB/863.02 KiB\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 333.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 446.96 KiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 459.82 KiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 461.12 KiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 415.78 KiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 432.32 KiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 424.56 KiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 461.86 KiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 412.76 KiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 431.08 KiB/346.60 MiB\n",
            "\u001b[2K\u001b[13A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (18/31)\n",
            "\u001b[2mnvidia-cuda-runtime-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 542.17 KiB/863.02 KiB\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 349.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 606.96 KiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 604.03 KiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 637.12 KiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 575.78 KiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 592.42 KiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 600.56 KiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 637.86 KiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 604.76 KiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 621.19 KiB/346.60 MiB\n",
            "\u001b[2K\u001b[12A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (18/31)\n",
            "\u001b[2mnvidia-cuda-runtime-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 542.17 KiB/863.02 KiB\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 349.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 606.96 KiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 652.03 KiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 669.12 KiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 607.78 KiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 640.42 KiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 648.56 KiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 669.86 KiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 604.76 KiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 621.19 KiB/346.60 MiB\n",
            "\u001b[2K\u001b[12A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (19/31)\n",
            "\u001b[2mnvidia-cuda-runtime-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 766.06 KiB/863.02 KiB\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 429.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 734.96 KiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 764.03 KiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 793.66 KiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 655.78 KiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 768.42 KiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 744.56 KiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 781.86 KiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 732.76 KiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 767.08 KiB/346.60 MiB\n",
            "\u001b[2K\u001b[12A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (19/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 429.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 782.96 KiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 812.03 KiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 951.31 KiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 767.78 KiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 800.42 KiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 808.56 KiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 829.86 KiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 796.76 KiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 815.08 KiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (19/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 445.86 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 894.96 KiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 940.03 KiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 951.31 KiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 879.78 KiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 944.42 KiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 952.56 KiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 957.86 KiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 908.76 KiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 943.08 KiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (19/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 445.86 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.01 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.06 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 1.09 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 1.06 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.09 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.12 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.12 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.09 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.12 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (19/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 461.86 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.14 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.20 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 1.09 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 1.20 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.09 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.12 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.18 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.09 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.12 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 477.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.14 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.20 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 1.25 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 1.20 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.23 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.22 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.26 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.22 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.36 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 477.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.17 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.20 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.37 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 1.20 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.39 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.38 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.34 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.37 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.41 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 477.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.17 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.53 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.55 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 1.40 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.54 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.38 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.58 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.37 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.58 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 493.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.41 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 1.62 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.62 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.59 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.64 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.66 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.67 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.65 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.69 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 493.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.65 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.81 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.86 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 1.81 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 1.94 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.87 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.95 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.97 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 1.92 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 509.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.68 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.15 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.19 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 2.17 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.20 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.18 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.19 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.20 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.24 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 509.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.73 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.46 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.45 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.45 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.47 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.48 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.50 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.56 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 509.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.78 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.78 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.72 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 2.75 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 2.92 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.75 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.80 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 2.87 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.05 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 509.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.79 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.11 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 2.99 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 3.17 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 3.10 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.00 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.10 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.06 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.18 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 509.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.82 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 3.30 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 3.32 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 3.36 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 3.29 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.18 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.28 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.27 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.41 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 509.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.84 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 3.74 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 3.59 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 3.61 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 3.73 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.62 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.70 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.69 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.83 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 525.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 1.92 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 4.03 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 3.85 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 3.88 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 4.19 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.92 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.14 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 3.97 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.11 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 541.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 1.96 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 4.30 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 4.09 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 4.12 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 4.29 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 4.17 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.23 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.33 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.50 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 541.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.07 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 4.64 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 4.33 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 4.48 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 4.52 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 4.56 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.44 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.42 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.63 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 541.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 2.30 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 4.89 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 4.72 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 4.87 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 4.86 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 4.79 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.82 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.75 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 4.96 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 557.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 2.56 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 5.23 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 5.05 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 5.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 5.19 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 5.17 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.14 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.11 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.29 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 557.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 3.33 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 5.50 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 5.31 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 5.25 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 5.38 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 5.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.29 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.29 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.59 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 557.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 3.41 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 5.72 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 5.53 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 5.62 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 5.86 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 5.68 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.60 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.82 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 5.82 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 557.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 3.52 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 6.15 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 5.95 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 5.83 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.10 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 6.12 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.06 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.08 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.00 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 557.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 3.82 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 6.36 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 6.12 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 6.05 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.32 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 6.31 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.25 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.28 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.33 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 557.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 3.89 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 6.82 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 6.56 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 6.49 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.78 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 6.75 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 6.71 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.50 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 6.75 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 557.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 4.11 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 7.04 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 6.78 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 6.73 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 6.98 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 6.97 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.09 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.12 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 7.01 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 573.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 4.19 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 7.49 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 7.21 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 7.12 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 7.42 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.33 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.34 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 7.41 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 573.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 4.32 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 7.73 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 7.42 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 7.30 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 7.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.67 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.42 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.56 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 7.64 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 573.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 4.42 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 7.73 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 7.62 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 7.53 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 7.83 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.87 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.60 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.56 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 7.67 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 589.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 4.43 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.98 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 7.62 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 7.56 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 7.83 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.87 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.76 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 7.75 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 7.87 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 589.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 4.82 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 8.29 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 7.87 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 7.77 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 8.20 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 8.12 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 8.07 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 8.07 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 8.20 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 589.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 5.10 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 8.48 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 8.25 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 8.19 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 8.51 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 8.53 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 8.42 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 8.45 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 8.36 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 589.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 5.21 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 8.86 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 8.53 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 8.45 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 8.75 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 8.78 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 8.66 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 8.67 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 8.87 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 605.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 5.30 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 9.19 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 8.83 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 8.71 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 9.01 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 9.04 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 8.89 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 9.01 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 9.14 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 605.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 5.49 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 9.35 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 9.01 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 8.92 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 9.20 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 9.33 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 9.33 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 9.37 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 9.29 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 605.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 5.62 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 9.75 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 9.43 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 9.33 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 9.61 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 9.39 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 9.37 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 9.42 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 9.52 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 605.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 6.21 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 9.92 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 9.45 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 9.35 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 9.65 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 9.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 9.56 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 9.65 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 9.95 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 621.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.27 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 10.23 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 9.76 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 9.64 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 9.98 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 9.98 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 9.89 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 9.89 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 10.04 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 637.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.27 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 10.57 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 10.31 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 10.19 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 10.32 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 10.37 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 10.39 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 10.40 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 10.42 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 653.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.32 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 10.87 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 10.59 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 10.51 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 10.63 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 10.69 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 10.70 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 10.72 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 10.86 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 715.96 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.39 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 11.14 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 10.87 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 10.78 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 10.89 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 10.95 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.07 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 10.97 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 11.13 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 715.96 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.39 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 11.65 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 11.32 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 11.26 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 11.24 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 11.37 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.46 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.40 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 715.96 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.41 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 11.97 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 11.68 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 11.63 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 11.82 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 11.70 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.94 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.94 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 11.97 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 715.96 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.41 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 12.46 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 12.10 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 12.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 12.06 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 12.15 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 12.19 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 12.17 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 12.41 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 731.96 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.41 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 12.86 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 12.56 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 12.51 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 12.55 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 12.62 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 12.49 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 12.68 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 12.74 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 731.96 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.41 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-cupti-cu12  \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 13.16 MiB/13.17 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 13.05 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 12.99 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 13.04 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 13.11 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 13.05 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 13.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 13.22 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[11A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 731.96 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.41 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 13.58 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 13.32 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 13.43 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 13.50 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 13.62 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 13.56 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 13.75 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 731.96 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.41 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 13.58 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 13.43 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 13.43 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 13.50 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 13.62 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 13.56 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 13.75 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (20/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 731.96 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.43 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 13.98 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 13.81 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 13.87 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 14.08 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.06 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.01 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.22 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 749.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.43 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 14.45 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 14.29 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 14.39 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 14.44 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.63 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.62 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.78 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 749.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.43 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 15.00 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 14.84 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 15.03 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 14.98 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 15.05 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 15.06 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 15.22 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 749.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.43 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 15.38 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 15.34 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 15.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 15.53 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 15.62 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 15.59 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 15.78 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 765.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.46 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 15.98 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 15.94 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 16.02 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 16.09 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.18 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.23 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.32 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 765.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 6.54 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 16.74 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 16.70 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 16.83 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 16.81 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.09 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 829.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.29 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.42 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.62 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.01 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.03 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.04 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.06 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.07 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.09 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.10 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.12 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.13 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.15 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.16 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.18 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.20 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.21 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 17.23 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 17.24 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 17.26 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 17.27 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 17.29 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 17.31 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 17.32 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 17.34 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 17.35 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.54 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 16.76 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 893.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.24 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 17.34 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 17.37 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.50 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 17.04 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 17.51 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 17.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 909.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.36 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 17.85 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 17.91 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 17.89 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 17.96 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 18.05 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 17.96 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 18.13 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 909.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 7.39 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 18.27 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 18.26 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 18.45 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 18.43 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 18.65 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 18.62 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 18.74 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 909.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 7.44 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 19.06 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 18.84 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 18.95 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 19.03 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 19.24 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 19.06 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 19.28 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 925.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 7.80 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 19.32 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 19.34 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 19.39 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 19.54 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 19.56 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 19.62 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 19.64 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 925.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 7.88 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 19.97 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 19.95 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 20.03 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 20.11 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 20.20 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 20.21 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 20.26 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 925.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 7.89 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-nvjitlink-cu12   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 20.09 MiB/20.09 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 20.62 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 20.69 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 20.75 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 20.84 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 20.83 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 20.83 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[10A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 925.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 7.89 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 20.77 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 20.88 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 20.96 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 21.06 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 21.01 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 21.13 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[9A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 941.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 7.91 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 21.12 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 21.19 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 21.32 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 21.42 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 21.36 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 21.57 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[9A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 941.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 7.92 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 21.59 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 21.69 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 21.87 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 21.96 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 22.11 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 22.22 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[9A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (21/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 941.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 8.00 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 22.29 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 22.40 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 22.55 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 22.67 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 22.45 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 22.66 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[9A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (22/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 941.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 8.13 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 22.56 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 22.94 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 22.86 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 22.91 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 22.78 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 23.11 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[9A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (22/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 941.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 8.16 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 23.40 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 23.39 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 23.50 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 23.62 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 23.51 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 23.62 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[9A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (22/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 957.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 8.16 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-cuda-nvrtc-cu12  \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 23.49 MiB/23.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 23.58 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 24.08 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 24.14 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 24.11 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 24.14 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[9A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (22/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 957.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 8.16 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 23.95 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 24.08 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 24.14 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 24.11 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 24.14 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (22/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 989.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 8.91 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 24.10 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 24.18 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 24.29 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 24.25 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 24.14 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (23/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1005.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 9.39 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 24.40 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 24.21 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 24.29 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 24.25 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 24.14 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (23/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1005.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 9.39 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 24.40 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 24.54 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 24.69 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 24.56 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 24.52 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (23/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1021.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 9.42 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 25.04 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 25.23 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 25.26 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 25.16 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 25.17 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (23/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1021.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 9.49 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 25.82 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 25.90 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 26.03 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 25.93 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 25.64 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (23/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1021.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 9.58 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 26.50 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 26.79 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 26.84 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 26.53 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 26.14 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (23/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1021.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 9.61 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 26.90 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 27.34 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 27.30 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 27.23 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 26.81 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (23/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1021.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 9.71 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 27.36 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 27.65 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 27.73 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 27.94 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 27.53 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (23/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1021.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 9.71 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 28.05 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 28.23 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 28.45 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 28.36 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 28.05 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (23/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1021.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 9.77 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 28.84 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 28.74 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 28.81 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 28.84 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 28.84 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (23/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1021.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 10.00 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 29.23 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 29.61 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 29.56 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 29.53 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 29.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (23/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 1021.97 KiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 10.14 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 30.09 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 30.29 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 30.00 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 30.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 30.06 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (23/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 1.01 MiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 10.38 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 30.42 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 31.04 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 30.59 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 30.72 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 30.33 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (23/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 1.03 MiB/1.50 MiB\n",
            "\u001b[2mjupyterlab              \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 11.55 MiB/11.70 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 30.59 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 31.32 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 31.03 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 31.17 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 30.50 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[8A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (23/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 1.03 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 30.59 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 31.32 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 31.03 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 31.17 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 30.50 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (23/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 1.03 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 31.29 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 31.64 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 31.51 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 31.50 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 31.21 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (23/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 1.03 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 32.23 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 32.15 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 32.36 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 32.18 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 31.59 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (23/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 1.03 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 32.90 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 32.88 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 33.01 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 32.92 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 32.38 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 1.03 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 33.61 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 33.50 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 33.82 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 33.40 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 33.21 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 1.03 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 34.32 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 33.94 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 34.16 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 34.08 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 33.63 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 1.03 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 35.06 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 34.69 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 34.91 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 34.87 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 34.27 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 1.06 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 35.70 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 35.19 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 35.69 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 35.67 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 35.03 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 1.06 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 36.23 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 35.93 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 36.38 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 36.28 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 35.70 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 1.09 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 36.69 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 36.42 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 36.64 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 36.75 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 36.40 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 1.09 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 37.17 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 36.97 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 37.25 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 37.59 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 37.26 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 1.09 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 37.89 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 37.90 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 38.02 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 38.04 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 38.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 1.09 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 38.75 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 38.82 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 39.30 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 38.86 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 39.07 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 1.09 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 39.49 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 39.32 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 39.86 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 39.65 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 39.63 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 1.10 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 39.82 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 39.95 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 40.45 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 39.70 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 39.90 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 1.10 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 40.20 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 40.25 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 40.45 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 40.04 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 40.44 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 1.10 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 41.14 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 40.97 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 41.52 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 41.09 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 41.06 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 1.10 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 42.14 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 41.86 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 42.48 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 41.97 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 41.75 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 1.11 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 42.66 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 42.56 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 42.93 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 42.85 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 42.90 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 1.11 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 43.81 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 43.28 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 44.14 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 43.49 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 43.31 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 1.13 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 44.20 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 44.00 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 44.75 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 44.11 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 44.00 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 1.18 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 44.96 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 44.23 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 45.30 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 44.97 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 44.53 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 1.18 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 45.79 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 45.00 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 46.18 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 45.69 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 45.35 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 1.18 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 46.61 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 46.20 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 47.08 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 46.24 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 46.33 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 1.18 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 47.30 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 46.96 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 47.67 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 47.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 47.38 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 1.18 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 47.73 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 47.75 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 48.45 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 47.67 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 47.98 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 1.18 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 48.28 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 48.33 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 49.25 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 48.28 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 48.60 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 1.18 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 48.83 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 49.00 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 49.72 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 48.79 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 49.28 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 1.18 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 49.55 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 49.55 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 50.55 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 49.55 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 50.24 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 1.18 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 50.51 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 50.07 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 51.39 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 50.23 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 50.78 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 1.20 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 50.76 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 50.73 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 51.67 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 50.50 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 51.37 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 1.20 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 51.48 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 51.44 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 52.53 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 51.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 51.92 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 1.20 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 52.70 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 51.84 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 52.94 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 51.90 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 52.58 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 1.20 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-curand-cu12      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 53.09 MiB/53.70 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 52.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 53.59 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 52.59 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 53.37 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[7A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 1.20 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 53.01 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 54.23 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 53.11 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 53.95 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 1.20 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 53.34 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 54.23 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 53.12 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 53.95 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (24/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 1.21 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 54.07 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 55.00 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 53.95 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 54.33 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 1.21 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 55.12 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.03 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 54.84 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 54.98 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 1.21 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.29 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.93 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 55.36 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 55.98 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 1.23 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 1.23 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 1.23 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 1.23 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 1.23 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 1.23 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 1.23 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 1.23 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 1.23 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 1.23 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 1.23 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 1.24 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 1.24 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 1.26 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 1.28 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 1.29 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 1.30 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 1.31 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 1.32 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 1.34 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 1.35 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 1.37 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 1.38 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 1.40 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 1.41 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mjedi                    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 1.50 MiB/1.50 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[6A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.41 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.53 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.55 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.56 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.58 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.59 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.61 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.62 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (25/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 58.28 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 58.58 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.62 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 58.58 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.62 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 58.58 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.62 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.76 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 59.05 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.62 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.76 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.77 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 59.05 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.62 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.76 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 56.79 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 59.05 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.62 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.76 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 57.90 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 59.05 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.62 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.76 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 58.24 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 59.05 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.62 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.76 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 58.24 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 59.05 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.62 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.76 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 58.24 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 59.05 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.62 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.76 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 58.24 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 59.05 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.62 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.76 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 58.24 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 59.05 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 56.62 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.76 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 58.32 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 59.36 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.85 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 56.76 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 59.06 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 59.70 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 57.85 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 58.53 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 59.42 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 60.37 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 58.79 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 59.28 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 60.42 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 60.76 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 59.34 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 60.18 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 60.80 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 61.53 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 60.17 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 60.50 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 61.11 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 62.00 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 60.54 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 60.57 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 61.35 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 62.27 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 60.75 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 61.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 62.08 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 63.14 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 61.45 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 61.91 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 62.44 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 63.94 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 62.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 62.50 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 63.12 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 64.22 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 62.69 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 63.70 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 64.00 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 64.93 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 63.23 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 64.19 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 64.34 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 65.28 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 63.53 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 64.20 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 64.77 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 65.71 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 63.98 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 64.91 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 65.38 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 66.29 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 64.56 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 65.53 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 65.95 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 67.06 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 65.30 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 65.98 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 66.43 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 67.47 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 65.70 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 66.86 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 66.85 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 67.47 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 65.90 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 67.35 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 67.00 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 68.00 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 66.71 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 67.60 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 67.74 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 68.68 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 67.40 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 68.31 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 68.86 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 69.71 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 68.18 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 68.83 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 69.50 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 70.57 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 68.52 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 69.95 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 69.81 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 70.96 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 69.17 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 70.90 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 70.00 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 71.56 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 69.37 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 71.00 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 70.94 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 71.92 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 69.97 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 71.62 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 71.57 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 72.37 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 70.56 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 72.47 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 72.12 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 72.66 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 70.92 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 72.86 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 72.73 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 73.11 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 71.36 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 73.51 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 73.50 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 74.44 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 71.59 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 73.81 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 74.38 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 74.81 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 72.31 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 74.14 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 74.61 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 75.38 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 72.59 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 75.19 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 75.17 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 75.75 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 73.12 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 75.95 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 75.50 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 76.36 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 73.48 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 76.77 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 76.34 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 77.16 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 74.77 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 77.22 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 77.34 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 77.53 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 75.31 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 78.42 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 78.16 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 78.52 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 75.87 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 79.25 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 78.87 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 79.14 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 76.48 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 79.93 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 79.63 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 79.72 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 77.31 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 80.81 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 80.19 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 80.56 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 78.11 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 81.65 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 81.25 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 81.92 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 78.81 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 82.25 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 82.06 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 82.86 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 79.61 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 83.16 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 83.00 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 83.39 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 80.85 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 84.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 83.75 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 83.98 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 81.33 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 84.86 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 84.31 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 84.99 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 82.28 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 85.53 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 85.00 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 85.78 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 83.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 86.19 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 85.43 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 86.81 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 83.36 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 86.62 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 86.00 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 87.06 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 83.93 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 87.56 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 86.79 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 87.70 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 84.79 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 88.00 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 87.69 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 88.86 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 85.71 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 88.83 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 88.57 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 89.70 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 86.58 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 89.73 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 89.19 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 90.69 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 87.57 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 90.37 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 89.74 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 91.12 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 88.05 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 90.69 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 90.63 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 91.78 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 88.92 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 91.42 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 91.34 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 93.00 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 89.60 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 92.26 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 92.06 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 93.53 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 90.33 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 92.95 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 92.48 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 94.50 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 90.97 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 93.57 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 93.63 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 95.32 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 91.87 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 94.08 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 93.98 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 96.00 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 92.29 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 94.62 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 94.75 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 96.36 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 93.12 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 95.81 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 95.72 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 96.92 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 93.73 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 96.44 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 96.39 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 97.72 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 94.37 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 97.05 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 96.98 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 98.71 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 94.79 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 97.92 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 97.97 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 99.37 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 95.77 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 98.99 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 98.41 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 100.86 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 96.16 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 99.87 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 99.36 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 101.27 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 97.25 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 100.76 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 99.99 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 102.44 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 97.72 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 101.36 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 101.00 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 103.49 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 98.34 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 102.06 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 102.12 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 104.31 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 99.31 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 102.97 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 103.19 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 105.00 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 100.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 104.24 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 104.31 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 106.11 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 101.06 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 104.96 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 105.46 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 107.00 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 102.01 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 106.08 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 106.05 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 107.34 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 102.45 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 106.34 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 106.65 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 107.73 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 102.78 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 106.73 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 107.45 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 108.63 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 103.06 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 107.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 108.59 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 109.34 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 104.12 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 108.95 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 109.90 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 110.45 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 105.12 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 110.14 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 110.33 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 111.37 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 105.45 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 111.69 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 110.94 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 111.97 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 106.05 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 112.41 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 112.14 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 113.39 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 106.66 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 113.18 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 112.70 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 114.36 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 107.64 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 113.81 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 113.62 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 114.91 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 108.37 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 114.70 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 114.27 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 116.53 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 108.94 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 115.97 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 114.93 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 117.31 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 109.48 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 117.18 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 116.52 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 118.31 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 110.12 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 117.42 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 117.94 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 118.91 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 110.81 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 117.94 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 118.94 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 120.28 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 111.47 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 119.00 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 120.03 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 120.99 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 112.53 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 120.23 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 120.77 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 121.75 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 112.89 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 120.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 121.99 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 122.31 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 113.29 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 121.23 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusolver-cu12    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 122.01 MiB/122.01 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 123.96 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 114.97 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 122.13 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 124.12 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 114.97 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 122.37 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 125.05 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 115.80 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 123.36 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 126.06 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 116.59 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 123.92 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (26/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 126.51 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 117.51 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 124.84 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 127.53 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 118.19 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 126.39 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 128.79 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 119.20 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 127.56 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 130.06 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 120.18 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 128.66 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 131.05 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 121.14 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 129.90 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 131.98 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 122.05 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 130.83 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 133.28 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 123.20 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 131.90 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 133.82 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 123.87 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 132.75 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 135.90 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 124.28 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 133.55 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 136.80 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 125.43 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 134.37 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 137.64 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 126.30 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 135.20 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 138.69 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 127.43 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 136.36 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 139.75 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 127.97 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 138.02 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 140.44 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 129.84 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 138.93 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 141.23 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 130.37 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 140.09 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 142.25 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 131.57 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 140.96 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 143.05 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 132.70 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 142.17 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 144.46 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 133.33 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 143.00 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 145.97 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 134.28 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 144.67 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 146.95 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 135.18 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 145.61 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 147.92 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 135.95 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 146.45 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 149.42 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 136.81 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 148.12 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 150.03 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 138.73 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 149.73 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 151.53 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 139.92 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 150.64 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 151.87 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 140.58 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 151.76 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 153.11 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 141.56 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 152.67 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 154.40 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 142.82 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 153.85 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 155.32 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 143.89 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 154.93 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 156.05 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 144.55 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 155.59 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 156.70 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 146.19 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 156.64 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 157.84 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 147.72 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 158.42 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 159.81 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 148.61 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 159.19 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 161.22 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 149.95 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 160.12 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 162.23 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 151.36 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 161.11 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 163.52 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 152.88 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 162.62 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 164.70 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 154.31 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 164.00 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 165.25 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 155.26 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 165.50 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 165.89 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 155.51 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 167.28 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 166.81 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 156.47 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 167.82 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 167.25 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 156.81 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 169.00 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 168.44 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 157.87 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 170.22 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 169.34 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 158.91 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 171.23 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 169.83 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 158.91 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 171.33 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 170.66 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 161.11 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 172.86 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 171.31 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 162.39 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 174.43 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 172.69 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 163.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 175.71 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 173.12 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 164.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 176.53 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 174.44 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 164.90 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 177.25 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 175.29 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 165.54 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 177.75 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 176.23 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 166.28 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 179.12 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 177.25 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 167.20 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 180.26 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 178.02 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 168.97 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 181.92 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 179.69 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 170.32 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 182.00 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 180.35 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 172.01 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 183.68 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 181.33 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 173.05 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 185.31 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 182.62 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 174.39 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 186.58 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 183.26 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 174.92 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 187.51 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 184.90 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 175.90 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 188.79 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 185.23 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 177.15 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 189.83 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 186.06 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 178.05 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 191.08 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 187.09 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 179.50 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 192.47 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 188.43 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 180.00 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 193.15 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 189.42 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 180.56 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 193.75 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 190.34 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 180.97 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 194.12 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 191.12 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 182.19 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 195.46 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 193.00 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 182.98 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 196.50 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 193.56 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 183.97 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 197.62 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 194.70 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 184.66 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 198.36 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 195.89 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 185.65 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 199.92 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cusparse-cu12    \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 197.51 MiB/197.84 MiB\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 186.53 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 200.91 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[4A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 186.94 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 201.37 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 187.29 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 201.37 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 188.53 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 202.92 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (27/31)\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 190.62 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 204.49 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 192.56 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 205.79 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 193.11 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 207.30 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 195.09 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 209.14 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 195.70 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 210.92 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 197.83 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 212.96 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 199.95 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 214.97 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 201.02 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 216.66 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 201.60 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 218.53 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 201.60 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 220.34 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 201.60 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 223.29 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cufft-cu12       \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 201.60 MiB/201.66 MiB\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 226.34 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[3A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 227.31 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.26 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 228.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 231.00 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 233.11 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 234.75 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 237.13 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 239.61 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (28/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 241.62 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 243.54 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 245.33 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 247.37 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 249.42 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 251.14 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 252.25 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 254.48 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 256.94 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 258.59 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 260.61 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 262.03 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 263.02 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 264.95 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 266.76 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 266.90 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 267.92 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 268.45 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 270.42 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 271.64 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 272.20 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 273.82 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 275.75 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 277.43 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 278.44 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 279.22 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 280.17 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 281.12 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 283.03 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 283.83 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 284.95 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 286.20 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 287.11 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 288.41 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 290.47 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 291.89 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 292.23 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 293.26 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 294.90 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 295.78 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 295.79 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 297.53 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 299.17 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 301.06 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 302.37 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 302.37 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 303.59 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 304.64 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 305.74 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 307.61 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 310.00 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 313.84 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 315.31 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 316.95 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 318.97 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 320.97 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 323.84 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 324.97 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 326.66 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 328.68 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 330.48 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 330.83 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 332.00 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 335.72 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 337.97 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 338.33 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 339.86 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 341.87 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 344.07 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2mnvidia-cublas-cu12      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 346.57 MiB/346.60 MiB\n",
            "\u001b[2K\u001b[2A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (29/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[1A\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (30/31)\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m31 packages\u001b[0m \u001b[2min 33.83s\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m12 packages\u001b[0m \u001b[2min 705ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m31 packages\u001b[0m \u001b[2min 121ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1marrow\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1masync-lru\u001b[0m\u001b[2m==2.0.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfqdn\u001b[0m\u001b[2m==1.5.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1misoduration\u001b[0m\u001b[2m==20.11.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjson5\u001b[0m\u001b[2m==0.12.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mjupyter-client\u001b[0m\u001b[2m==6.1.12\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjupyter-client\u001b[0m\u001b[2m==8.6.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjupyter-events\u001b[0m\u001b[2m==0.12.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjupyter-lsp\u001b[0m\u001b[2m==2.2.6\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mjupyter-server\u001b[0m\u001b[2m==1.16.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjupyter-server\u001b[0m\u001b[2m==2.16.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjupyter-server-terminals\u001b[0m\u001b[2m==0.5.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjupyterlab\u001b[0m\u001b[2m==4.4.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjupyterlab-server\u001b[0m\u001b[2m==2.27.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlark\u001b[0m\u001b[2m==1.2.2\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.5.3.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.4.5.8\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.3.0.75\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.1.0.70\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.3.61\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.1.3\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.6.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.5.147\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.3.83\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.1.9\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.3.1.170\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1moverrides\u001b[0m\u001b[2m==7.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-json-logger\u001b[0m\u001b[2m==3.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrfc3339-validator\u001b[0m\u001b[2m==0.1.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrfc3986-validator\u001b[0m\u001b[2m==0.1.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrfc3987-syntax\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtypes-python-dateutil\u001b[0m\u001b[2m==2.9.0.20250708\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1muri-template\u001b[0m\u001b[2m==1.3.0\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Working with text data"
      ],
      "metadata": {
        "id": "zagxD3bn2Oce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Understanding word embeddings"
      ],
      "metadata": {
        "id": "48nKdPlGfyPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Tokenizing text"
      ],
      "metadata": {
        "id": "HJhjN3-ef37O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
        "     \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
        "     \"the-verdict.txt\")\n",
        "file_path = \"the-verdict.txt\"\n",
        "urllib.request.urlretrieve(url, file_path)"
      ],
      "metadata": {
        "id": "pxk5lipH2zEo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9629f975-e7d8-43b1-dea2-be2fad39b039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('the-verdict.txt', <http.client.HTTPMessage at 0x79fe671760d0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "  raw_text = f.read()\n",
        "print(\"Total number of character:\", len(raw_text))\n",
        "print(raw_text[:99])"
      ],
      "metadata": {
        "id": "7M3RYKY93BUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb31f265-7ae9-4587-ffb9-f50b86fe92d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of character: 20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text = \"Hello, world. This, is a test.\"\n",
        "result = re.split(r'(\\s)', text)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "qSV70NE13TKh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c5f5d28-8240-473c-f96b-4e87062afa90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = re.split(r'([,.]|\\s)', text)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "y6WBOylP3cXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3de5313e-3869-43f1-884f-ef5e3a62bd52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ',', '', ' ', 'is', ' ', 'a', ' ', 'test', '.', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 移除空字符串\n",
        "result = [item for item in result if item.strip()]\n",
        "print(result)"
      ],
      "metadata": {
        "id": "4s_cUcrA3436",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89827997-9648-4861-de09-5d98a3d9b540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, world. Is this-- a test?\"\n",
        "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
        "result = [item.strip() for item in result if item.strip()]\n",
        "print(result)"
      ],
      "metadata": {
        "id": "fu7X1dJf4i4g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09b5e52a-d2e6-48c9-9631-d631379e9440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
        "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "print(len(preprocessed))"
      ],
      "metadata": {
        "id": "zz70QNZ94pWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e948fc8-cba2-4b08-fca6-e8e2aefaa682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(preprocessed[:30])"
      ],
      "metadata": {
        "id": "Fx9bfaFK4xTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c726ca1c-a4e1-4151-a6c0-83185894767c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Converting tokens into token IDs"
      ],
      "metadata": {
        "id": "Dk9SY6wDf9Ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = sorted(set(preprocessed))\n",
        "vocab_size = len(all_words)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "id": "-0qT-1orWgCY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5048e96d-0117-4af1-a5b5-49a4a2289090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {token:integer for integer,token in enumerate(all_words)}\n",
        "for i, item in enumerate(vocab.items()):\n",
        "  print(item)\n",
        "  if i >= 50:\n",
        "    break"
      ],
      "metadata": {
        "id": "6L-Jx5Oc4zTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c36a7cc-09dc-4ee0-8561-e8135882f0cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('!', 0)\n",
            "('\"', 1)\n",
            "(\"'\", 2)\n",
            "('(', 3)\n",
            "(')', 4)\n",
            "(',', 5)\n",
            "('--', 6)\n",
            "('.', 7)\n",
            "(':', 8)\n",
            "(';', 9)\n",
            "('?', 10)\n",
            "('A', 11)\n",
            "('Ah', 12)\n",
            "('Among', 13)\n",
            "('And', 14)\n",
            "('Are', 15)\n",
            "('Arrt', 16)\n",
            "('As', 17)\n",
            "('At', 18)\n",
            "('Be', 19)\n",
            "('Begin', 20)\n",
            "('Burlington', 21)\n",
            "('But', 22)\n",
            "('By', 23)\n",
            "('Carlo', 24)\n",
            "('Chicago', 25)\n",
            "('Claude', 26)\n",
            "('Come', 27)\n",
            "('Croft', 28)\n",
            "('Destroyed', 29)\n",
            "('Devonshire', 30)\n",
            "('Don', 31)\n",
            "('Dubarry', 32)\n",
            "('Emperors', 33)\n",
            "('Florence', 34)\n",
            "('For', 35)\n",
            "('Gallery', 36)\n",
            "('Gideon', 37)\n",
            "('Gisburn', 38)\n",
            "('Gisburns', 39)\n",
            "('Grafton', 40)\n",
            "('Greek', 41)\n",
            "('Grindle', 42)\n",
            "('Grindles', 43)\n",
            "('HAD', 44)\n",
            "('Had', 45)\n",
            "('Hang', 46)\n",
            "('Has', 47)\n",
            "('He', 48)\n",
            "('Her', 49)\n",
            "('Hermia', 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义一个简单的文本分词器类，用于编码（文本转ID）和解码（ID转文本）\n",
        "class SimpleTokenizerV1:\n",
        "    # 初始化方法，接收词汇表（vocab）作为参数\n",
        "    def __init__(self, vocab):\n",
        "        # 存储 字符串（token）到整数（ID）的映射\n",
        "        self.str_to_int = vocab\n",
        "        # 构建 整数（ID）到字符串（token）的反向映射，用于解码\n",
        "        self.int_to_str = {i: s for s, i in vocab.items()}\n",
        "\n",
        "    # 编码方法：将输入文本转换为 token ID 列表\n",
        "    def encode(self, text):\n",
        "        # 步骤1：用正则表达式分割文本，拆分出 token（包含标点、单词等）\n",
        "        # 正则匹配逻辑：逗号/句号/问号/感叹号/引号/中括号 或 空白字符\n",
        "        preprocessed = re.split(r'([,.?!\\'\"\\[\\]]|--|\\s)', text)\n",
        "        # 步骤2：过滤空内容（strip后为空的项），并去除每个 token 首尾空白\n",
        "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "        # 步骤3：通过词汇表映射，将每个字符串 token 转为对应的整数 ID\n",
        "        ids = [self.str_to_int[s] for s in preprocessed]\n",
        "        return ids  # 返回编码后的 ID 列表\n",
        "\n",
        "    # 解码方法：将 token ID 列表转换为原始文本\n",
        "    def decode(self, ids):\n",
        "        # 步骤1：通过反向映射，将 ID 转回字符串 token，并用空字符串拼接\n",
        "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "        # 步骤2：用正则表达式清理标点前的多余空格\n",
        "        # 匹配逻辑：标点（,.?!'\"\\[]）前的一个或多个空格，替换为单个空格（保证标点前无冗余空格）\n",
        "        text = re.sub(r'\\s+([,.?!\\'\"\\[\\]])', r'\\1', text)\n",
        "        return text  # 返回解码后的文本"
      ],
      "metadata": {
        "id": "uHsVcibBWWJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV1(vocab)\n",
        "text = \"\"\"\"It's the last he painted, you know,\"\n",
        "        Mrs. Gisburn said with pardonable pride.\"\"\"\n",
        "ids = tokenizer.encode(text)\n",
        "print(ids)"
      ],
      "metadata": {
        "id": "oWlilDPpYS7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fc546d5-62c0-476e-dba8-6f204996794d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(ids))"
      ],
      "metadata": {
        "id": "MVo8pGpDYYlx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6dc241d-33d3-4043-b2c8-e5b01e09d8be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\" It' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text = \"Hello, do you like tea?\"\n",
        "# print(tokenizer.encode(text))"
      ],
      "metadata": {
        "id": "40xWKn2ObAQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Adding special context tokens"
      ],
      "metadata": {
        "id": "2clX8sdZgDel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = sorted(list(set(preprocessed)))\n",
        "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
        "vocab = {token:integer for integer,token in enumerate(all_tokens)}\n",
        "print(len(vocab.items()))"
      ],
      "metadata": {
        "id": "1ewOYWPPbHlq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e53196c9-aa4f-4f56-9343-bb4bc515559d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, item in enumerate(list(vocab.items())[-5:]):\n",
        "  print(item)"
      ],
      "metadata": {
        "id": "tQa_CCiLbQsI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dd72c37-0103-4e91-bef5-aa15ae1077f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('younger', 1127)\n",
            "('your', 1128)\n",
            "('yourself', 1129)\n",
            "('<|endoftext|>', 1130)\n",
            "('<|unk|>', 1131)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义一个增强版的简单文本分词器类（相比V1版本增加了OOV处理）\n",
        "class SimpleTokenizerV2:\n",
        "    def __init__(self, vocab):\n",
        "        # 存储 字符串→ID 的映射（来自传入的词汇表）\n",
        "        self.str_to_int = vocab\n",
        "        # 构建 反向映射（ID→字符串），用于解码\n",
        "        self.int_to_str = {i: s for s, i in vocab.items()}\n",
        "\n",
        "    def encode(self, text):\n",
        "        # 步骤1：使用正则表达式将文本拆分为tokens（包括标点和空格）\n",
        "        preprocessed = re.split(r'([,.?!\\'\"\\[\\]]|--|\\s)', text)\n",
        "\n",
        "        # 步骤2：过滤空字符串，并去除每个token的首尾空格\n",
        "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "\n",
        "        # 步骤3：处理未登录词（OOV）：将词汇表中不存在的token替换为<|unk|>\n",
        "        # 关键增强点：相比V1版本，增加了对未知词的处理，避免KeyError\n",
        "        preprocessed = [\n",
        "            item if item in self.str_to_int  # 如果token在词汇表中，保留原样\n",
        "            else \"<|unk|>\"                   # 否则替换为特殊的未知词标记\n",
        "            for item in preprocessed\n",
        "        ]\n",
        "\n",
        "        # 步骤4：将tokens转换为对应的ID\n",
        "        ids = [self.str_to_int[s] for s in preprocessed]\n",
        "        return ids\n",
        "\n",
        "    def decode(self, ids):\n",
        "        # 步骤1：将ID列表转换回字符串tokens，并使用空格拼接（可能产生多余空格）\n",
        "        # 注意：此处使用空格拼接是为了后续正则处理的便利性\n",
        "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "\n",
        "        # 步骤2：修复标点符号前的多余空格（与V1版本相同）\n",
        "        # 例如：将 \"Hello , world\" 转换为 \"Hello, world\"\n",
        "        text = re.sub(r'\\s+([,.?!\\'\"\\[\\]])', r'\\1', text)\n",
        "        return text"
      ],
      "metadata": {
        "id": "zdog5zHzbWcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"Hello, do you like tea?\"\n",
        "text2 = \"In the sunlit terraces of the palace.\"\n",
        "text = \" <|endoftext|> \".join((text1, text2))\n",
        "print(text)"
      ],
      "metadata": {
        "id": "N2QvNdIkbaRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83a34cfc-561d-4338-8e78-27ff1275e3de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV2(vocab)\n",
        "print(tokenizer.encode(text))"
      ],
      "metadata": {
        "id": "q44t-4EAbbzI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c8721aa-12e8-42b7-a3b7-74dc219d802b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(tokenizer.encode(text)))"
      ],
      "metadata": {
        "id": "PYTvRnJJbdvK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f44ac8bf-cb0a-479f-9bec-408c983dd62e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 Btye pair encoding"
      ],
      "metadata": {
        "id": "OotNO8zBgI3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken"
      ],
      "metadata": {
        "id": "LYFE8kFHbgDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e436e1a8-ea46-45ad-f38a-7f229d5257aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.metadata import version\n",
        "import tiktoken\n",
        "print(\"tiktoken version:\", version(\"tiktoken\"))"
      ],
      "metadata": {
        "id": "hl-AAJv3blL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a788874b-f722-4590-d7ce-45ee87886a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiktoken version: 0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "PlW0jqekbpWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = (\n",
        "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
        "    \"of someunknownPlace.\"\n",
        ")\n",
        "integers = tokenizer.encode(text, allowed_special = {\"<|endoftext|>\"})\n",
        "print(integers)"
      ],
      "metadata": {
        "id": "j4CXF5SUbrOX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8081feb7-02b0-41d2-bc59-3ce20763d584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strings = tokenizer.decode(integers)\n",
        "print(strings)"
      ],
      "metadata": {
        "id": "ZDvU-8ABbt9j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "578f6436-db48-4149-838f-6850423491ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ip = \"Akwirw ier\"\n",
        "temp = tokenizer.encode(ip)\n",
        "print(temp)\n",
        "op = tokenizer.decode(temp)\n",
        "print(op)"
      ],
      "metadata": {
        "id": "NR45cjvXbw3o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69192205-5fec-4e8a-fe5c-dc45b0929b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[33901, 86, 343, 86, 220, 959]\n",
            "Akwirw ier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.6 Data sampling with a silding window"
      ],
      "metadata": {
        "id": "HomBlCMcgNRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "enc_text = tokenizer.encode(raw_text)\n",
        "print(len(enc_text))"
      ],
      "metadata": {
        "id": "wsEfr3ivbzQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41ab4f20-c2ff-4217-a62a-238365860fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_sample = enc_text[50:]"
      ],
      "metadata": {
        "id": "98sHRQAhb4q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义上下文窗口大小，即每次取多少个连续的 token 作为输入上下文\n",
        "context_size = 4\n",
        "# 从编码后的样本中，取从开头到 context_size 位置的子序列作为输入特征 x\n",
        "# 比如 context_size=4 时，取 [0,1,2,3] 位置的 token\n",
        "x = enc_sample[:context_size]\n",
        "# 从编码后的样本中，取从第 1 个位置到 context_size+1 位置的子序列作为目标值 y\n",
        "# 相当于在 x 的基础上向后滑动一位，用于训练时让模型学习“根据 x 预测下一个 token（即 y 对应的序列）”\n",
        "y = enc_sample[1:context_size+1]\n",
        "# 打印输入特征 x 的内容，方便调试或查看数据\n",
        "print(f\"x: {x}\")\n",
        "# 打印目标值 y 的内容，观察模型需要预测的结果形式\n",
        "print(f\"y:    {y}\")"
      ],
      "metadata": {
        "id": "qjiVzcogb6NA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea9f450b-50e1-446e-df3f-02cab9fc0db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: [290, 4920, 2241, 287]\n",
            "y:    [4920, 2241, 287, 257]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 遍历从 1 到 context_size（包含 context_size）的整数，实现滑动窗口的效果\n",
        "for i in range(1, context_size + 1):\n",
        "    # 截取从序列起始到索引 i 的子序列，作为模型的输入上下文\n",
        "    # 随着 i 增大，上下文长度从 1 逐渐增加到 context_size\n",
        "    context = enc_sample[:i]\n",
        "    # 选取索引 i 位置的元素，作为模型需要预测的目标\n",
        "    desired = enc_sample[i]\n",
        "    # 打印当前的输入上下文和对应的预测目标，方便观察滑动窗口过程\n",
        "    print(context, \"----->\", desired)"
      ],
      "metadata": {
        "id": "w5io2t2pcANs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b4d3c60-77e7-4718-cea5-82b3e940a0a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[290] -----> 4920\n",
            "[290, 4920] -----> 2241\n",
            "[290, 4920, 2241] -----> 287\n",
            "[290, 4920, 2241, 287] -----> 257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, context_size+1):\n",
        "  context = enc_sample[:i]\n",
        "  desired = enc_sample[i]\n",
        "  print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
      ],
      "metadata": {
        "id": "kmcto7GmcCDI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77acb933-c963-4309-a3d6-d064c9202229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " and ---->  established\n",
            " and established ---->  himself\n",
            " and established himself ---->  in\n",
            " and established himself in ---->  a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "id": "8-WwMymBcESx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8a0744d-6afc-4393-8b9d-eada72b99983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# 定义一个名为 GPTDatasetV1 的数据集类，继承自 PyTorch 的 Dataset 类\n",
        "class GPTDatasetV1(Dataset):\n",
        "    # 初始化方法，用于创建数据集对象时设置参数和初始化数据\n",
        "    # txt: 原始文本数据\n",
        "    # tokenizer: 分词器，用于将文本转换为 token IDs\n",
        "    # max_length: 每个输入块（input chunk）的最大长度\n",
        "    # stride: 滑动窗口的步长，控制每次窗口移动的距离\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        # 初始化存储输入 token IDs 的列表\n",
        "        self.input_ids = []\n",
        "        # 初始化存储目标 token IDs 的列表\n",
        "        self.target_ids = []\n",
        "\n",
        "        # 使用分词器对整个文本进行编码，得到 token IDs 序列\n",
        "        # tokenizer.encode 方法会同时完成分词和转换为 token IDs 的操作\n",
        "        token_ids = tokenizer.encode(txt)  # Tokenizes the entire text（对整个文本进行分词）\n",
        "\n",
        "        # 滑动窗口遍历 token_ids 序列，生成输入块和目标块\n",
        "        # 遍历的起始位置从 0 开始，结束位置为 len(token_ids) - max_length（保证窗口不越界），步长为 stride\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            # 截取从 i 开始，长度为 max_length 的子序列作为输入块\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            # 截取从 i + 1 开始，长度为 max_length 的子序列作为目标块（输入块右移一位，用于预测下一个词）\n",
        "            target_chunk = token_ids[i + 1:i + max_length + 1]\n",
        "\n",
        "            # 将输入块转换为 PyTorch 张量，并添加到 input_ids 列表中\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            # 将目标块转换为 PyTorch 张量，并添加到 target_ids 列表中\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    # 用于返回数据集的样本数量，PyTorch 的 Dataset 类需要实现的方法\n",
        "    def __len__(self):\n",
        "        # 返回输入数据的数量，即 input_ids 列表的长度\n",
        "        return len(self.input_ids)  # Returns the total number of rows in the dataset（返回数据集中行的总数）\n",
        "\n",
        "    # 用于根据索引 idx 获取数据集中的一个样本（输入和对应的目标），PyTorch 的 Dataset 类需要实现的方法\n",
        "    def __getitem__(self, idx):\n",
        "        # 返回指定索引 idx 对应的输入张量和目标张量\n",
        "        return self.input_ids[idx], self.target_ids[idx]  # Returns a single row from the dataset（从数据集中返回一行数据）"
      ],
      "metadata": {
        "id": "rtl6LZwHcI5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "    # 初始化分词器，使用 tiktoken 库的 get_encoding 方法获取 \"gpt2\" 对应的编码方式\n",
        "    # 分词器用于将文本转换为模型可处理的 token 形式\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")  # Initializes the tokenizer（初始化分词器）\n",
        "\n",
        "    # 创建数据集实例，传入原始文本、分词器、最大长度、滑动步长等参数\n",
        "    # 该数据集类（GPTDatasetV1）需提前定义好，用于处理文本数据并生成输入 - 目标对\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)  # Creates dataset（创建数据集）\n",
        "\n",
        "    # 使用 PyTorch 的 DataLoader 包装数据集，方便模型训练时按批次加载数据\n",
        "    dataloader = DataLoader(\n",
        "        dataset,  # 传入数据集对象\n",
        "        batch_size=batch_size,  # 每个批次的样本数量\n",
        "        shuffle=shuffle,  # 是否打乱数据顺序，True 表示训练时打乱增加随机性\n",
        "        drop_last=drop_last,  # drop_last=True drops the last batch if it is shorter than the specified batch size to prevent loss spikes during training.\n",
        "        # 若最后一个批次样本数量不足 batch_size，是否丢弃该批次，避免训练时因批次不规整导致损失异常波动\n",
        "        num_workers=num_workers  # The number of CPU processes to use for preprocessing\n",
        "        # 用于数据预处理的 CPU 进程数，0 表示在主进程中进行预处理\n",
        "    )\n",
        "\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "dJiATZLocNeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",
        ")\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "id": "4RoXQ0lGcSGB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e790f0b-9908-4e2d-f203-2cabd1de35a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "second_batch = next(data_iter)\n",
        "print(second_batch)"
      ],
      "metadata": {
        "id": "9HAYEuHKcWMV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbec1637-dbc5-4abb-a588-433f839313f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=8, max_length=4, stride=4, shuffle=False\n",
        ")\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "print(\"Inputs:\\n\", inputs)\n",
        "print(\"\\nTargets:\\n\", targets)"
      ],
      "metadata": {
        "id": "EjAJ5v9ScgZs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97a368ee-970b-4018-ecc5-d5381b7f3168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "\n",
            "Targets:\n",
            " tensor([[  367,  2885,  1464,  1807],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [ 2138,   257,  7026, 15632],\n",
            "        [  438,  2016,   257,   922],\n",
            "        [ 5891,  1576,   438,   568],\n",
            "        [  340,   373,   645,  1049],\n",
            "        [ 5975,   284,   502,   284],\n",
            "        [ 3285,   326,    11,   287]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.7 Creating token embeddings"
      ],
      "metadata": {
        "id": "1N9MY5X0gVWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 词汇表的索引\n",
        "input_ids = torch.tensor([2, 3, 5, 1])"
      ],
      "metadata": {
        "id": "UxKST0_ActGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 6\n",
        "output_dim = 3"
      ],
      "metadata": {
        "id": "rtUaNlw6dA4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
        "print(embedding_layer.weight)"
      ],
      "metadata": {
        "id": "1aljD7ojczAa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fe7c0d2-32a6-472d-a0bb-c3aaa6c81ea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3374, -0.1778, -0.1690],\n",
            "        [ 0.9178,  1.5810,  1.3010],\n",
            "        [ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-1.1589,  0.3255, -0.6315],\n",
            "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer(torch.tensor([3])))"
      ],
      "metadata": {
        "id": "wFhyZylFc7Nd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "720c4cfb-37e1-4776-dead-f7db1df9519e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " print(embedding_layer(input_ids))"
      ],
      "metadata": {
        "id": "eu0E7zWcdGXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a65d9fbc-ba82-4ef9-f5f2-355bb46a2592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-2.8400, -0.7849, -1.4096],\n",
            "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.8 Encoding word positions"
      ],
      "metadata": {
        "id": "2A0CXlDcgrXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50257\n",
        "output_dim = 256\n",
        "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
        "max_length = 4\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=8, max_length=max_length,stride=max_length, shuffle=False\n",
        ")\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "print(\"Token IDs:\\n\", inputs)\n",
        "# 8是 batch_size（每个批次的样本数 ）\n",
        "# 4是 max_length（每个样本包含的 token 数量 ）\n",
        "print(\"\\nInputs shape:\\n\", inputs.shape)"
      ],
      "metadata": {
        "id": "dnJ2D3GEdMCo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "668c106d-6ec0-44e4-83ad-4201196c56e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "\n",
            "Inputs shape:\n",
            " torch.Size([8, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings = token_embedding_layer(inputs)\n",
        "print(token_embeddings.shape)"
      ],
      "metadata": {
        "id": "CK-KU_SDeewa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac20983-895f-4a4f-a104-6ad522634ca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = max_length\n",
        "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
        "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
        "print(pos_embeddings.shape)"
      ],
      "metadata": {
        "id": "RoaIXTjYejlV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "792f8570-59ef-45ce-b51a-6085290974cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeddings = token_embeddings + pos_embeddings\n",
        "print(input_embeddings.shape)"
      ],
      "metadata": {
        "id": "TtaSsKaGenb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23f8a3d4-1e25-49af-aee0-513aed94f4cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Coding attention mechanisms"
      ],
      "metadata": {
        "id": "UzIQFEwvfNUB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 The problem with modeling long sequences"
      ],
      "metadata": {
        "id": "3-le9mQRg5zZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Capturing data dependencies with attention mechanisms"
      ],
      "metadata": {
        "id": "aaEiQctGIVeU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  3.3 Attending to different parts of the input with self-attention"
      ],
      "metadata": {
        "id": "9gAc2g5GIe8n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  3.3.1 A simple self-attention mechanism without trainable weights"
      ],
      "metadata": {
        "id": "6832aipFIkSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "inputs = torch.tensor(\n",
        "    [\n",
        "        [0.43, 0.15, 0.89],  # Your (x^1)\n",
        "        [0.55, 0.87, 0.66],  # journey (x^2)\n",
        "        [0.57, 0.85, 0.64],  # starts (x^3)\n",
        "        [0.22, 0.58, 0.33],  # with (x^4)\n",
        "        [0.77, 0.25, 0.10],  # one (x^5)\n",
        "        [0.05, 0.80, 0.55]   # step (x^6)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "BuoLin0OfTFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 获取第二个输入token作为查询向量（索引从0开始，所以inputs[1]是第二个元素）\n",
        "query = inputs[1]\n",
        "\n",
        "# 创建一个空张量，用于存储注意力分数，形状为(inputs.shape[0],)\n",
        "# inputs.shape[0]表示输入张量的第一个维度大小（即token的数量）\n",
        "attn_scores_2 = torch.empty(inputs.shape[0])\n",
        "\n",
        "# 遍历输入张量中的每个token\n",
        "# i是当前token的索引，x_i是当前token的嵌入向量\n",
        "for i, x_i in enumerate(inputs):\n",
        "    # 计算当前token与查询向量的点积，作为注意力分数\n",
        "    # torch.dot()用于计算两个向量的点积\n",
        "    attn_scores_2[i] = torch.dot(x_i, query)\n",
        "\n",
        "# 打印注意力分数\n",
        "print(attn_scores_2)"
      ],
      "metadata": {
        "id": "YwqyOICWfXq_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4efdbc45-a40c-47f5-eeb7-e9784b368e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算注意力权重：将注意力分数除以所有分数的总和，实现归一化\n",
        "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
        "\n",
        "# 打印注意力权重\n",
        "print(\"Attention weights:\", attn_weights_2_tmp)\n",
        "\n",
        "# 打印注意力权重的总和，验证是否归一化（理论上应为1）\n",
        "print(\"Sum:\", attn_weights_2_tmp.sum())"
      ],
      "metadata": {
        "id": "iQ_UGYyBJCDr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01962eab-b18a-43e2-efae-eaa57f2c9a1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
            "Sum: tensor(1.0000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_naive(x):\n",
        "    \"\"\"\n",
        "    手动实现softmax函数\n",
        "    Args:\n",
        "        x: 输入张量\n",
        "    Returns:\n",
        "        经过softmax处理后的张量\n",
        "    \"\"\"\n",
        "    # 计算输入张量的指数值\n",
        "    exp_x = torch.exp(x)\n",
        "    # 计算指数值的和（按第0维求和）\n",
        "    sum_exp_x = exp_x.sum(dim=0)\n",
        "    # 返回softmax结果：每个元素的指数值除以总和\n",
        "    return exp_x / sum_exp_x\n",
        "\n",
        "# 使用手动实现的softmax函数计算注意力权重\n",
        "attn_weights_2_naive = softmax_naive(attn_scores_2)\n",
        "\n",
        "# 打印注意力权重\n",
        "print(\"Attention weights:\", attn_weights_2_naive)\n",
        "\n",
        "# 打印注意力权重的总和，验证是否归一化（理论上应为1）\n",
        "print(\"Sum:\", attn_weights_2_naive.sum())"
      ],
      "metadata": {
        "id": "RJSaL0v8JQvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0b7809c-1921-42c3-b51f-00811a2b3405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
            "Sum: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用PyTorch内置的softmax函数计算注意力权重\n",
        "# dim=0表示在第0维上进行softmax操作\n",
        "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
        "\n",
        "# 打印注意力权重\n",
        "print(\"Attention weights:\", attn_weights_2)\n",
        "\n",
        "# 打印注意力权重的总和，验证是否归一化（理论上应为1）\n",
        "print(\"Sum:\", attn_weights_2.sum())"
      ],
      "metadata": {
        "id": "z4LQHSjQJczQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7188acf-14fd-475b-c06c-d03f7fae4c4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
            "Sum: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 获取第二个输入token作为查询向量（索引从0开始，所以inputs[1]是第二个元素）\n",
        "query = inputs[1]\n",
        "\n",
        "# 创建一个与查询向量形状相同的零张量，用于存储上下文向量\n",
        "context_vec_2 = torch.zeros(query.shape)\n",
        "\n",
        "# 遍历输入张量中的每个token\n",
        "# i是当前token的索引，x_i是当前token的嵌入向量\n",
        "for i, x_i in enumerate(inputs):\n",
        "    # 将当前token的嵌入向量乘以对应的注意力权重，并累加到上下文向量中\n",
        "    context_vec_2 += attn_weights_2[i] * x_i\n",
        "\n",
        "# 打印计算得到的上下文向量\n",
        "print(context_vec_2)"
      ],
      "metadata": {
        "id": "lVu77QelJm2R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "537fc510-14e8-4c23-ab7e-af99ad89ac67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4419, 0.6515, 0.5683])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  3.3.2 Computing attention weights for all input tokens"
      ],
      "metadata": {
        "id": "FF8Tt-nVKl-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建一个形状为(6, 6)的空张量，用于存储注意力分数\n",
        "attn_scores = torch.empty(6, 6)\n",
        "\n",
        "# 遍历输入张量中的每个token（作为键，i是索引，x_i是嵌入向量）\n",
        "for i, x_i in enumerate(inputs):\n",
        "    # 遍历输入张量中的每个token（作为查询，j是索引，x_j是嵌入向量）\n",
        "    for j, x_j in enumerate(inputs):\n",
        "        # 计算当前键（x_i）和查询（x_j）的点积，作为注意力分数\n",
        "        attn_scores[i, j] = torch.dot(x_i, x_j)\n",
        "\n",
        "# 打印注意力分数矩阵\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "id": "vh4d-_lmKVlp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12f7bb61-da95-4ff3-dd66-3c0e3f54a98f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
            "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用矩阵乘法计算自注意力分数矩阵\n",
        "# inputs.T 表示inputs的转置\n",
        "attn_scores = inputs @ inputs.T\n",
        "\n",
        "# 打印注意力分数矩阵\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "id": "TM0KnPMlKyrB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e4c7a30-7700-4870-93bb-c4be2ae53c62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
            "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 对注意力分数矩阵进行softmax归一化\n",
        "# dim=-1表示在最后一个维度上进行softmax操作\n",
        "attn_weights = torch.softmax(attn_scores, dim=-1)\n",
        "\n",
        "# 打印归一化后的注意力权重矩阵\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "id": "LPwvd5_pK_KP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74f43d51-0b61-4f53-aa7e-75e9d977e5a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
            "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
            "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
            "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
            "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
            "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 手动计算第二行的和（假设这是softmax后的注意力权重）\n",
        "row_2_sum = sum([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
        "\n",
        "# 打印手动计算的第二行和\n",
        "print(\"Row 2 sum:\", row_2_sum)\n",
        "\n",
        "# 使用PyTorch的sum函数计算每行的和\n",
        "# dim=-1表示在最后一个维度（行）上求和\n",
        "print(\"All row sums:\", attn_weights.sum(dim=-1))"
      ],
      "metadata": {
        "id": "l5F_3V6NLH-Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "577b6171-dba0-4b5a-da16-1bafbe8a4fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row 2 sum: 1.0\n",
            "All row sums: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用矩阵乘法计算所有上下文向量\n",
        "# attn_weights是注意力权重矩阵\n",
        "# inputs是原始输入嵌入向量\n",
        "all_context_vecs = attn_weights @ inputs\n",
        "\n",
        "# 打印计算得到的所有上下文向量\n",
        "print(all_context_vecs)"
      ],
      "metadata": {
        "id": "WDbL69t3LoSy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b640b3e1-a7ab-41c2-d07d-663e82ccc76a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4421, 0.5931, 0.5790],\n",
            "        [0.4419, 0.6515, 0.5683],\n",
            "        [0.4431, 0.6496, 0.5671],\n",
            "        [0.4304, 0.6298, 0.5510],\n",
            "        [0.4671, 0.5910, 0.5266],\n",
            "        [0.4177, 0.6503, 0.5645]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Previous 2nd context vector:\", context_vec_2)"
      ],
      "metadata": {
        "id": "VWIeKmrsLwf-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae33a81c-1089-4ece-9736-b43e039c3c78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous 2nd context vector: tensor([0.4419, 0.6515, 0.5683])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  3.4 Implementing self-attention with trainable weights"
      ],
      "metadata": {
        "id": "jm0MkQo7L04o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  3.4.1 Computing the attention weights step by step"
      ],
      "metadata": {
        "id": "QvM1ctFkMkSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 获取输入张量的第二个元素（索引从0开始，所以inputs[1]是第二个元素）\n",
        "x_2 = inputs[1]\n",
        "\n",
        "# 获取输入嵌入的维度（假设inputs是一个二维张量，inputs.shape[1]表示列数）\n",
        "d_in = inputs.shape[1]\n",
        "\n",
        "# 定义输出嵌入的维度\n",
        "d_out = 2"
      ],
      "metadata": {
        "id": "vA0AMlZhLzJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置随机种子，确保结果可复现\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 初始化查询(Query)线性变换矩阵\n",
        "# d_in是输入维度，d_out是输出维度\n",
        "# requires_grad=False表示该矩阵不需要梯度更新\n",
        "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "\n",
        "# 初始化键(Key)线性变换矩阵\n",
        "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "\n",
        "# 初始化值(Value)线性变换矩阵\n",
        "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
      ],
      "metadata": {
        "id": "sg0Kk0GiMunu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算查询向量的线性变换结果\n",
        "# x_2是输入向量，W_query是查询线性变换矩阵\n",
        "query_2 = x_2 @ W_query\n",
        "\n",
        "# 计算键向量的线性变换结果\n",
        "# x_2是输入向量，W_key是键线性变换矩阵\n",
        "key_2 = x_2 @ W_key\n",
        "\n",
        "# 计算值向量的线性变换结果\n",
        "# x_2是输入向量，W_value是值线性变换矩阵\n",
        "value_2 = x_2 @ W_value\n",
        "\n",
        "# 打印查询向量的线性变换结果\n",
        "print(query_2)"
      ],
      "metadata": {
        "id": "4nDfLMaXM0_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a37fddb4-6a3a-4e9b-97ee-ee336942e74b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4306, 1.4551])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算所有输入向量的键表示\n",
        "# inputs是输入张量，W_key是键线性变换矩阵\n",
        "keys = inputs @ W_key\n",
        "\n",
        "# 计算所有输入向量的值表示\n",
        "# inputs是输入张量，W_value是值线性变换矩阵\n",
        "values = inputs @ W_value\n",
        "\n",
        "# 打印键表示的形状\n",
        "print(\"Keys.shape:\", keys.shape)\n",
        "\n",
        "# 打印值表示的形状\n",
        "print(\"Values.shape:\", values.shape)"
      ],
      "metadata": {
        "id": "ZfuwQsyNM6tl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c702b17-7dc3-40b5-febb-965231b177a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys.shape: torch.Size([6, 2])\n",
            "Values.shape: torch.Size([6, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 获取键张量中的第二个元素（索引从0开始，所以keys[1]是第二个元素）\n",
        "keys_2 = keys[1]\n",
        "\n",
        "# 计算查询向量和键向量的点积，作为注意力分数\n",
        "attn_score_22 = query_2.dot(keys_2)\n",
        "\n",
        "# 打印计算得到的注意力分数\n",
        "print(attn_score_22)"
      ],
      "metadata": {
        "id": "qwP-3jShNHhm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a6e82eb-59db-4f08-dd2f-f60b6d2b9024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.8524)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算单个查询向量与所有键向量的注意力分数\n",
        "# query_2是查询向量，keys.T是键张量的转置\n",
        "attn_scores_2 = query_2 @ keys.T\n",
        "\n",
        "# 打印计算得到的注意力分数\n",
        "print(attn_scores_2)"
      ],
      "metadata": {
        "id": "_ggzDYF7PqMA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2712dc22-3755-49f6-b051-1a8fa68ab6b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 获取键向量的最后一个维度大小（即键的维度）\n",
        "d_k = keys.shape[-1]\n",
        "\n",
        "# 计算缩放的注意力权重\n",
        "# attn_scores_2是原始注意力分数\n",
        "# d_k**0.5是缩放因子，用于防止梯度消失\n",
        "attn_weights_2 = torch.softmax(attn_scores_2 / (d_k**0.5), dim=-1)\n",
        "\n",
        "# 打印计算得到的注意力权重\n",
        "print(attn_weights_2)"
      ],
      "metadata": {
        "id": "Qg2xnAHBPzMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bbccc78-ea46-4731-833d-033cf8d91972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算上下文向量\n",
        "# attn_weights_2是注意力权重\n",
        "# values是值张量\n",
        "context_vec_2 = attn_weights_2 @ values\n",
        "\n",
        "# 打印计算得到的上下文向量\n",
        "print(context_vec_2)"
      ],
      "metadata": {
        "id": "vyHKQGpfQO2k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7621d95f-ecd9-4ac0-e591-dbaa6350d3b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3061, 0.8210])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4.2 Implementing a compact self-attention Python class"
      ],
      "metadata": {
        "id": "IDOfijhLTbp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SelfAttention_v1(nn.Module):\n",
        "    def __init__(self, d_in, d_out):\n",
        "        super().__init__()\n",
        "        # 初始化查询(Query)线性变换矩阵\n",
        "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
        "        # 初始化键(Key)线性变换矩阵\n",
        "        self.W_key = nn.Parameter(torch.rand(d_in, d_out))\n",
        "        # 初始化值(Value)线性变换矩阵\n",
        "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 计算所有输入向量的键表示\n",
        "        keys = x @ self.W_key\n",
        "        # 计算所有输入向量的查询表示\n",
        "        queries = x @ self.W_query\n",
        "        # 计算所有输入向量的值表示\n",
        "        values = x @ self.W_value\n",
        "\n",
        "        # 计算注意力分数\n",
        "        attn_scores = queries @ keys.T\n",
        "\n",
        "        # 计算缩放的注意力权重\n",
        "        attn_weights = torch.softmax(\n",
        "            attn_scores / (keys.shape[-1]**0.5),\n",
        "            dim=-1\n",
        "        )\n",
        "\n",
        "        # 计算上下文向量\n",
        "        context_vec = attn_weights @ values\n",
        "\n",
        "        # 返回上下文向量\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "SmL4WV-JTasz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置随机种子，确保结果可复现\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 实例化自注意力模块\n",
        "# d_in是输入维度，d_out是输出维度\n",
        "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
        "\n",
        "print(sa_v1(inputs))"
      ],
      "metadata": {
        "id": "JZJDceXgTnq6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "513334f7-31ef-4e35-b803-7c9e46b318cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2996, 0.8053],\n",
            "        [0.3061, 0.8210],\n",
            "        [0.3058, 0.8203],\n",
            "        [0.2948, 0.7939],\n",
            "        [0.2927, 0.7891],\n",
            "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention_v2(nn.Module):\n",
        "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        # 定义查询(Query)线性层\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        # 定义键(Key)线性层\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        # 定义值(Value)线性层\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 计算所有输入向量的键表示\n",
        "        keys = self.W_key(x)\n",
        "        # 计算所有输入向量的查询表示\n",
        "        queries = self.W_query(x)\n",
        "        # 计算所有输入向量的值表示\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # 计算注意力分数\n",
        "        attn_scores = queries @ keys.T\n",
        "\n",
        "        # 计算缩放的注意力权重\n",
        "        attn_weights = torch.softmax(\n",
        "            attn_scores / (keys.shape[-1]**0.5),\n",
        "            dim=-1\n",
        "        )\n",
        "\n",
        "        # 计算上下文向量\n",
        "        context_vec = attn_weights @ values\n",
        "\n",
        "        # 返回上下文向量\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "8phheiFyT8kN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(789)\n",
        "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
        "print(sa_v2(inputs))"
      ],
      "metadata": {
        "id": "waufOHzJUQ9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "890a2c8b-2b2d-4354-f346-f9a2184dce85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0739,  0.0713],\n",
            "        [-0.0748,  0.0703],\n",
            "        [-0.0749,  0.0702],\n",
            "        [-0.0760,  0.0685],\n",
            "        [-0.0763,  0.0679],\n",
            "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## 3.5 Hiding future words with causal attention"
      ],
      "metadata": {
        "id": "4CZn6R2gU1F6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  3.5.1 Applying a causal attention mask"
      ],
      "metadata": {
        "id": "bI7Cx3WhU6W0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算查询向量\n",
        "# sa_v2.W_query是查询线性层\n",
        "# inputs是输入张量\n",
        "queries = sa_v2.W_query(inputs)\n",
        "\n",
        "# 计算键向量\n",
        "# sa_v2.W_key是键线性层\n",
        "# inputs是输入张量\n",
        "keys = sa_v2.W_key(inputs)\n",
        "\n",
        "# 计算注意力分数\n",
        "# queries是查询矩阵，keys.T是键矩阵的转置\n",
        "attn_scores = queries @ keys.T\n",
        "\n",
        "# 计算缩放的注意力权重\n",
        "# attn_scores是原始注意力分数\n",
        "# keys.shape[-1]**0.5是缩放因子，用于防止梯度消失\n",
        "attn_weights = torch.softmax(attn_scores / (keys.shape[-1]**0.5), dim=-1)\n",
        "\n",
        "# 打印计算得到的注意力权重\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "id": "SrwYn8_XUdgU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fac6ba07-d1e5-4bcc-abbd-004e4223a472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n",
            "        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n",
            "        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n",
            "        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n",
            "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n",
            "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 获取注意力分数矩阵的行数（即上下文长度）\n",
        "context_length = attn_scores.shape[0]\n",
        "\n",
        "# 创建一个下三角掩码\n",
        "# torch.ones(context_length, context_length) 创建一个全1矩阵\n",
        "# torch.tril(...) 提取矩阵的下三角部分\n",
        "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
        "\n",
        "# 打印创建的掩码\n",
        "print(mask_simple)"
      ],
      "metadata": {
        "id": "hlrU4rWRWsVf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62ac8e3b-899d-4408-d7ab-399d6cc030d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 将注意力权重与掩码相乘\n",
        "# attn_weights是原始注意力权重\n",
        "# mask_simple是下三角掩码\n",
        "masked_simple = attn_weights * mask_simple\n",
        "\n",
        "# 打印掩码后的注意力权重\n",
        "print(masked_simple)"
      ],
      "metadata": {
        "id": "bezLWW0eXCEX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d40af62-f62a-4062-f3c1-4d41662f5401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1921, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2041, 0.1659, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2036, 0.1659, 0.1662, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1869, 0.1667, 0.1668, 0.1571, 0.0000, 0.0000],\n",
            "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.0000],\n",
            "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算每行的和\n",
        "# masked_simple是掩码后的注意力权重\n",
        "# dim=-1表示在最后一个维度（行）上求和\n",
        "# keepdim=True表示保持维度\n",
        "row_sums = masked_simple.sum(dim=-1, keepdim=True)\n",
        "\n",
        "# 对掩码后的注意力权重进行归一化\n",
        "# masked_simple / row_sums 将每行的元素除以该行的和\n",
        "masked_simple_norm = masked_simple / row_sums\n",
        "\n",
        "# 打印归一化后的注意力权重\n",
        "print(masked_simple_norm)"
      ],
      "metadata": {
        "id": "yukCuASnXH63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b5ca46-59d7-4684-e4f5-a80372250c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
            "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
            "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
            "       grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建一个上三角掩码，对角线以上的元素为1\n",
        "# torch.ones(context_length, context_length) 创建一个全1矩阵\n",
        "# torch.triu(..., diagonal=1) 提取矩阵的上三角部分（不包括对角线）\n",
        "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
        "\n",
        "# 将注意力分数矩阵中对应掩码为1的位置填充为负无穷\n",
        "# attn_scores.masked_fill(mask.bool(), -torch.inf) 将掩码位置填充为负无穷\n",
        "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
        "\n",
        "# 打印掩码后的注意力分数\n",
        "print(masked)"
      ],
      "metadata": {
        "id": "y2oCmmotXOZM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "962240c1-d843-4fa1-9ed9-afc414d78d24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
            "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
            "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
            "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
            "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
            "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
            "       grad_fn=<MaskedFillBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算缩放的注意力权重\n",
        "# masked是掩码后的注意力分数\n",
        "# keys.shape[-1]**0.5是缩放因子，用于防止梯度消失\n",
        "# dim=1表示在第二个维度（列）上进行softmax\n",
        "attn_weights = torch.softmax(masked / (keys.shape[-1]**0.5), dim=1)\n",
        "\n",
        "# 打印计算得到的注意力权重\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "id": "Llf-di35XUi5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90058957-6775-4bef-dd74-7e5640f8d04a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
            "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
            "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  3.5.2 Masking additional attention weights with dropout"
      ],
      "metadata": {
        "id": "E0QpQIjaXjYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "dropout = torch.nn.Dropout(0.5)\n",
        "example = torch.ones(6, 6)\n",
        "print(dropout(example))"
      ],
      "metadata": {
        "id": "fVMyF_V1Xf5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bec6d0cc-86f8-4211-88a2-638b894171f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2., 2., 2., 2., 2., 2.],\n",
            "        [0., 2., 0., 0., 0., 0.],\n",
            "        [0., 0., 2., 0., 2., 0.],\n",
            "        [2., 2., 0., 0., 0., 2.],\n",
            "        [2., 0., 0., 0., 0., 2.],\n",
            "        [0., 2., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "print(dropout(attn_weights))"
      ],
      "metadata": {
        "id": "RG9NEOSLXypA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4228f38-a174-495f-80c1-ceec5fc5e72a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.8966, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.6206, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5517, 0.4921, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.4350, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.3327, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  3.5.3 Implementing a compact causal attention class"
      ],
      "metadata": {
        "id": "8YwMn_oUYGJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 将两个输入张量沿第一个维度（批量维度）堆叠\n",
        "# dim=0表示沿第一个维度堆叠\n",
        "batch = torch.stack((inputs, inputs), dim=0)\n",
        "\n",
        "# 打印堆叠后的张量形状\n",
        "print(batch.shape)"
      ],
      "metadata": {
        "id": "ywQHttVtYFO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f3b15cd-9953-410f-cf09-0ca4d588b22f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 6, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CausalAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        self.d_out = d_out\n",
        "        # 定义查询(Query)线性层\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        # 定义键(Key)线性层\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        # 定义值(Value)线性层\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        # 定义Dropout层\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # 注册一个缓冲区，存储因果掩码\n",
        "        self.register_buffer(\n",
        "            'mask',\n",
        "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 获取输入张量的形状\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        # 计算所有输入向量的键表示\n",
        "        keys = self.W_key(x)\n",
        "        # 计算所有输入向量的查询表示\n",
        "        queries = self.W_query(x)\n",
        "        # 计算所有输入向量的值表示\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # 计算注意力分数\n",
        "        attn_scores = queries @ keys.transpose(1, 2)\n",
        "\n",
        "        # 应用因果掩码\n",
        "        attn_scores.masked_fill_(\n",
        "            self.mask[:num_tokens, :num_tokens].bool(), -torch.inf\n",
        "        )\n",
        "\n",
        "        # 计算缩放的注意力权重\n",
        "        attn_weights = torch.softmax(\n",
        "            attn_scores / (keys.shape[-1]**0.5),\n",
        "            dim=-1\n",
        "        )\n",
        "\n",
        "        # 应用Dropout\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # 计算上下文向量\n",
        "        context_vec = attn_weights @ values\n",
        "\n",
        "        # 返回上下文向量\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "bI_wTyGtZBIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置随机种子，确保结果可复现\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 获取批量输入的上下文长度\n",
        "# batch.shape[1]获取第二个维度的大小（即上下文长度）\n",
        "context_length = batch.shape[1]\n",
        "\n",
        "# 实例化因果自注意力模块\n",
        "# d_in是输入维度，d_out是输出维度\n",
        "# context_length是上下文长度\n",
        "# 0.0表示不使用Dropout\n",
        "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
        "\n",
        "# 计算因果自注意力模块的输出\n",
        "# batch是输入张量\n",
        "context_vecs = ca(batch)\n",
        "\n",
        "# 打印输出张量的形状\n",
        "print(\"context_vecs.shape:\", context_vecs.shape)"
      ],
      "metadata": {
        "id": "kEH2NtnxZQLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4667cac7-6834-43bc-c6ab-231c85f91aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context_vecs.shape: torch.Size([2, 6, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  3.6 Extending single-head attention to multi-head attention"
      ],
      "metadata": {
        "id": "QgM8yPngsM1v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  3.6.1 Stacking multiple single-head attention layers"
      ],
      "metadata": {
        "id": "9MJt-1RQse6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        # 创建多个因果自注意力头\n",
        "        self.heads = nn.ModuleList([\n",
        "            CausalAttention(d_in, d_out, context_length, dropout, qkv_bias)\n",
        "            for _ in range(num_heads)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 对每个自注意力头的输出进行拼接\n",
        "        # head(x) 调用每个自注意力头的前向传播方法\n",
        "        # torch.cat(..., dim=-1) 沿最后一个维度拼接\n",
        "        return torch.cat([head(x) for head in self.heads], dim=-1)"
      ],
      "metadata": {
        "id": "KlQHilzTZayF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置随机种子，确保结果可复现\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 获取批量输入的上下文长度\n",
        "# batch是输入张量，假设形状为(2, 6, 3)\n",
        "# batch.shape[1]获取第二个维度的大小（即上下文长度）\n",
        "context_length = batch.shape[1]\n",
        "\n",
        "# 定义输入和输出维度\n",
        "d_in, d_out = 3, 2\n",
        "\n",
        "# 实例化多头自注意力模块\n",
        "# d_in是输入维度，d_out是输出维度\n",
        "# context_length是上下文长度\n",
        "# 0.0表示不使用Dropout\n",
        "# num_heads=2表示使用2个注意力头\n",
        "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
        "\n",
        "# 计算多头自注意力模块的输出\n",
        "# batch是输入张量\n",
        "context_vecs = mha(batch)\n",
        "\n",
        "# 打印输出张量及其形状\n",
        "print(context_vecs)\n",
        "print(\"context_vecs.shape:\", context_vecs.shape)"
      ],
      "metadata": {
        "id": "60zL5Fxesshz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cad059b-0533-466b-d8cc-8dcc177c62f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
            "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
            "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
            "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
            "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
            "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
            "\n",
            "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
            "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
            "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
            "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
            "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
            "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n",
            "context_vecs.shape: torch.Size([2, 6, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  3.6.2 Implementing multi-head attention with weight splits"
      ],
      "metadata": {
        "id": "90_C0Zi-txc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        # 确保输出维度可以被注意力头数整除\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "\n",
        "        # 定义查询(Query)、键(Key)、值(Value)线性层\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "        # 定义输出投影线性层\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "\n",
        "        # 定义Dropout层\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # 注册因果掩码\n",
        "        self.register_buffer(\n",
        "            'mask',\n",
        "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 获取输入张量的形状\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        # 计算查询、键、值\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # 重塑张量以适应多头注意力\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # 调整维度顺序\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # 计算注意力分数\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "\n",
        "        # 应用因果掩码\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        # 计算缩放的注意力权重\n",
        "        attn_weights = torch.softmax(\n",
        "            attn_scores / (keys.shape[-1]**0.5),\n",
        "            dim=-1\n",
        "        )\n",
        "\n",
        "        # 应用Dropout\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # 计算上下文向量\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # 重塑张量并应用输出投影\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "\n",
        "        # 返回上下文向量\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "Vk-dLwIws0jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建一个四维张量\n",
        "# 形状为 (1, 2, 3, 4)\n",
        "# 第一个维度：批量大小为1\n",
        "# 第二个维度：注意力头数为2\n",
        "# 第三个维度：标记数量为3\n",
        "# 第四个维度：每个头的维度为4\n",
        "a = torch.tensor([[[[0.2745, 0.6584, 0.2775, 0.8573],\n",
        "                    [0.8993, 0.0390, 0.9268, 0.7388],\n",
        "                    [0.7179, 0.7058, 0.9156, 0.4340]],\n",
        "\n",
        "                   [[0.0772, 0.3565, 0.1479, 0.5331],\n",
        "                    [0.4066, 0.2318, 0.4545, 0.9737],\n",
        "                    [0.4606, 0.5159, 0.4220, 0.5786]]]])"
      ],
      "metadata": {
        "id": "So1DktMouA0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a @ a.transpose(2, 3))"
      ],
      "metadata": {
        "id": "ZeUpFGKauJrR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67844a96-917f-4716-b738-12c6009edfdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[1.3208, 1.1631, 1.2879],\n",
            "          [1.1631, 2.2150, 1.8424],\n",
            "          [1.2879, 1.8424, 2.0402]],\n",
            "\n",
            "         [[0.4391, 0.7003, 0.5903],\n",
            "          [0.7003, 1.3737, 1.0620],\n",
            "          [0.5903, 1.0620, 0.9912]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 提取第一个注意力头\n",
        "# a是输入张量，形状为(1, 2, 3, 4)\n",
        "# a[0, 0, :, :] 提取第一个样本、第一个头、所有标记、所有维度\n",
        "first_head = a[0, 0, :, :]\n",
        "\n",
        "# 计算第一个注意力头的自注意力分数\n",
        "# first_head @ first_head.T 计算第一个头的查询和键的点积\n",
        "first_res = first_head @ first_head.T\n",
        "\n",
        "# 打印第一个头的自注意力分数\n",
        "print(\"First head:\\n\", first_res)\n",
        "\n",
        "# 提取第二个注意力头\n",
        "# a[0, 1, :, :] 提取第一个样本、第二个头、所有标记、所有维度\n",
        "second_head = a[0, 1, :, :]\n",
        "\n",
        "# 计算第二个注意力头的自注意力分数\n",
        "# second_head @ second_head.T 计算第二个头的查询和键的点积\n",
        "second_res = second_head @ second_head.T\n",
        "\n",
        "# 打印第二个头的自注意力分数\n",
        "print(\"\\nSecond head:\\n\", second_res)"
      ],
      "metadata": {
        "id": "k2_qBm-ruL1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c06afde-2f49-49aa-e09a-a1397b31f354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First head:\n",
            " tensor([[1.3208, 1.1631, 1.2879],\n",
            "        [1.1631, 2.2150, 1.8424],\n",
            "        [1.2879, 1.8424, 2.0402]])\n",
            "\n",
            "Second head:\n",
            " tensor([[0.4391, 0.7003, 0.5903],\n",
            "        [0.7003, 1.3737, 1.0620],\n",
            "        [0.5903, 1.0620, 0.9912]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置随机种子，确保结果可复现\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 获取批量输入的上下文长度和输入维度\n",
        "# batch是输入张量，假设形状为(2, 6, 3)\n",
        "# batch.shape[1]获取第二个维度的大小（即上下文长度）\n",
        "# batch.shape[2]获取第三个维度的大小（即输入维度）\n",
        "batch_size, context_length, d_in = batch.shape\n",
        "\n",
        "# 定义输出维度\n",
        "d_out = 2\n",
        "\n",
        "# 实例化多头自注意力模块\n",
        "# d_in是输入维度，d_out是输出维度\n",
        "# context_length是上下文长度\n",
        "# 0.0表示不使用Dropout\n",
        "# num_heads=2表示使用2个注意力头\n",
        "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
        "\n",
        "# 计算多头自注意力模块的输出\n",
        "# batch是输入张量\n",
        "context_vecs = mha(batch)\n",
        "\n",
        "# 打印输出张量的形状\n",
        "print(context_vecs)\n",
        "print(\"context_vecs.shape:\", context_vecs.shape)"
      ],
      "metadata": {
        "id": "gbFhZ2z7uWEh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08f50e64-5bff-4fdc-bbd3-3bbfdbfb359c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.3190, 0.4858],\n",
            "         [0.2943, 0.3897],\n",
            "         [0.2856, 0.3593],\n",
            "         [0.2693, 0.3873],\n",
            "         [0.2639, 0.3928],\n",
            "         [0.2575, 0.4028]],\n",
            "\n",
            "        [[0.3190, 0.4858],\n",
            "         [0.2943, 0.3897],\n",
            "         [0.2856, 0.3593],\n",
            "         [0.2693, 0.3873],\n",
            "         [0.2639, 0.3928],\n",
            "         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)\n",
            "context_vecs.shape: torch.Size([2, 6, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Implementing a GPT model from scratch to generate text"
      ],
      "metadata": {
        "id": "M-mz4p-jupzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Coding an LLM architecture"
      ],
      "metadata": {
        "id": "s3LHoTCx9gvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义一个名为GPT_CONFIG_124M的字典，用于配置一个1.24亿参数规模的GPT模型\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,  # 词汇表大小，即模型能够识别的不同单词或标记的数量\n",
        "    \"context_length\": 1024,  # 上下文长度，指模型在处理文本时能够考虑的最大单词数量\n",
        "    \"emb_dim\": 768,  # 嵌入维度，即每个单词或标记被转换为的向量空间的维度\n",
        "    \"n_heads\": 12,  # 注意力头的数量，即模型在处理注意力机制时使用的并行注意力头的数量\n",
        "    \"n_layers\": 12,  # 层数，即模型中Transformer层的数量\n",
        "    \"drop_rate\": 0.1,  # 丢弃率，即在训练过程中随机丢弃神经元的比例\n",
        "    \"qkv_bias\": False  # 查询-键-值偏置，指是否在计算注意力机制时使用偏置\n",
        "}"
      ],
      "metadata": {
        "id": "T7sW7upzutaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 定义一个简化版的GPT模型\n",
        "class DummyGPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        # 标记嵌入层，将输入标记转换为向量表示\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        # 位置嵌入层，为每个位置添加位置信息\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        # 嵌入层后的Dropout层，用于防止过拟合\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "        # Transformer块序列，使用占位符类DummyTransformerBlock\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
        "        )\n",
        "        # 最终的层归一化，使用占位符类DummyLayerNorm\n",
        "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
        "        # 输出头，将处理后的向量映射回词汇表大小\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        # 获取输入张量的形状\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        # 计算标记嵌入\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        # 计算位置嵌入\n",
        "        pos_embeds = self.pos_emb(\n",
        "            torch.arange(seq_len, device=in_idx.device)\n",
        "        )\n",
        "        # 标记嵌入和位置嵌入相加\n",
        "        x = tok_embeds + pos_embeds\n",
        "        # 应用Dropout\n",
        "        x = self.drop_emb(x)\n",
        "        # 通过Transformer块\n",
        "        x = self.trf_blocks(x)\n",
        "        # 应用层归一化\n",
        "        x = self.final_norm(x)\n",
        "        # 计算输出logits\n",
        "        logits = self.out_head(x)\n",
        "        # 返回logits\n",
        "        return logits\n",
        "\n",
        "# 占位符类，实际应用中会被真实的Transformer块替换\n",
        "class DummyTransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x\n",
        "\n",
        "# 占位符类，实际应用中会被真实的层归一化替换\n",
        "class DummyLayerNorm(nn.Module):\n",
        "    def __init__(self, normalized_shape, eps=1e-5):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x"
      ],
      "metadata": {
        "id": "U8t9YY3z920U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "import torch\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "batch = []\n",
        "txt1 = \"Every effort moves you\"\n",
        "txt2 = \"Every day holds a\"\n",
        "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
        "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
        "batch = torch.stack(batch, dim=0)\n",
        "print(batch)"
      ],
      "metadata": {
        "id": "5UUxScBL-JBy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35c066f8-bf07-4fd3-e082-b778af61ee54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6109, 3626, 6100,  345],\n",
            "        [6109, 1110, 6622,  257]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置随机种子，确保结果可复现\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 实例化DummyGPTModel模型\n",
        "# GPT_CONFIG_124M是配置字典\n",
        "model = DummyGPTModel(GPT_CONFIG_124M)\n",
        "\n",
        "# 计算模型的输出\n",
        "# batch是输入张量\n",
        "logits = model(batch)\n",
        "\n",
        "# 打印输出张量的形状\n",
        "print(\"Output shape:\", logits.shape)\n",
        "\n",
        "# 打印输出张量\n",
        "print(logits)"
      ],
      "metadata": {
        "id": "U4MHXAuP-Wi2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9c9cfd6-fc5f-45b1-abc5-f9234646e683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([2, 4, 50257])\n",
            "tensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n",
            "         [-0.4476,  0.1726,  0.5354,  ..., -0.3932,  1.5285,  0.8557],\n",
            "         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n",
            "         [ 0.0447,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n",
            "\n",
            "        [[-1.5474, -0.0542, -1.0571,  ..., -1.8061, -0.4494, -0.6747],\n",
            "         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n",
            "         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n",
            "         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Normalizing activations with layer normalization"
      ],
      "metadata": {
        "id": "9j4wwCJ7-kxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置随机种子，确保结果可复现\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 创建一个随机张量，形状为(2, 5)\n",
        "# 表示2个训练样本，每个样本有5个特征\n",
        "batch_example = torch.randn(2, 5)\n",
        "\n",
        "# 定义一个神经网络层序列\n",
        "# 包含一个线性层和一个ReLU激活函数\n",
        "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
        "\n",
        "# 对输入张量进行前向传播\n",
        "out = layer(batch_example)\n",
        "\n",
        "# 打印输出结果\n",
        "print(out)"
      ],
      "metadata": {
        "id": "XecJClw6-gbT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a42d5ad8-8a64-4023-9a81-b84cedec166d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
            "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
            "       grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算张量的均值，沿最后一个维度，保持维度\n",
        "mean = out.mean(dim=-1, keepdim=True)\n",
        "\n",
        "# 计算张量的方差，沿最后一个维度，保持维度\n",
        "var = out.var(dim=-1, keepdim=True)\n",
        "\n",
        "# 打印均值\n",
        "print(\"Mean:\\n\", mean)\n",
        "\n",
        "# 打印方差\n",
        "print(\"Variance:\\n\", var)"
      ],
      "metadata": {
        "id": "YTAzEIKl-0PS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2844ff17-ee35-4f6f-c89c-f04314094578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean:\n",
            " tensor([[0.1324],\n",
            "        [0.2170]], grad_fn=<MeanBackward1>)\n",
            "Variance:\n",
            " tensor([[0.0231],\n",
            "        [0.0398]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 对张量进行归一化处理\n",
        "# (out - mean) 减去均值\n",
        "# torch.sqrt(var) 计算方差的平方根\n",
        "out_norm = (out - mean) / torch.sqrt(var)\n",
        "\n",
        "# 重新计算归一化后的均值\n",
        "mean = out_norm.mean(dim=-1, keepdim=True)\n",
        "\n",
        "# 重新计算归一化后的方差\n",
        "var = out_norm.var(dim=-1, keepdim=True)\n",
        "\n",
        "# 打印归一化后的张量\n",
        "print(\"Normalized layer outputs:\\n\", out_norm)\n",
        "\n",
        "# 打印归一化后的均值\n",
        "print(\"Mean:\\n\", mean)\n",
        "\n",
        "# 打印归一化后的方差\n",
        "print(\"Variance:\\n\", var)"
      ],
      "metadata": {
        "id": "btpX0GvB-67X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e9c5e96-51b5-4ca4-c868-9c8170bfea40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized layer outputs:\n",
            " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
            "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Mean:\n",
            " tensor([[    0.0000],\n",
            "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
            "Variance:\n",
            " tensor([[1.0000],\n",
            "        [1.0000]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置PyTorch的打印选项，禁用科学计数法\n",
        "torch.set_printoptions(sci_mode=False)\n",
        "\n",
        "# 打印均值\n",
        "print(\"Mean:\\n\", mean)\n",
        "\n",
        "# 打印方差\n",
        "print(\"Variance:\\n\", var)"
      ],
      "metadata": {
        "id": "MF2NxM5p_Bt9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f0eece2-1703-402b-bdd0-d679794daf6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean:\n",
            " tensor([[    0.0000],\n",
            "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
            "Variance:\n",
            " tensor([[1.0000],\n",
            "        [1.0000]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        # 数值稳定性参数\n",
        "        self.eps = 1e-5\n",
        "        # 缩放参数，初始化为全1\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        # 偏移参数，初始化为全0\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 计算输入张量的均值，沿最后一个维度，保持维度\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        # 计算输入张量的方差，沿最后一个维度，保持维度\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        # 归一化操作\n",
        "        # (x - mean) 减去均值\n",
        "        # torch.sqrt(var + self.eps) 计算方差的平方根，并加上数值稳定性参数\n",
        "        norm = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        # 应用缩放和偏移\n",
        "        return self.scale * norm + self.shift"
      ],
      "metadata": {
        "id": "Yj2lqssb_HeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 实例化自定义的层归一化模块，嵌入维度为5\n",
        "ln = LayerNorm(emb_dim=5)\n",
        "\n",
        "# 对输入张量进行层归一化\n",
        "out_ln = ln(batch_example)\n",
        "\n",
        "# 计算归一化后的均值，沿最后一个维度，保持维度\n",
        "mean = out_ln.mean(dim=-1, keepdim=True)\n",
        "\n",
        "# 计算归一化后的方差，沿最后一个维度，保持维度\n",
        "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
        "\n",
        "# 打印归一化后的均值\n",
        "print(\"Mean:\\n\", mean)\n",
        "\n",
        "# 打印归一化后的方差\n",
        "print(\"Variance:\\n\", var)"
      ],
      "metadata": {
        "id": "4h5rjh1k_Q2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "658f79d8-bfc1-4312-abcc-ea9dba88bf6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean:\n",
            " tensor([[    -0.0000],\n",
            "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
            "Variance:\n",
            " tensor([[1.0000],\n",
            "        [1.0000]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  4.3 Implementing a feed forward network with GELU activations"
      ],
      "metadata": {
        "id": "f6793NHG_Z_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))"
      ],
      "metadata": {
        "id": "ICBthErt_X-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# 实例化GELU和ReLU激活函数\n",
        "gelu, relu = GELU(), nn.ReLU()\n",
        "# 创建100个样本数据点，范围从-3到3\n",
        "x = torch.linspace(-3, 3, 100)\n",
        "y_gelu, y_relu = gelu(x), relu(x)\n",
        "plt.figure(figsize=(8, 3))\n",
        "# 遍历GELU和ReLU的输出及标签\n",
        "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
        "    plt.subplot(1, 2, i)\n",
        "    plt.plot(x, y)\n",
        "    plt.title(f\"{label} activation function\")\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(f\"{label}(x)\")\n",
        "    plt.grid(True)\n",
        "# 调整子图布局\n",
        "plt.tight_layout()\n",
        "# 显示图像\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-DG_BwNV_mkw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "9b9d63b7-a30d-40cb-a90d-cac06b0cb3bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        # 定义前馈神经网络的层序列\n",
        "        self.layers = nn.Sequential(\n",
        "            # 第一个线性层，输入维度为emb_dim，输出维度为4*emb_dim\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            # GELU激活函数\n",
        "            GELU(),\n",
        "            # 第二个线性层，输入维度为4*emb_dim，输出维度为emb_dim\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 前向传播，将输入张量通过层序列\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "Xj-6GbWDAJj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 实例化前馈神经网络模块，使用GPT_CONFIG_124M配置\n",
        "ffn = FeedForward(GPT_CONFIG_124M)\n",
        "\n",
        "# 创建一个随机张量，形状为(2, 3, 768)\n",
        "# 表示批量大小为2，序列长度为3，嵌入维度为768\n",
        "x = torch.rand(2, 3, 768)\n",
        "\n",
        "# 对输入张量进行前向传播\n",
        "out = ffn(x)\n",
        "\n",
        "# 打印输出张量的形状\n",
        "print(out.shape)"
      ],
      "metadata": {
        "id": "BMRuTid4AXVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a030ed6d-0209-4aca-be5e-ffd10993267e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  4.4 Adding shortcut connections"
      ],
      "metadata": {
        "id": "YgIBf7pgAfFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ExampleDeepNeuralNetwork(nn.Module):\n",
        "    def __init__(self, layer_sizes, use_shortcut):\n",
        "        super().__init__()\n",
        "        # 是否使用快捷连接\n",
        "        self.use_shortcut = use_shortcut\n",
        "        # 定义神经网络的层列表\n",
        "        self.layers = nn.ModuleList([\n",
        "            # 第一层：线性层 + GELU激活函数\n",
        "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
        "            # 第二层：线性层 + GELU激活函数\n",
        "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
        "            # 第三层：线性层 + GELU激活函数\n",
        "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
        "            # 第四层：线性层 + GELU激活函数\n",
        "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
        "            # 第五层：线性层 + GELU激活函数\n",
        "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 遍历每一层\n",
        "        for layer in self.layers:\n",
        "            # 计算当前层的输出\n",
        "            layer_output = layer(x)\n",
        "            # 如果使用快捷连接且输入和输出形状一致\n",
        "            if self.use_shortcut and x.shape == layer_output.shape:\n",
        "                # 应用快捷连接，输入加上当前层的输出\n",
        "                x = x + layer_output\n",
        "            else:\n",
        "                # 否则，直接使用当前层的输出\n",
        "                x = layer_output\n",
        "        # 返回最终的输出\n",
        "        return x"
      ],
      "metadata": {
        "id": "IR0d6mdHAdpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 定义神经网络的层大小\n",
        "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
        "\n",
        "# 创建一个样本输入张量\n",
        "sample_input = torch.tensor([[1., 0., -1.]])\n",
        "\n",
        "# 设置随机种子，确保结果可复现\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 实例化不使用快捷连接的深度神经网络模型\n",
        "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
        "    layer_sizes, use_shortcut=False\n",
        ")"
      ],
      "metadata": {
        "id": "Z0joUA0MAsXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def print_gradients(model, x):\n",
        "    # 前向传播，计算模型的输出\n",
        "    output = model(x)\n",
        "    # 定义目标张量\n",
        "    target = torch.tensor([[0.]])\n",
        "    # 定义均方误差损失函数\n",
        "    loss = nn.MSELoss()\n",
        "    # 计算损失\n",
        "    loss = loss(output, target)\n",
        "    # 反向传播，计算梯度\n",
        "    loss.backward()\n",
        "\n",
        "    # 遍历模型的所有参数\n",
        "    for name, param in model.named_parameters():\n",
        "        # 如果参数名称包含'weight'\n",
        "        if 'weight' in name:\n",
        "            # 打印参数的梯度均值\n",
        "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
      ],
      "metadata": {
        "id": "YWGjKRreA4fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_gradients(model_without_shortcut, sample_input)"
      ],
      "metadata": {
        "id": "aJvXpA4vBCU-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9563ced6-51b6-420e-def9-d05776a2eead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layers.0.0.weight has gradient mean of 0.00020173584925942123\n",
            "layers.1.0.weight has gradient mean of 0.00012011159560643137\n",
            "layers.2.0.weight has gradient mean of 0.0007152040489017963\n",
            "layers.3.0.weight has gradient mean of 0.0013988736318424344\n",
            "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 设置随机种子，确保结果可复现\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 实例化使用快捷连接的深度神经网络模型\n",
        "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
        "    layer_sizes, use_shortcut=True\n",
        ")\n",
        "\n",
        "# 计算模型的梯度并打印参数的梯度均值\n",
        "print_gradients(model_with_shortcut, sample_input)"
      ],
      "metadata": {
        "id": "JFgWan7wBTeS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e7a19e0-0c45-4c5e-9ee7-5c10c1d1a465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layers.0.0.weight has gradient mean of 0.22169791162014008\n",
            "layers.1.0.weight has gradient mean of 0.20694105327129364\n",
            "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
            "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
            "layers.4.0.weight has gradient mean of 1.3258540630340576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.5  Connecting attention and linear layers in a transformer block"
      ],
      "metadata": {
        "id": "PsfCueNVBc-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# import MultiHeadAttention\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        # 定义多头注意力模块\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"]\n",
        "        )\n",
        "        # 定义前馈神经网络模块\n",
        "        self.ff = FeedForward(cfg)\n",
        "        # 定义层归一化模块\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        # 定义dropout模块\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 保存原始输入作为快捷连接\n",
        "        shortcut = x\n",
        "        # 应用层归一化\n",
        "        x = self.norm1(x)\n",
        "        # 应用多头注意力\n",
        "        x = self.att(x)\n",
        "        # 应用dropout\n",
        "        x = self.drop_shortcut(x)\n",
        "        # 应用快捷连接\n",
        "        x = x + shortcut\n",
        "\n",
        "        # 保存当前输入作为快捷连接\n",
        "        shortcut = x\n",
        "        # 应用层归一化\n",
        "        x = self.norm2(x)\n",
        "        # 应用前馈神经网络\n",
        "        x = self.ff(x)\n",
        "        # 应用dropout\n",
        "        x = self.drop_shortcut(x)\n",
        "        # 应用快捷连接\n",
        "        x = x + shortcut\n",
        "\n",
        "        # 返回最终的输出\n",
        "        return x"
      ],
      "metadata": {
        "id": "f7gbi-qEBb4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 设置随机种子，确保结果可复现\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 创建一个随机张量，形状为(2, 4, 768)\n",
        "# 表示批量大小为2，序列长度为4，嵌入维度为768\n",
        "x = torch.rand(2, 4, 768)\n",
        "\n",
        "# 实例化Transformer块，使用GPT_CONFIG_124M配置\n",
        "block = TransformerBlock(GPT_CONFIG_124M)\n",
        "\n",
        "# 对输入张量进行前向传播\n",
        "output = block(x)\n",
        "\n",
        "# 打印输入张量的形状\n",
        "print(\"Input shape:\", x.shape)\n",
        "\n",
        "# 打印输出张量的形状\n",
        "print(\"Output shape:\", output.shape)"
      ],
      "metadata": {
        "id": "Xkar0FS4COJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4082365-8d87-42ec-a0b1-3e47c26a79f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.6 Coding the GPT model"
      ],
      "metadata": {
        "id": "naifOlW1CZ58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        # 定义词嵌入层\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        # 定义位置嵌入层\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        # 定义dropout层\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        # 定义Transformer块序列\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
        "        )\n",
        "\n",
        "        # 定义最终的层归一化\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        # 定义输出头\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        # 获取输入的批量大小和序列长度\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        # 计算词嵌入\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        # 计算位置嵌入\n",
        "        pos_embeds = self.pos_emb(\n",
        "            torch.arange(seq_len, device=in_idx.device)\n",
        "        )\n",
        "        # 词嵌入加上位置嵌入\n",
        "        x = tok_embeds + pos_embeds\n",
        "        # 应用dropout\n",
        "        x = self.drop_emb(x)\n",
        "        # 通过Transformer块序列\n",
        "        x = self.trf_blocks(x)\n",
        "        # 应用最终的层归一化\n",
        "        x = self.final_norm(x)\n",
        "        # 计算输出logits\n",
        "        logits = self.out_head(x)\n",
        "        # 返回logits\n",
        "        return logits"
      ],
      "metadata": {
        "id": "cQO_qsvsCYIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 设置随机种子，确保结果可复现\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 实例化GPT模型，使用GPT_CONFIG_124M配置\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "\n",
        "# 对输入批次进行前向传播\n",
        "out = model(batch)\n",
        "\n",
        "# 打印输入批次\n",
        "print(\"Input batch:\\n\", batch)\n",
        "\n",
        "# 打印输出形状\n",
        "print(\"Output shape:\", out.shape)\n",
        "\n",
        "# 打印输出结果\n",
        "print(out)"
      ],
      "metadata": {
        "id": "JDf02z7mClog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5190e8f-7d10-41ad-8f9c-e58c064cdde9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch:\n",
            " tensor([[6109, 3626, 6100,  345],\n",
            "        [6109, 1110, 6622,  257]])\n",
            "Output shape: torch.Size([2, 4, 50257])\n",
            "tensor([[[ 0.1381,  0.0077, -0.1963,  ..., -0.0222, -0.1060,  0.1717],\n",
            "         [ 0.3865, -0.8408, -0.6564,  ..., -0.5163,  0.2369, -0.3357],\n",
            "         [ 0.6989, -0.1829, -0.1631,  ...,  0.1472, -0.6504, -0.0056],\n",
            "         [-0.4290,  0.1669, -0.1258,  ...,  1.1579,  0.5303, -0.5549]],\n",
            "\n",
            "        [[ 0.1094, -0.2894, -0.1467,  ..., -0.0557,  0.2911, -0.2824],\n",
            "         [ 0.0882, -0.3552, -0.3527,  ...,  1.2930,  0.0053,  0.1898],\n",
            "         [ 0.6091,  0.4702, -0.4094,  ...,  0.7688,  0.3787, -0.1974],\n",
            "         [-0.0612, -0.0737,  0.4751,  ...,  1.2463, -0.3834,  0.0609]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 计算模型的总参数数量\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "# 打印总参数数量\n",
        "print(f\"Total number of parameters: {total_params:,}\")"
      ],
      "metadata": {
        "id": "G63ouwWmCse5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e93c187-9d50-4c1f-8669-f66a11f782da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters: 163,009,536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 打印词嵌入层的权重形状\n",
        "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
        "\n",
        "# 打印输出层的权重形状\n",
        "print(\"Output layer shape:\", model.out_head.weight.shape)"
      ],
      "metadata": {
        "id": "-eEeaZOmC4fx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b34551d-4c4c-4595-a748-dd80e54c5a0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token embedding layer shape: torch.Size([50257, 768])\n",
            "Output layer shape: torch.Size([50257, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 计算考虑权重绑定后的可训练参数数量\n",
        "total_params_gpt2 = (\n",
        "    total_params - sum(p.numel() for p in model.out_head.parameters())\n",
        ")\n",
        "\n",
        "# 打印结果\n",
        "print(f\"Number of trainable parameters \"\n",
        "      f\"considering weight tying: {total_params_gpt2:,}\")"
      ],
      "metadata": {
        "id": "yskcA-xMC-bw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce185f1-91f8-444a-bd3a-1d52ab292fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters considering weight tying: 124,412,160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 计算模型的总大小（字节）\n",
        "total_size_bytes = total_params * 4\n",
        "\n",
        "# 将总大小转换为兆字节\n",
        "total_size_mb = total_size_bytes / (1024 * 1024)\n",
        "\n",
        "# 打印模型的总大小\n",
        "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
      ],
      "metadata": {
        "id": "3DhKkaipDIeE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "006d0083-f225-49ca-e67a-8392866f99ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total size of the model: 621.83 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.7  Generating text"
      ],
      "metadata": {
        "id": "Z3cLZjP0DRZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # 裁剪当前上下文，使其不超过支持的上下文大小\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            # 获取模型的输出logits\n",
        "            logits = model(idx_cond)\n",
        "        # 聚焦于最后一个时间步\n",
        "        logits = logits[:, -1, :]\n",
        "        # 将logits转换为概率\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "        # 采样下一个token的索引\n",
        "        idx_next = torch.argmax(probs, dim=-1, keepdim=True)\n",
        "        # 将采样的token索引添加到运行序列中\n",
        "        idx = torch.cat((idx, idx_next), dim=1)\n",
        "    # 返回生成的序列\n",
        "    return idx"
      ],
      "metadata": {
        "id": "ycPDwPNFDPy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# 定义起始文本\n",
        "start_context = \"Hello, I am\"\n",
        "\n",
        "# 使用分词器对起始文本进行编码\n",
        "encoded = tokenizer.encode(start_context)\n",
        "\n",
        "# 打印编码结果\n",
        "print(\"encoded:\", encoded)\n",
        "\n",
        "# 将编码结果转换为张量，并添加批次维度\n",
        "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "\n",
        "# 打印张量的形状\n",
        "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
      ],
      "metadata": {
        "id": "0MbxN4A0DdA1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d529996-145a-4e53-efed-4065dfb3b8b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoded: [15496, 11, 314, 716]\n",
            "encoded_tensor.shape: torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 将模型设置为评估模式，禁用dropout\n",
        "model.eval()\n",
        "\n",
        "# 使用简单的文本生成函数生成新的文本序列\n",
        "out = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=encoded_tensor,\n",
        "    max_new_tokens=6,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "# 打印生成的序列\n",
        "print(\"Output:\", out)\n",
        "\n",
        "# 打印生成的序列长度\n",
        "print(\"Output length:\", len(out[0]))"
      ],
      "metadata": {
        "id": "oNeTgrCmDk8N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c61c7b1-3061-4e5b-c0f7-3d8e7e4cf83d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
            "Output length: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# 将生成的张量转换为列表，并移除批次维度\n",
        "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
        "\n",
        "# 打印解码后的文本\n",
        "print(decoded_text)"
      ],
      "metadata": {
        "id": "NR06CA_8DuQK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43d5f786-c426-4cb0-a737-cf3c3e73d862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, I am Featureiman Byeswickattribute argue\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 Pretraining on unlabeled data"
      ],
      "metadata": {
        "id": "yWZVe8EpD112"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1  Evaluating generative text models"
      ],
      "metadata": {
        "id": "BHT12MQ9D8zw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1.1 Using GPT to generate text"
      ],
      "metadata": {
        "id": "xvYKsF-PEBJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# from chapter04 import GPTModel\n",
        "\n",
        "# 定义GPT模型的配置\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 256,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}\n",
        "\n",
        "# 设置随机种子，确保结果可复现\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 实例化GPT模型，使用GPT_CONFIG_124M配置\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "\n",
        "# 将模型设置为评估模式，禁用dropout\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "9MpakNcLD0MS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2efdc1d-9b6a-4b9f-b3ae-007239a05be8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tiktoken\n",
        "# from chapter04 import generate_text_simple\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    # 将文本编码为token索引\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    # 转换为张量并添加批次维度\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    # 移除批次维度\n",
        "    flat = token_ids.squeeze(0)\n",
        "    # 将token索引解码为文本\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "# 定义起始文本\n",
        "start_context = \"Every effort moves you\"\n",
        "\n",
        "# 加载GPT-2的分词器\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "# 生成新的文本序列\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(start_context, tokenizer),\n",
        "    max_new_tokens=10,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "# 将生成的token索引转换回文本并打印\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "tHn2oA7jEWHD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d4f06e3-d1df-426b-9298-e3dd4bd61987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1.2  Calculating the text generation loss"
      ],
      "metadata": {
        "id": "HrsiJk3yEllq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
        "             [40,    1107, 588]])   #  \"I really like\"]"
      ],
      "metadata": {
        "id": "4VfrhrbHEn9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
        "             [1107, 588, 11311]])  #  \" really like chocolate\"]"
      ],
      "metadata": {
        "id": "p_6V1rkrEuta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 禁用梯度跟踪，提高性能并减少内存占用\n",
        "with torch.no_grad():\n",
        "    # 获取模型的输出logits\n",
        "    logits = model(inputs)\n",
        "    # 将logits转换为概率分布\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    # 打印概率分布的形状\n",
        "    print(probs.shape)"
      ],
      "metadata": {
        "id": "Dh5PaiaPE3VO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b09c2f4-e51f-41ed-f315-43f271cc7672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 50257])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 从概率分布中获取每个位置的最可能token索引\n",
        "token_ids = torch.argmax(probs, dim=-1, keepdim=True)\n",
        "\n",
        "# 打印token索引\n",
        "print(\"Token IDs:\\n\", token_ids)"
      ],
      "metadata": {
        "id": "4Kuz3GtIE_bJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7806b35-eba3-4e86-9a21-e8b9195ed7a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[[16657],\n",
            "         [  339],\n",
            "         [42826]],\n",
            "\n",
            "        [[49906],\n",
            "         [29669],\n",
            "         [41751]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 打印目标批次的第一个样本\n",
        "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
        "\n",
        "# 打印生成的token索引的第一个样本\n",
        "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
      ],
      "metadata": {
        "id": "CHx09veMFHZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08c87889-abf2-40d1-b0be-504cb2d15bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Targets batch 1:  effort moves you\n",
            "Outputs batch 1:  Armed heNetflix\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 定义文本索引\n",
        "text_idx = 0\n",
        "\n",
        "# 计算目标token在概率分布中的概率值\n",
        "target_probas_1 = probs[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "\n",
        "# 打印结果\n",
        "print(\"Text 1:\", target_probas_1)\n",
        "\n",
        "# 定义文本索引\n",
        "text_idx = 1\n",
        "\n",
        "# 计算目标token在概率分布中的概率值\n",
        "target_probas_2 = probs[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "\n",
        "# 打印结果\n",
        "print(\"Text 2:\", target_probas_2)"
      ],
      "metadata": {
        "id": "J-KOqYkjFNWY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b10603d4-d132-48c6-99c3-5b35ce25aa25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1: tensor([    0.0001,     0.0000,     0.0000])\n",
            "Text 2: tensor([    0.0000,     0.0001,     0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 计算目标token概率的对数\n",
        "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
        "\n",
        "# 打印结果\n",
        "print(log_probas)"
      ],
      "metadata": {
        "id": "Q9PEZM36KPaF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b684f6a8-5d56-46eb-96d3-cce1abf7167c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算对数概率的平均值\n",
        "avg_log_probas = torch.mean(log_probas)\n",
        "\n",
        "# 打印结果\n",
        "print(avg_log_probas)"
      ],
      "metadata": {
        "id": "uY-pBo7yK0rB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcd04b4b-d549-45cf-dfff-38c76146d7f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-10.7940)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 将平均对数概率取反\n",
        "neg_avg_log_probas = avg_log_probas * -1\n",
        "\n",
        "# 打印结果\n",
        "print(neg_avg_log_probas)"
      ],
      "metadata": {
        "id": "Xt_KzyKXLNqL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c425dcaa-7c48-4383-fd71-d7b7f97d8f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.7940)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Logits shape:\", logits.shape)\n",
        "print(\"Targets shape:\", targets.shape)"
      ],
      "metadata": {
        "id": "NjvkmlYYLVA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43889437-c4c4-4a82-cb80-57ced30d5778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits shape: torch.Size([2, 3, 50257])\n",
            "Targets shape: torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 将logits张量展平\n",
        "logits_flat = logits.flatten(0, 1)\n",
        "\n",
        "# 将targets张量展平\n",
        "targets_flat = targets.flatten()\n",
        "\n",
        "# 打印展平后的logits形状\n",
        "print(\"Flattened logits:\", logits_flat.shape)\n",
        "\n",
        "# 打印展平后的targets形状\n",
        "print(\"Flattened targets:\", targets_flat.shape)"
      ],
      "metadata": {
        "id": "T-n5iq9xLYo8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adfbb272-97a1-45ab-f958-e3c8cf35d8a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flattened logits: torch.Size([6, 50257])\n",
            "Flattened targets: torch.Size([6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算交叉熵损失\n",
        "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "UvLEjQzQLgXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a4fb56-bd93-4c3e-f45b-5da6365e1eee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.7940)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1.3  Calculating the training and validation set losses"
      ],
      "metadata": {
        "id": "XaRiLNAUOR1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义文件路径\n",
        "file_path = \"the-verdict.txt\"\n",
        "\n",
        "# 以只读模式打开文件，指定编码为UTF-8\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    # 读取文件内容\n",
        "    text_data = file.read()"
      ],
      "metadata": {
        "id": "5GpWRTzPLpJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算文本数据的字符总数\n",
        "total_characters = len(text_data)\n",
        "\n",
        "# 计算文本数据的token总数\n",
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "\n",
        "# 打印字符总数\n",
        "print(\"Characters:\", total_characters)\n",
        "\n",
        "# 打印token总数\n",
        "print(\"Tokens:\", total_tokens)"
      ],
      "metadata": {
        "id": "yuw58i3lOdan",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa9aa34e-f294-4b60-c7f2-439733d93e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Characters: 20479\n",
            "Tokens: 5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义训练集比例\n",
        "train_ratio = 0.90\n",
        "\n",
        "# 计算分割索引\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "\n",
        "# 分割为训练集和验证集\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]"
      ],
      "metadata": {
        "id": "mVHuEoahOkRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from chapter02 import create_dataloader_v1\n",
        "\n",
        "# 设置随机种子，确保结果可复现\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 创建训练集的数据加载器\n",
        "train_loader = create_dataloader_v1(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "# 创建验证集的数据加载器\n",
        "val_loader = create_dataloader_v1(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "QPe6PdvmOqVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 打印训练集数据加载器的批次形状\n",
        "print(\"Train loader:\")\n",
        "for x, y in train_loader:\n",
        "    print(x.shape, y.shape)\n",
        "\n",
        "# 打印验证集数据加载器的批次形状\n",
        "print(\"\\nValidation loader:\")\n",
        "for x, y in val_loader:\n",
        "    print(x.shape, y.shape)"
      ],
      "metadata": {
        "id": "mVALvrljPAfJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb36b75f-c66e-4e9c-84d8-5e6591d53960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "\n",
            "Validation loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    # 将输入数据和目标数据移动到指定设备（如GPU）\n",
        "    input_batch = input_batch.to(device)\n",
        "    target_batch = target_batch.to(device)\n",
        "\n",
        "    # 获取模型的输出logits\n",
        "    logits = model(input_batch)\n",
        "\n",
        "    # 计算交叉熵损失\n",
        "    loss = torch.nn.functional.cross_entropy(\n",
        "        logits.flatten(0, 1),  # 展平logits张量\n",
        "        target_batch.flatten()  # 展平目标张量\n",
        "    )\n",
        "\n",
        "    # 返回损失\n",
        "    return loss"
      ],
      "metadata": {
        "id": "nR9xDf1DPIPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    # 初始化总损失\n",
        "    total_loss = 0\n",
        "\n",
        "    # 处理空数据加载器的情况\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "\n",
        "    # 确定要处理的批次数量\n",
        "    if num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "    # 遍历数据加载器中的批次\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            # 计算单个批次的损失\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            # 累加损失\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # 返回平均损失\n",
        "    return total_loss / num_batches"
      ],
      "metadata": {
        "id": "Kiv_cbpwf-o9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# 检查是否有CUDA支持的GPU，否则使用CPU\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# 将模型移动到指定设备\n",
        "model.to(device)\n",
        "\n",
        "# 禁用梯度跟踪，提高性能并减少内存占用\n",
        "with torch.no_grad():\n",
        "    # 计算训练集的损失\n",
        "    train_loss = calc_loss_loader(train_loader, model, device)\n",
        "    # 计算验证集的损失\n",
        "    val_loss = calc_loss_loader(val_loader, model, device)\n",
        "\n",
        "# 打印训练集损失\n",
        "print(\"Training loss:\", train_loss)\n",
        "# 打印验证集损失\n",
        "print(\"Validation loss:\", val_loss)"
      ],
      "metadata": {
        "id": "toSzmlBLgIi2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df76e950-a4d5-4d12-ac76-9ff1a2a56657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 10.987583584255642\n",
            "Validation loss: 10.98110580444336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2  Training an LLM"
      ],
      "metadata": {
        "id": "3Q-KF-FXYqVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_simple(\n",
        "    model, train_loader, val_loader,\n",
        "    optimizer, device, num_epochs,\n",
        "    eval_freq, eval_iter, start_context, tokenizer\n",
        "):\n",
        "    # 初始化损失列表和token统计\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # 主训练循环\n",
        "    for epoch in range(num_epochs):\n",
        "        # 设置模型为训练模式\n",
        "        model.train()\n",
        "        # 遍历训练集\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            # 更新全局步数\n",
        "            global_step += 1\n",
        "            # 重置梯度\n",
        "            optimizer.zero_grad()\n",
        "            # 计算损失\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            # 反向传播\n",
        "            loss.backward()\n",
        "            # 更新模型参数\n",
        "            optimizer.step()\n",
        "            # 更新已处理的token数\n",
        "            tokens_seen += input_batch.numel()\n",
        "\n",
        "            # 定期评估模型\n",
        "            if global_step % eval_freq == 0:\n",
        "                # 评估模型\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter\n",
        "                )\n",
        "                # 记录损失\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                # 打印损失\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, \"\n",
        "                      f\"Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # 生成并打印示例文本\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    # 返回训练历史\n",
        "    return train_losses, val_losses, track_tokens_seen"
      ],
      "metadata": {
        "id": "iCAsa56bgQPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    # 禁用梯度计算，提高性能并减少内存占用\n",
        "    with torch.no_grad():\n",
        "        # 计算训练集的损失\n",
        "        train_loss = calc_loss_loader(\n",
        "            train_loader, model, device, num_batches=eval_iter\n",
        "        )\n",
        "        # 计算验证集的损失\n",
        "        val_loss = calc_loss_loader(\n",
        "            val_loader, model, device, num_batches=eval_iter\n",
        "        )\n",
        "\n",
        "    # 设置模型为评估模式\n",
        "    model.eval()\n",
        "\n",
        "    # 返回训练集和验证集的损失\n",
        "    return train_loss, val_loss"
      ],
      "metadata": {
        "id": "dnDTitZpY6Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    # 设置模型为评估模式\n",
        "    model.eval()\n",
        "\n",
        "    # 获取模型的上下文大小\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "\n",
        "    # 将起始文本编码为token ID\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "\n",
        "    # 禁用梯度计算\n",
        "    with torch.no_grad():\n",
        "        # 生成文本\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model,\n",
        "            idx=encoded,\n",
        "            max_new_tokens=50,\n",
        "            context_size=context_size\n",
        "        )\n",
        "\n",
        "    # 将token ID解码为文本\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "\n",
        "    # 打印生成的文本（去除换行符）\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))\n",
        "\n",
        "    # 设置模型为训练模式\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "B7HBOCA4ZH-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置随机种子，确保结果可复现\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 初始化模型\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "\n",
        "# 将模型移动到指定设备（如GPU）\n",
        "model.to(device)\n",
        "\n",
        "# 初始化优化器\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=0.0004,\n",
        "    weight_decay=0.1\n",
        ")\n",
        "\n",
        "# 定义训练轮次\n",
        "num_epochs = 10\n",
        "\n",
        "# 开始训练模型\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer,\n",
        "    device,\n",
        "    num_epochs=num_epochs,\n",
        "    eval_freq=5,\n",
        "    eval_iter=5,\n",
        "    start_context=\"Every effort moves you\",\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "6NT7RVSGZSsp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da5204f2-60ff-47e1-addc-82c661d01567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 9.831, Val loss 9.968\n",
            "Ep 1 (Step 000005): Train loss 7.981, Val loss 8.328\n",
            "Every effort moves you,,,,,,,,,,,,.                                     \n",
            "Ep 2 (Step 000010): Train loss 6.776, Val loss 7.069\n",
            "Ep 2 (Step 000015): Train loss 6.076, Val loss 6.575\n",
            "Every effort moves you, and, and, and, and, and, and, and. \", and, and, and, and, and, and the, and, and, and, and, and, and, and, and, and, and\n",
            "Ep 3 (Step 000020): Train loss 5.495, Val loss 6.632\n",
            "Ep 3 (Step 000025): Train loss 5.154, Val loss 6.349\n",
            "Every effort moves you                                                  \n",
            "Ep 4 (Step 000030): Train loss 4.532, Val loss 6.341\n",
            "Ep 4 (Step 000035): Train loss 3.964, Val loss 6.153\n",
            "Every effort moves you know it was, and I felt--I to the picture. \"Oh, I was a little--and, I had been, and I was his the, and I had been the, and of his pictures--and it's the of\n",
            "Ep 5 (Step 000040): Train loss 3.999, Val loss 6.133\n",
            "Every effort moves you know it was not that, and in a little the fact of the of a little: \"Yes, with a little of the fact, in the of his pictures--I had always--his, and of Jack's \"There, I was his\n",
            "Ep 6 (Step 000045): Train loss 3.312, Val loss 6.129\n",
            "Ep 6 (Step 000050): Train loss 2.501, Val loss 6.130\n",
            "Every effort moves you know,\" was not that my dear, and he had been the his painting.                                  \n",
            "Ep 7 (Step 000055): Train loss 2.239, Val loss 6.175\n",
            "Ep 7 (Step 000060): Train loss 1.490, Val loss 6.227\n",
            "Every effort moves you?\"  \"Yes--I glanced after him, so a little: \"There: make yourself comfortable--and here are the cigars you like.\"    \"I had been the honour being _mine_--because he didn't want\n",
            "Ep 8 (Step 000065): Train loss 1.298, Val loss 6.246\n",
            "Ep 8 (Step 000070): Train loss 0.836, Val loss 6.278\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the fact with a laugh: \"Yes--and by me!\"  He laughed again, and threw back his head to look up at the honour being _mine_--oh, and in his\n",
            "Ep 9 (Step 000075): Train loss 0.847, Val loss 6.318\n",
            "Ep 9 (Step 000080): Train loss 0.463, Val loss 6.437\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the fact with equanimity.        He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
            "Ep 10 (Step 000085): Train loss 0.517, Val loss 6.418\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    # 创建图形和子图\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # 绘制训练损失和验证损失随训练轮次的变化\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"--\", label=\"Validation loss\")\n",
        "\n",
        "    # 设置x轴标签\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    # 设置y轴标签\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    # 设置图例位置\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    # 设置x轴为整数刻度\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "\n",
        "    # 创建第二个x轴，共享y轴\n",
        "    ax2 = ax1.twiny()\n",
        "    # 绘制处理token数的不可见曲线，用于对齐刻度\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
        "    # 设置第二个x轴标签\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    # 自动调整子图布局\n",
        "    fig.tight_layout()\n",
        "    # 显示图形\n",
        "    plt.show()\n",
        "\n",
        "# 创建训练轮次的张量\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "\n",
        "# 调用plot_losses函数绘制损失曲线\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ],
      "metadata": {
        "id": "1CgtUDOJZaSQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "41248e9f-d1bf-4a2e-a0ff-ce455f73d7f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAV/VJREFUeJzt3Xd4FFXbwOHfbnpPCKmQhAAxhd5LaEo0IKIURTEfgmIlCIgFbAgoIoiIoC9YXsFXqiggSg0dQotAIEAIndCS0EMS0nbP98fChqWZQMJuwnNf11w7M+fszLMHss/OnDMzGqWUQgghhBAWSWvuAIQQQghxe5KohRBCCAsmiVoIIYSwYJKohRBCCAsmiVoIIYSwYJKohRBCCAsmiVoIIYSwYJKohRBCCAsmiVoIIYSwYJKohagAjh49ikajITEx0dyhCCFKmSRqISyERqO54zR8+HBzhyiEMANrcwcghDA4ffq0cX7OnDkMGzaMlJQU4zpnZ2dzhCWEMDM5ohbCQvj6+honNzc3NBqNcdnb25vx48dTtWpV7OzsqF+/PkuXLr3ttnQ6HS+99BJhYWGkpqYC8Oeff9KwYUPs7e2pXr06I0aMoLCw0PgejUbDTz/9RNeuXXF0dCQkJISFCxcayy9cuEBMTAxeXl44ODgQEhLC1KlTbxvD77//Tp06dXBwcMDT05OoqCiys7ON5T/99BPh4eHY29sTFhbGf/7zH5P3Hz9+nB49euDu7k6lSpV46qmnOHr0qLG8T58+dOnShXHjxuHn54enpyexsbEUFBQUu82FKBeUEMLiTJ06Vbm5uRmXx48fr1xdXdWsWbPUvn371HvvvadsbGzU/v37lVJKHTlyRAFqx44dKjc3V3Xt2lU1aNBAZWRkKKWUWrdunXJ1dVXTpk1Thw4dUsuXL1fVqlVTw4cPN+4DUFWrVlUzZ85UBw4cUAMGDFDOzs7q3LlzSimlYmNjVf369VVCQoI6cuSIiouLUwsXLrxl/KdOnVLW1tZq/Pjx6siRI2rXrl3qu+++U5cvX1ZKKTV9+nTl5+en/vjjD3X48GH1xx9/qEqVKqlp06YppZTKz89X4eHh6qWXXlK7du1Se/fuVc8//7wKDQ1VeXl5SimlevfurVxdXdXrr7+ukpOT1V9//aUcHR3VDz/8ULr/GEKYmSRqISzQjYna399fjRo1yqROkyZNVL9+/ZRSRYl6/fr1qn379qpVq1bq4sWLxrrt27dXn3/+ucn7f/31V+Xn52dcBtRHH31kXM7KylKAWrJkiVJKqc6dO6sXX3yxWPFv27ZNAero0aO3LK9Ro4aaOXOmybpPP/1UtWjRwhhbaGio0uv1xvK8vDzl4OCgli1bppQyJOqgoCBVWFhorPPMM8+oZ599tlgxClFeSB+1EBYuMzOTU6dOERkZabI+MjKSnTt3mqzr2bMnVatWZdWqVTg4OBjX79y5k/j4eEaNGmVcp9PpyM3NJScnB0dHRwDq1q1rLHdycsLV1ZWMjAwA3njjDbp378727dt57LHH6NKlCy1btrxlzPXq1aN9+/bUqVOH6OhoHnvsMZ5++mk8PDzIzs7m0KFD9O3bl1deecX4nsLCQtzc3IzxHjx4EBcXF5Pt5ubmcujQIeNyrVq1sLKyMi77+fmRlJR0h9YUovyRRC1EBfL4448zffp0Nm3axCOPPGJcn5WVxYgRI+jWrdtN77G3tzfO29jYmJRpNBr0ej0AHTt25NixYyxevJi4uDjat29PbGws48aNu2mbVlZWxMXFsXHjRpYvX86kSZP48MMP2bJli/FHwY8//kizZs1uet+1eBs1asSMGTNu2raXl1ex4hWiopBELYSFc3V1xd/fn/j4eNq2bWtcHx8fT9OmTU3qvvHGG9SuXZsnn3ySRYsWGes3bNiQlJQUataseU+xeHl50bt3b3r37k3r1q159913b5mowZA0IyMjiYyMZNiwYQQFBTF//nwGDx6Mv78/hw8fJiYm5pbvbdiwIXPmzMHb2xtXV9d7ilmI8k4StRDlwLvvvssnn3xCjRo1qF+/PlOnTiUxMfGWR5xvvvkmOp2OJ554giVLltCqVSuGDRvGE088QWBgIE8//TRarZadO3eye/duPvvss2LFMGzYMBo1akStWrXIy8vj77//Jjw8/JZ1t2zZwsqVK3nsscfw9vZmy5YtnDlzxlh/xIgRDBgwADc3Nzp06EBeXh7//PMPFy5cYPDgwcTExPDll1/y1FNPMXLkSKpWrcqxY8eYN28e7733HlWrVr37xhSinJFELUQ5MGDAAC5dusTbb79NRkYGERERLFy4kJCQkFvWHzRoEHq9nscff5ylS5cSHR3N33//zciRIxkzZgw2NjaEhYXx8ssvFzsGW1tb3n//fY4ePYqDgwOtW7dm9uzZt6zr6urKunXrmDBhApmZmQQFBfHVV1/RsWNHAF5++WUcHR358ssveffdd3FycqJOnToMGjQIAEdHR9atW8eQIUPo1q0bly9fpkqVKrRv316OsMUDR6OUUuYOQgghhBC3Jjc8EUIIISyYJGohhBDCgkmiFkIIISyYJGohhBDCgkmiFkIIISyYJGohhBDCgkmivo3vvvuOatWqYW9vT7Nmzdi6dau5Q7II69ato3Pnzvj7+6PRaFiwYIFJuVKKYcOG4efnh4ODA1FRURw4cMCkzvnz54mJicHV1RV3d3f69u1LVlaWSZ1du3bRunVr7O3tCQgIYOzYsTfFMnfuXMLCwrC3t6dOnTosXry41D/v/TR69GiaNGmCi4sL3t7edOnSxeR51GC413VsbCyenp44OzvTvXt30tPTTeqkpqbSqVMnHB0d8fb25t133zV5nCXAmjVraNiwIXZ2dtSsWZNp06bdFE9F/BuYPHkydevWxdXVFVdXV1q0aMGSJUuM5dK+peuLL75Ao9EYr48HaeO7YuaHglik2bNnK1tbW/Xzzz+rPXv2qFdeeUW5u7ur9PR0c4dmdosXL1YffvihmjdvngLU/PnzTcq/+OIL5ebmphYsWKB27typnnzySRUcHKyuXLlirNOhQwdVr149tXnzZrV+/XpVs2ZN1bNnT2P5pUuXlI+Pj4qJiVG7d+9Ws2bNUg4ODur777831omPj1dWVlZq7Nixau/eveqjjz5SNjY2KikpqczboKxER0erqVOnqt27d6vExET1+OOPq8DAQJWVlWWs8/rrr6uAgAC1cuVK9c8//6jmzZurli1bGssLCwtV7dq1VVRUlNqxY4davHixqly5snr//feNdQ4fPqwcHR3V4MGD1d69e9WkSZOUlZWVWrp0qbFORf0bWLhwoVq0aJHav3+/SklJUR988IGysbFRu3fvVkpJ+5amrVu3qmrVqqm6deuqgQMHGtdLG5ecJOpbaNq0qYqNjTUu63Q65e/vr0aPHm3GqCzPjYlar9crX19f9eWXXxrXXbx4UdnZ2alZs2YppZTau3evAlRCQoKxzpIlS5RGo1EnT55USin1n//8R3l4eBifO6yUUkOGDFGhoaHG5R49eqhOnTqZxNOsWTP12muvlepnNKeMjAwFqLVr1yqlDG1pY2Oj5s6da6yTnJysALVp0yallOGHlFarVWlpacY6kydPVq6ursb2fO+991StWrVM9vXss8+q6Oho4/KD9Dfg4eGhfvrpJ2nfUnT58mUVEhKi4uLiVNu2bY2JWtr47sip7xvk5+ezbds2oqKijOu0Wi1RUVFs2rTJjJFZviNHjpCWlmbSdm5ubjRr1szYdps2bcLd3Z3GjRsb60RFRaHVatmyZYuxTps2bbC1tTXWiY6OJiUlhQsXLhjrXL+fa3Uq0r/RpUuXAKhUqRIA27Zto6CgwORzh4WFERgYaNK+derUwcfHx1gnOjqazMxM9uzZY6xzp7Z7UP4GdDods2fPJjs7mxYtWkj7lqLY2Fg6dep0UztIG98dudf3Dc6ePYtOpzP5TwLg4+PDvn37zBRV+ZCWlgZwy7a7VpaWloa3t7dJubW1NZUqVTKpExwcfNM2rpV5eHiQlpZ2x/2Ud3q9nkGDBhEZGUnt2rUBw2e3tbXF3d3dpO6N7XurdrlWdqc6mZmZXLlyhQsXLlTov4GkpCRatGhBbm4uzs7OzJ8/n4iICBITE6V9S8Hs2bPZvn07CQkJN5XJ/+G7I4laCAsUGxvL7t272bBhg7lDqXBCQ0NJTEzk0qVL/P777/Tu3Zu1a9eaO6wK4fjx4wwcOJC4uDiT55yLeyOnvm9QuXJlrKysbhqFmJ6ejq+vr5miKh+utc+d2s7X15eMjAyT8sLCQs6fP29S51bbuH4ft6tTEf6N+vfvz99//83q1atNHufo6+tLfn4+Fy9eNKl/Y/vebdu5urri4OBQ4f8GbG1tqVmzJo0aNWL06NHUq1ePb775Rtq3FGzbto2MjAwaNmyItbU11tbWrF27lokTJ2JtbY2Pj4+08V2QRH0DW1tbGjVqxMqVK43r9Ho9K1eupEWLFmaMzPIFBwfj6+tr0naZmZls2bLF2HYtWrTg4sWLbNu2zVhn1apV6PV6mjVrZqyzbt06CgoKjHXi4uIIDQ3Fw8PDWOf6/VyrU57/jZRS9O/fn/nz57Nq1aqbTv83atQIGxsbk8+dkpJCamqqSfsmJSWZ/BiKi4vD1dWViIgIY507td2D9jeg1+vJy8uT9i0F7du3JykpicTEROPUuHFjYmJijPPSxnfB3KPZLNHs2bOVnZ2dmjZtmtq7d6969dVXlbu7u8koxAfV5cuX1Y4dO9SOHTsUoMaPH6927Nihjh07ppQyXJ7l7u6u/vzzT7Vr1y711FNP3fLyrAYNGqgtW7aoDRs2qJCQEJPLsy5evKh8fHxUr1691O7du9Xs2bOVo6PjTZdnWVtbq3Hjxqnk5GT1ySeflPvLs9544w3l5uam1qxZo06fPm2ccnJyjHVef/11FRgYqFatWqX++ecf1aJFC9WiRQtj+bVLWx577DGVmJioli5dqry8vG55acu7776rkpOT1XfffXfLS1sq4t/A0KFD1dq1a9WRI0fUrl271NChQ5VGo1HLly9XSkn7loXrR30rJW18NyRR38akSZNUYGCgsrW1VU2bNlWbN282d0gWYfXq1Qq4aerdu7dSynCJ1scff6x8fHyUnZ2dat++vUpJSTHZxrlz51TPnj2Vs7OzcnV1VS+++KK6fPmySZ2dO3eqVq1aKTs7O1WlShX1xRdf3BTLb7/9ph566CFla2uratWqpRYtWlRmn/t+uFW7Amrq1KnGOleuXFH9+vVTHh4eytHRUXXt2lWdPn3aZDtHjx5VHTt2VA4ODqpy5crq7bffVgUFBSZ1Vq9ererXr69sbW1V9erVTfZxTUX8G3jppZdUUFCQsrW1VV5eXqp9+/bGJK2UtG9ZuDFRSxuXnEYppcxzLC+EEEKIfyN91EIIIYQFk0QthBBCWDBJ1EIIIYQFk0QthBBCWDBJ1EIIIYQFk0QthBBCWDBJ1HeQl5fH8OHDycvLM3coFZK0b9mS9i170sZlS9rXQK6jvoPMzEzc3Ny4dOkSrq6u5g6nwpH2LVvSvmVP2rhsSfsayBG1EEIIYcEkUQshhBAWrMI/j7qwsJAdO3bg4+ODVluy3yWXL18G4OTJk2RmZpZFeA80ad+yJe1b9qSNy1ZFbl+9Xk96ejoNGjTA2vrOqbjC91EnJCTQtGlTc4chhBBC3GTr1q00adLkjnUq/BG1j48PYGgMPz8/M0cjhBBCwOnTp2natKkxR91JhU/U1053+/n5UbVqVTNHI4QQQhQpTpesDCYTQgghLJhZE/W6devo3Lkz/v7+aDQaFixYYFKulGLYsGH4+fnh4OBAVFQUBw4cME+wQgghhBmYNVFnZ2dTr149vvvuu1uWjx07lokTJzJlyhS2bNmCk5MT0dHR5Obm3udIhRBCCPMwax91x44d6dix4y3LlFJMmDCBjz76iKeeegqA//3vf/j4+LBgwQKee+65+xmqEOIBodPpKCgoMHcYopyzsbHBysqqVLZlsYPJjhw5QlpaGlFRUcZ1bm5uNGvWjE2bNt02Uefl5ZncF/badXhCCHEnSinS0tK4ePGiuUMRFYS7uzu+vr5oNJp72o7FJuq0tDSAm4au+/j4GMtuZfTo0YwYMaJsgtIVwqqRUL0d1HikbPYhhDCLa0na29sbR0fHe/5yFQ8upRQ5OTlkZGQA3POlwRabqO/W+++/z+DBg43LJ0+eJCIionQ2vmUyxH8DO6bDa+vATS73EqIi0Ol0xiTt6elp7nBEBeDg4ABARkYG3t7e93Qa3GIvz/L19QUgPT3dZH16erqx7Fbs7OxwdXU1Ti4uLqUSz6UrBQw+0oR9muqQcw5+6w2F+aWybSGEeV3rk3Z0dDRzJKIiufb/6V7HPFhsog4ODsbX15eVK1ca12VmZrJlyxZatGhx3+Ox1mr45+QVXs4dQI7WGU7+A8s/vO9xCCHKjpzuFqWptP4/mTVRZ2VlkZiYSGJiImAYQJaYmEhqaioajYZBgwbx2WefsXDhQpKSknjhhRfw9/enS5cu9z1WJztrxj1Tj5N4E5v7hmHl1h9g12/3PRYhhBAPDrMm6n/++YcGDRrQoEEDAAYPHkyDBg0YNmwYAO+99x5vvvkmr776Kk2aNCErK4ulS5dib29vlnibBlfi1dbVWa1vwE+a7oaVfw2E9L1miUcIIcpCtWrVmDBhQrHrr1mzBo1GU+Yj5qdNm4a7u3uZ7sMSmXUwWbt27bjTw7s0Gg0jR45k5MiR9zGqO3vr0YdYnZLB5+ldaelxlPDCZDQXjoJPKQ1YE0KIYvq3U6uffPIJw4cPL/F2ExIScHJyKnb9li1bcvr0adzc3Eq8L/HvKtyo77Jmb2PF+B716fJdPDEXXuHLjn5EhbUzd1hCiAfQ6dOnjfNz5sxh2LBhpKSkGNc5Ozsb55VS6HS6f332MYCXl1eJ4rC1tb3jIF9xbyx2MJklq13FjYHtQ7iAK2+tzuP0pSuGgsK8O79RCCFKka+vr3Fyc3NDo9EYl/ft24eLiwtLliyhUaNG2NnZsWHDBg4dOsRTTz2Fj48Pzs7ONGnShBUrVphs98ZT3xqNhp9++omuXbvi6OhISEgICxcuNJbfeOr72inqZcuWER4ejrOzMx06dDD5YVFYWMiAAQNwd3fH09OTIUOG0Lt37xKPQZo8eTI1atTA1taW0NBQfv31V2OZUorhw4cTGBiInZ0d/v7+DBgwwFj+n//8h5CQEOzt7fHx8eHpp58u0b7vF0nUd+mNdjWoF+DO5dxC3vt9F+rYRpjYEI5tNHdoQohSoJQiJ7/QLNOdugRLaujQoXzxxRckJydTt25dsrKyePzxx1m5ciU7duygQ4cOdO7cmdTU1DtuZ8SIEfTo0YNdu3bx+OOPExMTw/nz529bPycnh3HjxvHrr7+ybt06UlNTeeedd4zlY8aMYcaMGUydOpX4+HgyMzNvejDTv5k/fz4DBw7k7bffZvfu3bz22mu8+OKLrF69GoA//viDr7/+mu+//54DBw6wYMEC6tSpAxjGSA0YMICRI0eSkpLC0qVLadOmTYn2f7/Iqe+7ZG2lZXyPenSauJ71B85yWDeLGpknYG4feG09uPz7w8CFEJbrSoGOiGHLzLLvvSOjcbQtna/nkSNH8uijjxqXK1WqRL169YzLn376KfPnz2fhwoX079//ttvp06cPPXv2BODzzz9n4sSJbN26lQ4dOtyyfkFBAVOmTKFGjRoA9O/f32S80aRJk3j//ffp2rUrAN9++y2LFy8u0WcbN24cffr0oV+/foBhQPLmzZsZN24cDz/8MKmpqfj6+hIVFYWNjQ2BgYE0bdoUgNTUVJycnHjiiSdwcXEhKCjIOLDZ0sgR9T2o4eXM0A5hADx9vDv5lUIhKx1+f9Fwu1EhhDCzxo0bmyxnZWXxzjvvEB4ejru7O87OziQnJ//rEXXdunWN805OTri6uhpvkXkrjo6OxiQNhttoXqt/6dIl0tPTjUkTwMrKikaNGpXosyUnJxMZGWmyLjIykuTkZACeeeYZrly5QvXq1XnllVeYP38+hYWG7+ZHH32UoKAgqlevTq9evZgxYwY5OTkl2v/9IkfU9+iFFtVYvjedjYfOMZi3mWT7Nppj8bByBDz2qbnDE0LcJQcbK/aOjDbbvkvLjaO333nnHeLi4hg3bhw1a9bEwcGBp59+mvz8O99p0cbGxmRZo9Gg1+tLVL80T+kXR0BAACkpKaxYsYK4uDj69evHl19+ydq1a3FxcWH79u2sWbOG5cuXM2zYMIYPH05CQoLFXQImR9T3SKvV8OUz9XCxs+bvU84srfmxoWDjRNi78M5vFkJYLI1Gg6OttVmmsrxDWnx8PH369KFr167UqVMHX19fjh49Wmb7uxU3Nzd8fHxISEgwrtPpdGzfvr1E2wkPDyc+Pt5kXXx8vMnzHRwcHOjcuTMTJ05kzZo1bNq0iaSkJACsra2Jiopi7Nix7Nq1i6NHj7Jq1ap7+GRlQ46oS0EVdwc+ebIW78zdyYCdAWxu9Cqeu36ABf3ApxZ41vj3jQghxH0QEhLCvHnz6Ny5MxqNho8//viOR8Zl5c0332T06NHUrFmTsLAwJk2axIULF0r0I+Xdd9+lR48eNGjQgKioKP766y/mzZtnHMU+bdo0dDodzZo1w9HRkenTp+Pg4EBQUBB///03hw8fpk2bNnh4eLB48WL0ej2hoaFl9ZHvmhxRl5LuDavwWIQPBTrFC8c6og9oATXbg7O3uUMTQgij8ePH4+HhQcuWLencuTPR0dE0bNjwvscxZMgQevbsyQsvvECLFi1wdnYmOjq6RHee7NKlC9988w3jxo2jVq1afP/990ydOpV27doBhudB//jjj0RGRlK3bl1WrFjBX3/9haenJ+7u7sybN49HHnmE8PBwpkyZwqxZs6hVq1YZfeK7p1H3u9PgPjtx4gQBAQEcP36cqlXL9rGUZ7PyiP56Heey8xnY2pe3Hm8IcpN/ISxebm4uR44cITg42Gy3KH7Q6fV6wsPD6dGjB59+WjHG99zp/1VJcpMcUZeiys52jOpquEZv0oY0tqVeMBQoBWlJZoxMCCEsy7Fjx/jxxx/Zv38/SUlJvPHGGxw5coTnn3/e3KFZHEnUpaxDbV+6NayCXsHg33aSk5MFc3vDDw/DiW3mDk8IISyCVqtl2rRpNGnShMjISJKSklixYgXh4eHmDs3iyGCyMvBJ51psOnSOY+dyGL3sCJ8qPegL4LcX4LV14ORp7hCFEMKsAgICbhqxLW5NjqjLgJuDDV8+bbjzz69bUomvNRIq1YDMEzDvZdDrzByhEEKI8kISdRlpFVKZ3i2CAHh74REuPzUNbBzh0CpY84V5gxNCCFFuSKIuQ0M7hlO9shNpmbl8vEkHnb8xFKwbC/vNcw9hIYQQ5Ysk6jLkYGvFuB710GpgQeIpFmtaQ5OXDYV/xkK+Zd5XVgghhOWQRF3GGgZ60K9dTQA+nJ9ERsthEPYEPDsdbB3NHJ0QQghLJ4n6PhjQPoQIP1cu5BTwwcL9qGenQ2Bzc4clhBCiHJBEfR/YWmsZ/2w9bK20rEjOYO4/J4oK0/fC3j/NF5wQ4oHXrl07Bg0aZFyuVq0aEyZMuON7NBoNCxYsuOd9l9Z27mT48OHUr1+/TPdRliRR3ydhvq4MfuwhAEb+vZfj53MgfQ/81B7mvQqnd5k5QiFEedO5c2c6dOhwy7L169ej0WjYtavk3y0JCQm8+uqr9xqeidsly9OnT9OxY8dS3VdFI4n6PnqldXUaB3mQlVfIO3N3oq8cBtVaQWEu/NYLrlw0d4hCiHKkb9++xMXFceLEiZvKpk6dSuPGjalbt26Jt+vl5YWj4/0ZQ+Pr64udnd192Vd5JYn6PrLSaviqRz0cba3YcuQ8UzelQtfvwT0QLhyFuX2gINfcYQohyoknnngCLy8vpk2bZrI+KyuLuXPn0rdvX86dO0fPnj2pUqUKjo6O1KlTh1mzZt1xuzee+j5w4ABt2rTB3t6eiIgI4uLibnrPkCFDeOihh3B0dKR69ep8/PHHFBQUAIbHTY4YMYKdO3ei0WjQaDTGmG889Z2UlMQjjzyCg4MDnp6evPrqq2RlZRnL+/TpQ5cuXRg3bhx+fn54enoSGxtr3Fdx6PV6Ro4cSdWqVbGzs6N+/fosXbrUWJ6fn0///v3x8/PD3t6eoKAgRo8eDYBSiuHDhxMYGIidnR3+/v4MGDCg2Pu+G5Ko77MgTyc+7GS4l+2Ypfs4mGUDPX413Azl8GqY3RMKrpg5SiGEUX727acbf1jfse6V4tUtAWtra1544QWmTZvG9Q9CnDt3Ljqdjp49e5Kbm0ujRo1YtGgRu3fv5tVXX6VXr15s3bq1WPvQ6/V069YNW1tbtmzZwpQpUxgyZMhN9VxcXJg2bRp79+7lm2++4ccff+Trr78G4Nlnn+Xtt9+mVq1anD59mtOnT/Pss8/etI3s7Gyio6Px8PAgISGBuXPnsmLFCvr3729Sb/Xq1Rw6dIjVq1fzyy+/MG3atJt+rNzJN998w1dffcW4cePYtWsX0dHRPPnkkxw4cACAiRMnsnDhQn777TdSUlKYMWMG1apVA+CPP/7g66+/5vvvv+fAgQMsWLCAOnXqFHvfd8Oi7/Wt0+kYPnw406dPJy0tDX9/f/r06cNHH31UooeLW5rnmwayfE86a/efYfBvO/njjZbYxMyFGc8Y7lw2qyf0nAU2DuYOVQjxuf/ty0Ieg5i5Rctf1oSC29wfIagVvLioaHlCHcg5d3O94ZdKFN5LL73El19+ydq1a43PYZ46dSrdu3fHzc0NNzc33nnnHWP9N998k2XLlvHbb7/RtGnTf93+ihUr2LdvH8uWLcPf39AWn3/++U39yh999JFxvlq1arzzzjvMnj2b9957DwcHB5ydnbG2tsbX1/e2+5o5cya5ubn873//w8nJCYBvv/2Wzp07M2bMGHx8fADw8PDg22+/xcrKirCwMDp16sTKlSt55ZVXitVm48aNY8iQITz33HMAjBkzhtWrVzNhwgS+++47UlNTCQkJoVWrVmg0GoKCgozvTU1NxdfXl6ioKGxsbAgMDCxWO94Liz6iHjNmDJMnT+bbb78lOTmZMWPGMHbsWCZNmmTu0O6JRqNhTPe6uDnYsOvEJb5bfdDQVx3zO9g4GRK0xsrcYQohyoGwsDBatmzJzz//DMDBgwdZv349ffv2BQwHPJ9++il16tShUqVKODs7s2zZMlJTU4u1/eTkZAICAoxJGqBFixY31ZszZw6RkZH4+vri7OzMRx99VOx9XL+vevXqGZM0QGRkJHq9npSUFOO6WrVqYWVV9B3p5+dHRkZGsfaRmZnJqVOniIyMNFkfGRlJcnIyYDi9npiYSGhoKAMGDGD58uXGes888wxXrlyhevXqvPLKK8yfP5/CwsISfc6Ssugj6o0bN/LUU0/RqVMnwPArbdasWcU+ZWPJfN3sGflULQbOTuTbVQd5JMybutUioe8yqBwK1rbmDlEIAfDBqduX3fiD+t2Dd6h7w3HRoNJ7Rn3fvn158803+e6775g6dSo1atSgbdu2AHz55Zd88803TJgwgTp16uDk5MSgQYPIz88vtf1v2rSJmJgYRowYQXR0NG5ubsyePZuvvvqq1PZxPRsbG5NljUaDXq8vte03bNiQI0eOsGTJElasWEGPHj2Iiori999/JyAggJSUFFasWEFcXBz9+vUzntG4Ma7SYtFH1C1btmTlypXs378fgJ07d7Jhw4YKM5T/yXr+dKrrR6FeMfi3neQW6MC3TlGSVgq2/FDifishRCmydbr9ZGNfgroOxat7F3r06IFWq2XmzJn873//46WXXjJ2D8bHx/PUU0/xf//3f9SrV4/q1asbv1OLIzw8nOPHj3P69Gnjus2bN5vU2bhxI0FBQXz44Yc0btyYkJAQjh07ZvpxbW3R6e785MDw8HB27txJdnbRd158fDxarZbQ0NBix3wnrq6u+Pv73/SIzfj4eCIiIkzqPfvss/z444/MmTOHP/74g/PnzwPg4OBA586dmThxImvWrGHTpk0kJZXeD68bWfQR9dChQ8nMzCQsLAwrKyt0Oh2jRo0iJibmtu/Jy8sjLy/PuHz58uX7Eepd0Wg0fPZUbbYeOc/BjCxG/LWXz7vWLup/XzEc4icYbogS89td/xELISo2Z2dnnn32Wd5//30yMzPp06ePsSwkJITff/+djRs34uHhwfjx40lPTzdJSncSFRXFQw89RO/evfnyyy/JzMzkww8/NKkTEhJCamoqs2fPpkmTJixatIj58+eb1KlWrRpHjhwhMTGRqlWr4uLictNlWTExMXzyySf07t2b4cOHc+bMGd5880169epl7J8uDe+++y6ffPIJNWrUoH79+kydOpXExERmzJgBwPjx4/Hz86NBgwZotVrmzp2Lr68v7u7uTJs2DZ1OR7NmzXB0dGT69Ok4ODiY9GOXNos+ov7tt9+YMWMGM2fOZPv27fzyyy+MGzeOX3755bbvGT16tHEAhZubW7H/M5qLh5MtY7obRgzO2prKB/N3o9NfHb0Z1glsXeDYBsNAs7ysO2xJCPEg69u3LxcuXCA6OtqkP/mjjz6iYcOGREdH065dO3x9fenSpUuxt6vVapk/fz5XrlyhadOmvPzyy4waNcqkzpNPPslbb71F//79qV+/Phs3buTjjz82qdO9e3c6dOjAww8/jJeX1y0vEXN0dGTZsmWcP3+eJk2a8PTTT9O+fXu+/fbbkjXGvxgwYACDBw/m7bffpk6dOixdupSFCxcSEhICGEawjx07lsaNG9OkSROOHj3K4sWL0Wq1uLu78+OPPxIZGUndunVZsWIFf/31F56enqUa4/U06vox/RYmICCAoUOHEhsba1z32WefMX36dPbt23fL99x4RH3y5EkiIiI4fvw4VatWLfOY79achFSGzktCKehS359xz9TD2koLxxNgejfIy4TAFoYRpnYu5g5XiAolNzeXI0eOEBwcjL29/b+/QYhiuNP/qxMnThAQEFCs3GTRR9Q5OTlotaYhWllZ3XHQgJ2dHa6ursbJxaV8JLVnmwTyzXMNsNZqWJB4in4ztpNXqIOAJtBrAdi5QeommP405Fnu6XwhhBCly6ITdefOnRk1ahSLFi3i6NGjzJ8/n/Hjx9O1a1dzh1Ymnqznz5T/a4SttZble9N5+Zd/uJKvg6qN4IX5hmR9fDPMfBZKcYSjEEIIy2XRiXrSpEk8/fTT9OvXj/DwcN555x1ee+01Pv30U3OHVmaiInyY2qcJDjZWrD9wlhd+3kJmbgFUaQQvLABHT2j8Emgt+p9OCCFEKbHoPurSUJJ+AEuy7dh5+kxN4HJuIXWquPG/l5ri4WQLuZlg72ru8ISoUKSPWpSFB6KP+kHWKKgSs15pTiUnW5JOXuLZHzaRkZlrmqQvnYTfX5KnbgkhRAUmidqC1a7ixpxXm+PtYsf+9Cx6fL+JExeu3kdYKZjbG3b/Ab92lWQtRCkozbtbCVFa/58s+oYnAkJ8XPj99ZY8/9Nmjp7LoceUTcx4pTnBlZ3gia/hlyfh1Hb4tQv0mg8OHuYOWYhyx9bWFq1Wy6lTp/Dy8sLW1rZcP/hHmJdSivz8fM6cOYNWq8XW9t5uCS191OXE6UtXiPlpC4fPZFPZ2Y7pLzclzNcV0nbD/540PIXHr57hUi7HSuYOV4hyJz8/n9OnT5OTc5unXwlRQo6Ojvj5+d0yUZckN0miLkfOZuXR679bST6dibujDb+82JR6Ae6Qvhd+6Qw5Z8G3LrzwpyRrIe6CUorCwsJ/vSe1EP/GysoKa2vr256ZkUR9nYqUqAEu5RTQe+pWEo9fxNnOmv/2bkyz6p6QkWxI1tlnoFZXeGaauUMVQghxGzLquwJzc7Rh+svNaF69Ell5hfSeupW1+8+Adzj0/huCIqHDF+YOUwghRCmRRF0OOdtZM+3Fpjwc6kVugZ6Xf0lg6e408A6DPovAxbeosq5sH2guhBCibEmiLqfsbaz4vldjOtXxo0CniJ25nfk7TsD1/SG7foMf2kHWGbPFKYQQ4t5Ioi7HbK21TOzZgKcbVUWnVwz+bScztlx9WHt+DqwYAelJhr7rYxsN114LIYQoVyRRl3NWWg1ju9eld4sglIIP5+/mh3WHwNbRMPrbxQ/OJMPUjvBtY9gwAS6nmztsIYQQxSSJugLQajUMf7IW/drVAODzxfv4Om4/yrMG9F0ODXqBjROcOwgrPoHx4bB3oZmjFkIIURySqCsIjUbDex3CeDc6FIBvVh5g1KJklFsAPPUtvJMCT06Cqk0M/diBzYvefHoXnD9ipsiFEELcidxCtIKJfbgmTrZWDP9rLz9tOEJ2vo7PutTGys4FGr5gmC6dBGfvojct+wCOrofgNtCwN4Q9ATbyBCEhhLAEkqgroD6RwTjaWjN03i5mbU0lJ7+QsU/Xxc7aylDBrUpR5cJ8sLIFNHBknWGyd4e6z0LDXuBbxxwfQQghxFVy6ruC6tEkgIk9G2Ct1fBn4inaf7WWPxNPotffMPLb2hZ6zYNBu6DtUHALgNyLsPV7mNIK/n7LLPELIYQwkERdgT1R15+fejfG19WeExeuMHB2Il3+E8/mw+duruweCA+/DwN3wv/9ARFdQGsDAc2K6mSfk8u8hBDiPpN7fT8AruTr+Dn+CJPXHCIrz3Cnsqhwb4Z2DKOmt8vt35h9Fmydi/qr4ydC3MfgWdPQ112vp2lf9/VyzkNeJuRnG67pLsgumld6qPdsUd3Nkw1PAcvPgoIcQ53CK4b9VG0C9WMMl5sJIUQFIQ/luI4k6iJns/L4ZsUBZm5NRadXWGk1PNskgEFRIXi7FGPw2JoxEP+NIekCaK2h8kOG5GrrAm9sKKr738fg+JZbb8fWGT44WbT8azc4tPLWda3s4P0ThlP0APsWgcbKkMCdPP89ZiGEsEAlyU0ymOwBUtnZjk+71KZPZDXGLNnH8r3pzNySyoIdJ3mtTQ1eaWMYhHZb7YZAi36wex7s+BVOJEDGXkOZnatpXVsnsHE0TLZORZONI9jdcBRf/3mo1sq0jtYa0ndD3uWiJA2wahRk7DHMe9aEqk0hoInh1TsctFb33lBCCGFB5Ij6Abb1yHlGLU5m5/GLAHi72DH40Yd4pnEAVtpbP0PVxJn9kHnCcDMVWyfwrV1UppTpfcdLg14Pfw2A1M1w7sDN5b514PXrjurzsw1xCSEeDOcOwYWjhr99rZXhB7/WynAWTmttGHNz7Yf/pZOQe6mojrH+1cnBo+iHv14HaEBbesO65NT3dSRR35lSikVJpxm7NIXU8zkAhPq4MPTxMNo95HXbh56bXc55OPEPnNgKx7fCyW2G67+7fW8o1+tgTDXDk8SuP+r2CivVPzYhRBm7eBwupkJWOmRlmL7mnIWXVxX9Tf/2Auz98/bbeu8IOFYyzP81CLZNvX3dt/aA29WcsfQD2Pyd4Tvk5bhS+Vhy6lsUm0aj4Ym6/jwa4cP0zalMXHmAlPTLvDg1gcianrzfMZzaVdzMHebNHCvBQ48ZJjAk5rzLReXnDhoGs+Vlwtn9kDjdsN7OFbwjoEGMYUAcGH5ZL+wPGq1hQlM0r9FAaEdo8H+GujnnYfE7t66n0Rj+kBv1LoqjLM4sCFGe6HVQmGvo0rr2t3Ax1fDMgewzpok3O8MwiLXP4qLku/wj2Lvg9tu/cqFovIpnTfCuZeheUzrQF16d9IZX7XUpz9YJnLyulutMX5XOcBR+jdIZXs3UtSZH1MLEpZwCvltzkGnxR8nX6dFooGv9KrwdHUoVdwdzh1cy2ecM/ejGo+7tRQPh2rwLj3xkmD+zH75rcvvtNI+FDp8b5i+dgK9r3b5uoxeh8wTDfF4WfB0BlWoYvkA8a4JnjaLXG/vqhSgNSoEu3zAV5hsSj4tPUfnZA4YfnNfqGKcCwxUZdXsU1d39B5xJMSTawryi14Irhvo9ZxbVXTIUDiy/Wue6+nrDlSZ8lAHWdob5ea/Crjm3/wzvHgKnyob5uE8g+S9w9jFcZWLy6gPBrcGmlL+brqXFaz8s8nMMn1mjKToiv0dyRC3umpujDR88Hk6v5kGMW57Cn4mnmLfjJH8nnaZvq2DeaFcDV3sbc4dZPE6eENrBMAHoCg2D384fgsqhRfVcfKDLFEAZvqjUtVe9YZ33dYnZ3g06fFFUh+vqKj1UaVxU9/xhQx/Yqe2G6UbN+0GH0Yb5wjw4uNKQxD2qmQ6gE5blxrMkZ/YbzuYUZBu+zPOzDVdCFFwx/H+5PvGtHGk4krx21GY84tMZks61H3kA814znBky1tMX1Xfygr7Liur+r4vhx6guH/QFpvE6VIIh193L/++3DLcMvhUrO9N4d/0G+5fevi10hWB1NY1kZxj+tm6nMLcoUTt5gVugIRnfKgHbXHc55qMjDNP9dONZMFtHs14iavGJ+uTJkwwZMoQlS5aQk5NDzZo1mTp1Ko0bN/73N4u7FlDJkW+ea0DfVsF8vjiZzYfPM3nNIeYkHGfAIzV5vlkQttblrK/Xyhr86hqm69m7Qf2exduGnQs0f6N4db3Dod9mw5etcTpkeM0+Y/hCuubcIZh9NQaNFtyDrjv6rglBkeATYSjPyzJs4/qBL9cPhLFzATtnQ1293vDFrbUuOkVfEen11x3J5RqSpJUtuAcU1Un+27C+8AoU5Jq+ugdC45eK6s75P8NR5/VJ99q8fwN46brkNa2TIUndik8d08S3Z8Htk1ml6qbL6XsMz5O/lfxs0+WCK0Vni2507bTtNa7+4BFsaB9rW8PrtelaIr2mZpShn9ba3lBm7XD11f7mum3eg6avmpZb2xdN1x/1Ro8yTKJYLDpRX7hwgcjISB5++GGWLFmCl5cXBw4cwMPDw9yhPTDqVnVn1ivNWZmcweglyRw6k83wv/YybeNRhnQIo0NtX8sdcGZuVjaGZO0dfnPZlYumywVXwK+eIWHnZ8GFI4bp4ApD+SMfFyXq9N3wc/Tt9/vIR4ZT+9fqft+6qOz65K6xgpZvQturdc8fhp87XpfMr/a7X3tt+AK0fc9QdDndEMPt6tbqCg9/YCjKvWS4rh5uuKvd1fnQjvDoSMN8YT5MbnFdlRt65mo8DJ2+MszrdTA22JBsdXk3t0NINMT8VrT8R19DEr+VoEjTRH1sk2Gg0q3cmCTdqhiSks3Voy7jZYmOhrMj12sRe91I42uT1vBqf8NYkOjPro5evu6H2LXRyzcmye4/GY60ryVbKxvD0bGVzc39qt1+uPXnupWmrxS/rndY8euKErHoRD1mzBgCAgKYOrVoZF5wcLAZI3owaTQaoiJ8aBfqxZx/jvN13AGOnsvhjRnbqR/gzutta/BohE/xLukSBg7upstVG8Fr6wyJKSv95qPwKg2L6mqtwbXKdadNrx8Mc8OAmRuPpq7VuUaXf918IWSl3T7m639c6AsMPyRuJyv9uro6OLPv9nX9G1y3oAyf+Xau/9GjtTL0Hd54qldrffXI74bug2qtDP2qNg5FR3jXjvY8a5jW7TTO8Hp90r02f+PYglfX3D7eGzXpW/y61dsVv+71Zw5EhWPRg8kiIiKIjo7mxIkTrF27lipVqtCvXz9eeaX4v/JkMFnpy8or5Id1h/lx3WGuFBgSQXBlJ15uHUz3hlWxt5GbjlgMvc5wVHZjMr+27OBeNGinIBfOphjmlcLQ/37tFXD2MpwiBkOf+qkdt6mrDJfFVQ4xlOsKDNe+X+/6szBOXuB1dcyAXn/zHe2ur+vgUVQX4OxBQ0K2djDc6tbaoajPVAgLVmGuo7a3N9zWcvDgwTzzzDMkJCQwcOBApkyZQu/evW/5nry8PPLyik6DnTx5koiICEnUZeDM5Tx+2XiU/206Smau4SitsrMtvVtUo1eLINwdZUCUEELcSoVJ1La2tjRu3JiNGzca1w0YMICEhAQ2bdp0y/cMHz6cESNuHiEoibrsZOcVMifhOP/dcISTF68A4GhrRY/GAfRtFUxAJXmghhBCXK8kidqih+36+fkRERFhsi48PJzU1NTbvuf999/n0qVLxmnv3r1lHeYDz8nOmpdaBbPm3XZ881x9IvxcycnXMW3jUdqNW8OAWTvYffKSucMUQohy6a46c44fP45GozH+Cti6dSszZ84kIiKCV199tdSCi4yMJCUlxWTd/v37CQoKuu177OzssLMrGhGZmZlZavGIO7Ox0vJU/So8Wc+fDQfP8sO6w6w/cJaFO0+xcOcpImt68lqbGrQOqSwjxYUQopju6oj6+eefZ/Xq1QCkpaXx6KOPsnXrVj788ENGjhxZasG99dZbbN68mc8//5yDBw8yc+ZMfvjhB2JjY0ttH6L0aTQaWod48WvfZiwa0Iou9f2x0mqIP3iOF37eyuMTNzB/xwkKdHpzhyqEEBbvrvqoPTw82Lx5M6GhoUycOJE5c+YQHx/P8uXLef311zl8+HCpBfj333/z/vvvc+DAAYKDgxk8eLCM+i6HTlzI4ecNR5mdkEpOvmGkuL+bPS+1Cua5poE428lIXSHEg6PMB5M5Ozuze/duqlWrxpNPPklkZCRDhgwhNTWV0NBQrly5ctfBlzZJ1JblUk4B07ccY2r8Uc5mGUbnu9pbE9M8iBdbVsPb1d7MEQohRNkr88FktWrVYsqUKaxfv564uDg6dDDcS/nUqVN4enrezSbFA8LN0YbYh2uyYcjDjO5Wh+qVncjMLWTymkO0GrOaIb/v4mBGlrnDFEIIi3FXiXrMmDF8//33tGvXjp49e1KvXj0AFi5cSNOmTUs1QFEx2dtY0bNpICsGt+WHXo1oFORBvk7PnH+OEzV+LS//ksCiXae5mJP/7xsTQogK7K6vo9bpdGRmZprcd/vo0aM4Ojri7e1dagHeKzn1XX5sO3ae79ceJi453eQpc3WquNGqZmVa1axMo2oe2FnLnc+EEOVbmfdRX7lyBaUUjo6GG1kcO3aM+fPnEx4eTnT0HR4WYAaSqMufQ2eymLUllXUHzrA/3fQ0uL2NlqbBnrSuWZlWIZUJ83WRS72EEOVOmT+P+qmnnqJbt268/vrrXLx4kWbNmmFjY8PZs2cZP348b7xRzMcACnELNbyc+egJw41u0jNz2XDgLPEHz7L+4FnOXM5j3f4zrNt/BjDcsjTy6tF26xAvfN1kMJoQomK5qyPqypUrs3btWmrVqsVPP/3EpEmT2LFjB3/88QfDhg0jOTm5LGK9K3JEXXEopdifnsX6A2fYcPAsWw6fNz4U5Jqa3s7G0+TNa3jKZV9CCItU5kfUOTk5uLgYHvW2fPlyunXrhlarpXnz5hw7duxuNinEv9JoNIT6uhDq68LLrauTV6hjR+pFNhwwHG0nnbjIwYwsDmZkMW3jUay1GhoEutOqphetQipTr6ob1lYWfddcIYS4yV0l6po1a7JgwQK6du3KsmXLeOuttwDIyMjA1dW1VAMU4nbsrK1oXt2T5tU9eSc6lEs5BWw6fJb1B86y4eBZjp3LIeHoBRKOXuDrFftxsbOmeQ1P2oV60bVBFRxt5WhbCGH57urU9++//87zzz+PTqfjkUceIS4uDoDRo0ezbt06lixZUuqB3i059f3gOn4+h/VX+7fjD53lYk6BsczTyZaXW1enV4sgOT0uhLjv7stjLtPS0jh9+jT16tVDqzWcTty6dSuurq6EhYXdzSbLhCRqAaDTK/acusT6A2eZk3Cc1PM5ALg72tA3MpjekdVwtbcxc5RCiAfFfX0e9YkTJwAsNglKohY3KtTpWbjzFN+uOsjhs9kAuNhb82JkMC9FVsPd0dbMEQohKroyv4WoXq9n5MiRuLm5ERQURFBQEO7u7nz66afo9fJEJGHZrK20dGtYlbjBbZnYswEh3s5czi1k4soDtBqzmrFL93Hu6n3IhRDC3O6qc+7DDz/kv//9L1988QWRkZEAbNiwgeHDh5Obm8uoUaNKNUghyoKVVsOT9fx5oo4fy/akMXHVQZJPZ/KfNYeYGn+U/2seyCttquPtItdmCyHM565Offv7+zNlyhSefPJJk/V//vkn/fr14+TJk6UW4L2SU9+iuJRSrEjOYNKqA+w6cQkAO2stPZsG8nrbGnIzFSFEqSnzU9/nz5+/5YCxsLAwzp8/fzebFMLsNBoNj0b48GdsJFNfbEKDQHfyCvVM23iUNmNX89GCJE5etJxHuAohHgx3lajr1avHt99+e9P6b7/9lrp1695zUEKYk0aj4eFQb+a90ZLpfZvRtFol8nV6pm9Opd2Xqxn6xy5Sz+WYO0whxAPirvqox44dS6dOnVixYgUtWrQAYNOmTRw/fpzFixeXaoBCmItGo6FViOHhH5sPn2PSqgPEHzzH7ITjzN12gi71qxD7cA2qezmbO1QhRAV2V0fUbdu2Zf/+/XTt2pWLFy9y8eJFunXrxp49e/j1119LO0YhzK55dU9mvNycP95oQduHvNDpFX9sP0HU+LUMnL2DA+mXzR2iEKKCuufrqK+3c+dOGjZsiE6n+/fK94kMJhNlIfH4Rb5ddYAVyRmA4bnZHWv7EvtwTWr5u5k5OiGEpSvzwWRCPOjqB7jzU+8m/P1mKzrU8kUpWJyURqeJG4j5aTOr92Wg15fab2AhxANMbnIsxD2oXcWNKb0asS8tk+9WH2Jx0mniD54j/uA5ano783KrYLo0qIK9jZW5QxVClFNyRC1EKQjzdWVSzwasfbcdL7cKxtnOmoMZWQydl0TkF6uYsGK/3O1MCHFXStRH3a1btzuWX7x4kbVr10oftXjgXc4tYE7CcabGHzVee21nbbh1ad9WwdT0lpHiQjzISpKbSnTq283tzoNk3NzceOGFF0qySSEqJBd7G15uXZ0+LauxeHcaP60/zK4Tl5i1NZVZW1N5JMybl1sH06K6JxqNxtzhCiEsWKmO+rZEckQtLIFSioSjF/hx/WFWJKdz7a+ulr8rL7cO5om6/thYSU+UEA+KCjvq+4svvkCj0TBo0CBzhyJEiWg0GpoGV+LHFxqzcnBb/q95IPY2WvacyuStOTtpPWY1U9Ye4tKVAnOHKoSwMOUmUSckJPD999/LLUpFuVfdy5nPutRh09D2vPPYQ1R2tiMtM5cvluyjxeiVDF+4h+Pn5RalQgiDcpGos7KyiImJ4ccff8TDw8Pc4QhRKjycbOn/SAjxQx9m7NN1CfVxISdfx7SNR2n75Wr6zdjG9tQL5g5TCGFm5eI66tjYWDp16kRUVBSfffbZHevm5eWRl1d0Gczly3JrR2HZ7Kyt6NE4gGcaVWX9gbP8uP4w6w+cZXFSGouT0mgY6E6fyGC8XezIK9STf23S6cgv1BvXGct0evIKispN1+lNtpFXqMPH1Z7Yh2sSWbOyuZtCCHELFp+oZ8+ezfbt20lISChW/dGjRzNixIgyjkqI0qfRaGjzkBdtHvJiX1om/11/hD8TT7E99SLbU3eU2X4Pnclm46FztHnIi6Edwojwdy2zfQkhSs6iR30fP36cxo0bExcXZ+ybbteuHfXr12fChAm3fM+NR9QnT54kIiJCRn2Lcinjci7/23iMpXvSUEpha22FrbUWu6uTrZUWW2utcZ2ttRZbKyuTdUXrr60rKrex0rB8TzrTNx+jUK/QaKBL/SoMfvQhAio5mvvjC1FhlWTUt0Un6gULFtC1a1esrIpuv6jT6dBoNGi1WvLy8kzKbkUuzxLi3x07l82Xy1L4e9dpAGyttLzQIojYh2vi4WRr5uiEqHgqTKK+fPkyx44dM1n34osvEhYWxpAhQ6hdu/a/bkMStRDFt+vERb5Yso+Nh84B4GJvzRvtavBSZLDcr1yIUlRmdya731xcXG5Kxk5OTnh6ehYrSQshSqZuVXdmvNyMtfvP8MWSfexLu8zYpSn8b+MxBj/6EN0bVcVKK3dSE+J+KheXZwkh7h+NRkO7UG8WD2jN+B71qOLuQFpmLu/9sYsOE9axYm86FnwiTogKx6JPfZcGOfUtxL3JLdDx66ZjfLv6oPHOaU2rVWLo42E0DJT7GghxNyrsLUSFEPefvY0Vr7Spzrr3Hub1tjWws9ay9eh5uv1nI6//uo1DZ7LMHaIQFZokaiFEsbg52DC0Yxir32nHM42qotXA0j1pPPb1Oj6cn0TG5VxzhyhEhSSJWghRIv7uDnz5TD2WDGxD+zBvdHrFjC2ptB27hvHLU8jKKzR3iEJUKJKohRB3JdTXhf/2acKcV5tTP8CdKwU6Jq46SNuxq/ll41HyC/XmDlGICkEStRDinjSr7sn8fi2ZHNOQ4MpOnMvO55OFe3j067Us25Nm7vCEKPckUQsh7plGo6FjHT+Wv9WGT7vUprKzHcfO5fDar9t47dd/SM+U/msh7pYkaiFEqbGx0tKreRBr321H7MM1sNZqWLYnnaiv1jJzSyp6fYW+GlSIMiGJWghR6pzsrHk3Ooy/3mxFvapuXM4r5IP5STz342a5nEuIEpJELYQoM+F+rszrF8nHT0TgaGvF1iPn6fjNer5ddUAGmwlRTJKohRBlykqroW+rYJYNakPbh7zIL9Qzbvl+Ok/awI7UC+YOTwiLJ4laCHFfBFRyZNqLTfjmufpUcrIlJf0y3SZvZMRfe8iWa6+FuC1J1EKI+0aj0fBU/SqsGNyWbg2qoBRMjT/KY1+vY3VKhrnDE8IiSaIWQtx3lZxsGf9sff73UlOqejhw8uIVXpyawMDZOziXlWfu8ISwKJKohRBm0+YhL5a/1YaXWwWj1cCfiaeIGr+WedtPyKM0hbhKErUQwqwcba356IkIFsRGEu7nyoWcAgb/tpMXft7K8fM55g5PCLOTRC2EsAh1q7qzsH8k73UIxdZay/oDZ3ns63X8tP4whTq5lEs8uCRRCyEsho2Vln7tarJsUBuaV6/ElQIdny1Kput/NrLn1CVzhyeEWUiiFkJYnODKTsx6pTljutfB1d6apJOXePLbeMYs3Udugc7c4QlxX0miFkJYJI1Gw7NNAlnxdls61fFDp1dMXnOIDhPWsfHgWRlsJh4Y1uYOQAgh7sTbxZ7vYhry1J40hv25h6Pncnj+py1UcrKlblU36lZxo25Vd+oGuOHtYm/ucIUodZKohRDlwmO1fGlRw5OxS1OYnZDK+ex81qScYU3KGWMdPzd7Q/Ku6n41ibvj5mhjxqiFuHcaVcHPH504cYKAgACOHz9O1apVzR2OEKIU5Bbo2Jd2mV0nLrLz+CWSTl7kQEYWt/o2q+bpWJS4q7pTu4orjrZyjCLMqyS5Sf63CiHKHXsbK+oHuFM/wB1aGNZl5xWy++Qldp24xM4TF9l14hKp53M4es4wLdx5CgCtBkK8XQyJO8CdulXcCPNzwc7aynwfSIg7kEQthKgQnOysaVbdk2bVPY3rLubks+vEJcOR99XX9Mw8UtIvk5J+mbnbTgBga6UlzM+QvNs95E37cG80Go25PooQJiw6UY8ePZp58+axb98+HBwcaNmyJWPGjCE0NNTcoQkhygF3R1vaPORFm4e8jOvSM3PZefwiSScvGZP3xZyCqwn9EtM3p9KiuifDn6xFqK+LGaMXwsCi+6g7dOjAc889R5MmTSgsLOSDDz5g9+7d7N27Fycnp2JtQ/qohRB3opTi+Pkr7DxxkX+Onmd2wnHyCvVYaTX0ah7EW48+hJuDDEgTpaskucmiE/WNzpw5g7e3N2vXrqVNmzbFeo8kaiFESRw/n8OoRcks3ZMGgKeTLe91COWZRgFotXI6XJSOkuSmcnXDk0uXDLcQrFSpkpkjEUJUVAGVHJnSqxHT+zajprcz57LzGfJHEl3/E0/i8YvmDk88gMpNotbr9QwaNIjIyEhq165923p5eXlkZmYap8uXL9/HKIUQFUWrkMosGdiajzqF42xnzc4Tl+jyXTzv/b6Ts/LMbHEflZtEHRsby+7du5k9e/Yd640ePRo3NzfjFBERcZ8iFEJUNDZWWl5uXZ1V77Sle0PD6cnf/jnBw+PW8POGIxTIU73EfVAu+qj79+/Pn3/+ybp16wgODr5j3by8PPLyin7tnjx5koiICOmjFkLcs23HLjB84R6SThq64R7ycWb4k7VoWaOymSMT5U2F6aNWStG/f3/mz5/PqlWr/jVJA9jZ2eHq6mqcXFzk8gohROloFOTBgthIPu9aBw9HG/anZ/H8j1uInbGdkxevmDs8UUFZdKKOjY1l+vTpzJw5ExcXF9LS0khLS+PKFfmDEEKYh5VWw/PNAln9TjteaBGEVgOLkk7T/qs1TFp5QB7DKUqdRZ/6vt2dgaZOnUqfPn2KtQ25PEsIUZb2nspk+MI9bD16HoDASo58/EQEUXJ3M3EHFeZe3xb8G0IIIQCI8HdlzmvNWbjzFJ8vTib1fA6v/O8f2j7kxSedI6ju5WzuEEU5Z9GnvoUQojzQaDQ8Vb8Kq95ux+tta2BjpWHt/jNET1jH6CXJZOUVmjtEUY5JohZCiFLiZGfN0I5hLBvUhnahXhToFN+vPUz7r9awYMdJdHo5SyhKzqL7qEuD9FELIcxBKcXK5AxG/r2X1PM5gOEpXYGejlSv7ER1L+err4Z5D0cb6dN+gFSYPmohhCivNBoNURE+tAqpzE/rD/P92sNczivkYEYWBzOygHST+m4ONoakXdn56qshgQd5OmJvI8/KfpBJohZCiDJkb2NF/0dCeKNdTU5dvMLhs9kcOZPF4bPZHD6TzZGz2Zy8eIVLVwrYkXqRHakXTd6v0UAVdwfTI/DKzgR7OeHnai8PCnkASKIWQoj7wEqrIaCSIwGVHGl73fOxAa7k6zh6zpC4D5/J4sjZbA6dNcxfzi3kxIUrnLhwhXX7z5i8z95GS3BlZ8J8XXi8jh9tH/LC1lqGHlU0kqiFEMLMHGytCPdzJdzP1WS9Uopz2fmmCfxMNkfOZpF6PofcAj3JpzNJPp3J/B0n8XC04cl6/nRtWJV6Vd2kz7uCkEQthBAWSqPRUNnZjsrOdjQNNn28b6FOz/ELVzhyNouNB8/x585TnLmcxy+bjvHLpmNUr+xEt4ZV6NKgClU9HM30CURpkFHfQghRARTq9Gw4eJb5O06ybE8auQVFT/ZqGlyJ7g2r0LGOH672NmaMUlxTktwkiVoIISqYrLxCliSdZv6Ok2w6fI5r3/J21lqiInzo3rAKrUO8sLGS/mxzkcuzhBDiAeZsZ80zjQN4pnEApy5eYUHiSeZvP8mBjCwW7TrNol2n8XSypXM9f7o3rErtKq7Sn23B5IhaCCEeAEopdp/MZN6OE/y18xRns/KNZTW9nQ392fWr4O/uYMYoHxxy6vs6kqiFEMJUgU7P+gNnmLf9JHF708krNPRnazTQPNiTrg2r0LG2Ly7Sn11mJFFfRxK1EELcXmZuAUuSTjNv+0m2HDlvXG9vo+WxCF/qVnVDrxR6BTq9Qt1qXin0SqEU6PUK3bV5pdDpDXXUDfNarYZGQR60D/PG29XejC1gHpKoryOJWgghiuf4+Rz+TDzJvB0nOXwm+77tt15VN9qH+xAV7kO4n8sD0V8uifo6kqiFEKJklFLsOnGJhTtPcS4rD61Gg0ajwUrLTfNFE2i1183fat1181m5hazdf4adJy6Z7LuKuwPtw72JCvehWfVK2FlXzPucS6K+jiRqIYSwXBmZuazcl8HK5HQ2HDxrcv23k60VbUO9aB/mw8Nh3lRysjVjpKVLLs8SQghRLni72tOzaSA9mwZyJV9H/MGzrNyXzorkDM5czmNxUhqLk9LQajD0aV89RV7Dy+mBOEUOckQthBDCAun1iqSTl1iRbEjayaczTcqreToSFe5DVIQPjYM8sC5nN2+RU9/XkUQthBDl34kLOazal0Hc3nQ2Hz5Hga4odbk52PBwqBftw31oG+p1021SlVIU6BRX8nXkFBSSk6/jSr6OKwW6q/OGdbddX6Aj92p5YCVHxjxd994/j5z6FkIIUZFU9XDkhRbVeKFFNS7nFrD+wFlWJKezel8GF3IKWJB4igWJp7DWaqjh5UxeYVHizSnQodOXzjHphZz8f69UyiRRCyGEKFdc7G14vI4fj9fxQ6dXbE+9wIq96axITufQmWxS0i/f9r3WWg0OtlY42lrhaGuNvc21eSscrs472FpfN19Ubm9jRWVnu/v4Sa/GfN/3KIQQQpQSK62GJtUq0aRaJd5/PJwjZ7M5fj4Hh+sSr6OttXHZ1rp89WWDJGohhBAVSHBlJ4IrO5k7jFJV/n5aCCGEEA+QcpGov/vuO6pVq4a9vT3NmjVj69at5g5JCCGEuC8sPlHPmTOHwYMH88knn7B9+3bq1atHdHQ0GRkZ5g5NCCGEKHMWn6jHjx/PK6+8wosvvkhERARTpkzB0dGRn3/+2dyhCSGEEGXOohN1fn4+27ZtIyoqyrhOq9USFRXFpk2bzBiZEEIIcX9Y9Kjvs2fPotPp8PHxMVnv4+PDvn37bvmevLw88vLyjMuXLhmezHL69OmyC1QIIYQogWs5Sa/X/0tNC0/Ud2P06NGMGDHipvVNmzY1QzRCCCHE7aWnpxMYGHjHOhadqCtXroyVlRXp6ekm69PT0/H19b3le95//30GDx5sXC4sLCQ5OZmAgAC02ns703/58mUiIiLYu3cvLi4u97StB4W0WclJm5WctFnJSZuVXGm2mV6vJz09nQYNGvxrXYtO1La2tjRq1IiVK1fSpUsXwPDhVq5cSf/+/W/5Hjs7O+zsTG/xFhkZWSrxZGYant5SpUoVXF1dS2WbFZ20WclJm5WctFnJSZuVXGm32b8dSV9j0YkaYPDgwfTu3ZvGjRvTtGlTJkyYQHZ2Ni+++KK5QxNCCCHKnMUn6meffZYzZ84wbNgw0tLSqF+/PkuXLr1pgJkQQghREVl8ogbo37//bU913092dnZ88sknN51aF7cnbVZy0mYlJ21WctJmJWeuNtMopUrnIZ1CCCGEKHUWfcMTIYQQ4kEniVoIIYSwYJKohRBCCAsmiboE5HGbxTd69GiaNGmCi4sL3t7edOnShZSUFHOHVW588cUXaDQaBg0aZO5QLNrJkyf5v//7Pzw9PXFwcKBOnTr8888/5g7LYul0Oj7++GOCg4NxcHCgRo0afPrpp8hQJVPr1q2jc+fO+Pv7o9FoWLBggUm5Uophw4bh5+eHg4MDUVFRHDhwoMzikURdTPK4zZJZu3YtsbGxbN68mbi4OAoKCnjsscfIzs42d2gWLyEhge+//566deuaOxSLduHCBSIjI7GxsWHJkiXs3buXr776Cg8PD3OHZrHGjBnD5MmT+fbbb0lOTmbMmDGMHTuWSZMmmTs0i5KdnU29evX47rvvblk+duxYJk6cyJQpU9iyZQtOTk5ER0eTm5tbNgEpUSxNmzZVsbGxxmWdTqf8/f3V6NGjzRhV+ZGRkaEAtXbtWnOHYtEuX76sQkJCVFxcnGrbtq0aOHCguUOyWEOGDFGtWrUydxjlSqdOndRLL71ksq5bt24qJibGTBFZPkDNnz/fuKzX65Wvr6/68ssvjesuXryo7Ozs1KxZs8okBjmiLgZ53Oa9u/YUs0qVKpk5EssWGxtLp06dTP6viVtbuHAhjRs35plnnsHb25sGDRrw448/mjssi9ayZUtWrlzJ/v37Adi5cycbNmygY8eOZo6s/Dhy5AhpaWkmf6Nubm40a9aszPJBubjhibndzeM2RRG9Xs+gQYOIjIykdu3a5g7HYs2ePZvt27eTkJBg7lDKhcOHDzN58mQGDx7MBx98QEJCAgMGDMDW1pbevXubOzyLNHToUDIzMwkLC8PKygqdTseoUaOIiYkxd2jlRlpaGsAt88G1stImiVqUudjYWHbv3s2GDRvMHYrFOn78OAMHDiQuLg57e3tzh1Mu6PV6GjduzOeffw5AgwYN2L17N1OmTJFEfRu//fYbM2bMYObMmdSqVYvExEQGDRqEv7+/tJkFk1PfxXA3j9sUBv379+fvv/9m9erVVK1a1dzhWKxt27aRkZFBw4YNsba2xtramrVr1zJx4kSsra3R6XTmDtHi+Pn5ERERYbIuPDyc1NRUM0Vk+d59912GDh3Kc889R506dejVqxdvvfUWo0ePNndo5ca17/z7mQ8kURfD9Y/bvOba4zZbtGhhxsgsl1KK/v37M3/+fFatWkVwcLC5Q7Jo7du3JykpicTEROPUuHFjYmJiSExMxMrKytwhWpzIyMibLvnbv38/QUFBZorI8uXk5KDVmn7tW1lZodfrzRRR+RMcHIyvr69JPsjMzGTLli1llg/k1HcxyeM2SyY2NpaZM2fy559/4uLiYuy7cXNzw8HBwczRWR4XF5eb+u+dnJzw9PSUfv3beOutt2jZsiWff/45PXr0YOvWrfzwww/88MMP5g7NYnXu3JlRo0YRGBhIrVq12LFjB+PHj+ell14yd2gWJSsri4MHDxqXjxw5QmJiIpUqVSIwMJBBgwbx2WefERISQnBwMB9//DH+/v506dKlbAIqk7HkFdSkSZNUYGCgsrW1VU2bNlWbN282d0gWC7jlNHXqVHOHVm7I5Vn/7q+//lK1a9dWdnZ2KiwsTP3www/mDsmiZWZmqoEDB6rAwEBlb2+vqlevrj788EOVl5dn7tAsyurVq2/5/dW7d2+llOESrY8//lj5+PgoOzs71b59e5WSklJm8cjTs4QQQggLJn3UQgghhAWTRC2EEEJYMEnUQgghhAWTRC2EEEJYMEnUQgghhAWTRC2EEEJYMEnUQgghhAWTRC2EEEJYMEnUQohSp9FoWLBggbnDEKJCkEQtRAXTp08fNBrNTVOHDh3MHZoQ4i7IQzmEqIA6dOjA1KlTTdbZ2dmZKRohxL2QI2ohKiA7Ozt8fX1NJg8PD8BwWnry5Ml07NgRBwcHqlevzu+//27y/qSkJB555BEcHBzw9PTk1VdfJSsry6TOzz//TK1atbCzs8PPz4/+/fublJ89e5auXbvi6OhISEgICxcuNJZduHCBmJgYvLy8cHBwICQk5KYfFkIIA0nUQjyAPv74Y7p3787OnTuJiYnhueeeIzk5GYDs7Gyio6Px8PAgISGBuXPnsmLFCpNEPHnyZGJjY3n11VdJSkpi4cKF1KxZ02QfI0aMoEePHuzatYvHH3+cmJgYzp8/b9z/3r17WbJkCcnJyUyePJnKlSvfvwYQojwps+dyCSHMonfv3srKyko5OTmZTKNGjVJKGR5B+vrrr5u8p1mzZuqNN95QSin1ww8/KA8PD5WVlWUsX7RokdJqtSotLU0ppZS/v7/68MMPbxsDoD766CPjclZWlgLUkiVLlFJKde7cWb344oul84GFqOCkj1qICujhhx9m8uTJJusqVapknG/RooVJWYsWLUhMTAQgOTmZevXq4eTkZCyPjIxEr9eTkpKCRqPh1KlTtG/f/o4x1K1b1zjv5OSEq6srGRkZALzxxht0796d7du389hjj9GlSxdatmx5V59ViIpOErUQFZCTk9NNp6JLi4ODQ7Hq2djYmCxrNBr0ej0AHTt25NixYyxevJi4uDjat29PbGws48aNK/V4hSjvpI9aiAfQ5s2bb1oODw8HIDw8nJ07d5KdnW0sj4+PR6vVEhoaiouLC9WqVWPlypX3FIOXlxe9e/dm+vTpTJgwgR9++OGetidERSVH1EJUQHl5eaSlpZmss7a2Ng7Ymjt3Lo0bN6ZVq1bMmDGDrVu38t///heAmJgYPvnkE3r37s3w4cM5c+YMb775Jr169cLHxweA4cOH8/rrr+Pt7U3Hjh25fPky8fHxvPnmm8WKb9iwYTRq1IhatWqRl5fH33//bfyhIIQwJYlaiApo6dKl+Pn5mawLDQ1l3759gGFE9uzZs+nXrx9+fn7MmjWLiIgIABwdHVm2bBkDBw6kSZMmODo60r17d8aPH2/cVu/evcnNzeXrr7/mnXfeoXLlyjz99NPFjs/W1pb333+fo0eP4uDgQOvWrZk9e3YpfHIhKh6NUkqZOwghxP2j0WiYP38+Xbp0MXcoQohikD5qIYQQwoJJohZCCCEsmPRRC/GAkd4uIcoXOaIWQgghLJgkaiGEEMKCSaIWQgghLJgkaiGEEMKCSaIWQgghLJgkaiGEEMKCSaIWQgghLJgkaiGEEMKCSaIWQgghLNj/A7uWkdDdReerAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 Decoding strategies to control randomness"
      ],
      "metadata": {
        "id": "-1J-OtuqfFFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 将模型移动到CPU\n",
        "model.to(\"cpu\")\n",
        "\n",
        "# 设置模型为评估模式\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "2-6ZZyErfDQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1391a4e9-712b-4f5a-a983-1ef6881669f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 296
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 获取GPT-2分词器\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "# 生成文本\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        "    max_new_tokens=25,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "# 将生成的token ID解码为文本并打印\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "hPrI9Sg8fYZB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf6fc164-f8ff-4b74-c9cb-2da42383fbcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you?\"\n",
            "\n",
            "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3.1  Temperature scaling"
      ],
      "metadata": {
        "id": "LcjelCp9fpzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义词汇表\n",
        "vocab = {\n",
        "    \"closer\": 0,\n",
        "    \"every\": 1,\n",
        "    \"effort\": 2,\n",
        "    \"forward\": 3,\n",
        "    \"inches\": 4,\n",
        "    \"moves\": 5,\n",
        "    \"pizza\": 6,\n",
        "    \"toward\": 7,\n",
        "    \"you\": 8,\n",
        "}\n",
        "\n",
        "# 定义反向词汇表\n",
        "inverse_vocab = {v: k for k, v in vocab.items()}"
      ],
      "metadata": {
        "id": "Hxza83y7fh7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义下一个token的logits张量\n",
        "next_token_logits = torch.tensor([4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79])"
      ],
      "metadata": {
        "id": "S-S6FVhifvBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 将logits转换为概率分布\n",
        "probs = torch.softmax(next_token_logits, dim=0)\n",
        "\n",
        "# 选择概率最高的token的索引\n",
        "next_token_id = torch.argmax(probs).item()\n",
        "\n",
        "# 将token索引转换为单词并打印\n",
        "print(inverse_vocab[next_token_id])"
      ],
      "metadata": {
        "id": "7wMJzpe9f3Ra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47424315-fe6c-4bb3-dba8-795dbf56c55b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置随机种子，确保结果可复现\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 从概率分布中随机选择一个token\n",
        "next_token_id = torch.multinomial(probs, num_samples=1).item()\n",
        "\n",
        "# 将token索引转换为单词并打印\n",
        "print(inverse_vocab[next_token_id])"
      ],
      "metadata": {
        "id": "KcGjVxVlf_72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c88fb502-0ef7-4e43-86a5-71ce11177881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_sampled_tokens(probs):\n",
        "    # 设置随机种子，确保结果可复现\n",
        "    torch.manual_seed(123)\n",
        "\n",
        "    # 从概率分布中采样1000个token\n",
        "    sample = [torch.multinomial(probs, num_samples=1).item() for _ in range(1000)]\n",
        "\n",
        "    # 计算每个token的频率\n",
        "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
        "\n",
        "    # 打印每个token的频率和对应的单词\n",
        "    for i, freq in enumerate(sampled_ids):\n",
        "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
        "\n",
        "# 调用函数\n",
        "print_sampled_tokens(probs)"
      ],
      "metadata": {
        "id": "0BID4MPvgHs9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80610669-c9ea-49a7-baf1-b365dbf62dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71 x closer\n",
            "2 x every\n",
            "0 x effort\n",
            "544 x forward\n",
            "2 x inches\n",
            "1 x moves\n",
            "0 x pizza\n",
            "376 x toward\n",
            "4 x you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_with_temperature(logits, temperature):\n",
        "    # 对logits进行缩放\n",
        "    scaled_logits = logits / temperature\n",
        "    # 计算带温度参数的softmax概率分布\n",
        "    return torch.softmax(scaled_logits, dim=0)"
      ],
      "metadata": {
        "id": "y08QWUnghN3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义不同的温度参数，用于控制softmax的输出分布\n",
        "# 温度为1时接近原始分布，0.1时分布更集中（高置信度），5时分布更平坦（低置信度）\n",
        "temperatures = [1, 0.1, 5]\n",
        "\n",
        "# 对每个温度参数，使用带温度的softmax函数计算概率分布\n",
        "# scaled_probas将存储不同温度下的概率分布列表\n",
        "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
        "\n",
        "# 生成x轴的位置坐标，用于绘制柱状图\n",
        "# x的长度等于词汇表的大小，每个位置对应一个词汇\n",
        "x = torch.arange(len(vocab))\n",
        "\n",
        "# 定义柱状图的宽度，用于控制不同温度下柱状图的间距\n",
        "bar_width = 0.15\n",
        "\n",
        "# 创建一个图形和子图对象，设置图形大小为5x3英寸\n",
        "fig, ax = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "# 遍历每个温度参数及其索引\n",
        "for i, T in enumerate(temperatures):\n",
        "    # 绘制当前温度下的概率分布柱状图\n",
        "    # x + i * bar_width：计算每个温度下柱状图的x轴位置\n",
        "    # scaled_probas[i]：当前温度下的概率分布，作为柱状图的高度\n",
        "    # bar_width：柱状图的宽度\n",
        "    # label：为当前温度的柱状图添加图例标签\n",
        "    rects = ax.bar(\n",
        "        x + i * bar_width,\n",
        "        scaled_probas[i],\n",
        "        bar_width,\n",
        "        label=f\"Temperature = {T}\"\n",
        "    )\n",
        "\n",
        "# 设置y轴的标签为\"Probability\"，表示y轴显示的是概率值\n",
        "ax.set_ylabel('Probability')\n",
        "\n",
        "# 设置x轴的刻度位置，与x的长度对应\n",
        "ax.set_xticks(x)\n",
        "\n",
        "# 设置x轴的刻度标签为词汇表中的单词，旋转90度以避免重叠\n",
        "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
        "\n",
        "# 显示图例，解释不同颜色柱状图对应的温度参数\n",
        "ax.legend()\n",
        "\n",
        "# 自动调整子图布局，确保所有元素都能正确显示\n",
        "plt.tight_layout()\n",
        "\n",
        "# 显示绘制的图形\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yj4qDgR3hYiL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "4c929c77-e6fb-432b-8c57-690f88c125ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3.2  Top-k sampling"
      ],
      "metadata": {
        "id": "LIxnquCXiIsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义要获取的top token数量\n",
        "top_k = 3\n",
        "\n",
        "# 获取概率最高的前k个token的logits和位置\n",
        "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
        "\n",
        "# 打印概率最高的前k个token的logits\n",
        "print(\"Top logits:\", top_logits)\n",
        "\n",
        "# 打印概率最高的前k个token的位置\n",
        "print(\"Top positions:\", top_pos)"
      ],
      "metadata": {
        "id": "LClKsZB7hfXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e41c069-eea0-442e-8dec-adf388638b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
            "Top positions: tensor([3, 7, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用torch.where函数将低于top_logits[-1]的logits设置为-∞\n",
        "new_logits = torch.where(\n",
        "    # 条件：logits小于top_logits中的最小值\n",
        "    condition=next_token_logits < top_logits[-1],\n",
        "    # 满足条件时，设置为-∞\n",
        "    input=torch.tensor(float('-inf')),\n",
        "    # 不满足条件时，保留原logits\n",
        "    other=next_token_logits\n",
        ")\n",
        "\n",
        "# 打印处理后的logits\n",
        "print(new_logits)"
      ],
      "metadata": {
        "id": "Q2mWu7S4iQ7-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dab567aa-760a-4548-f6ba-1751b39e67e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 对处理后的logits应用softmax函数，生成概率分布\n",
        "topk_probas = torch.softmax(new_logits, dim=0)\n",
        "\n",
        "# 打印生成的概率分布\n",
        "print(topk_probas)"
      ],
      "metadata": {
        "id": "WM1Tgdf0iWj-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2407d893-721b-494b-bc9c-a1ae737f225c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3.3 Modifying the text generation function"
      ],
      "metadata": {
        "id": "LDiCrxfuid0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(\n",
        "    model, idx, max_new_tokens, context_size,\n",
        "    temperature=0.0, top_k=None, eos_id=None\n",
        "):\n",
        "    # 生成指定数量的新token\n",
        "    for _ in range(max_new_tokens):\n",
        "        # 截取最后context_size个token作为条件\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # 禁用梯度计算\n",
        "        with torch.no_grad():\n",
        "            # 获取模型的预测logits\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        # 只关注最后一个时间步的预测\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # 如果指定了top_k，应用top_k采样\n",
        "        if top_k is not None:\n",
        "            # 获取top_k的logits和位置\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            # 获取top_k中的最小值\n",
        "            min_val = top_logits[:, -1]\n",
        "            # 将低于最小值的logits设置为-∞\n",
        "            logits = torch.where(\n",
        "                logits < min_val[:, None],\n",
        "                torch.tensor(float('-inf')).to(logits.device),\n",
        "                logits\n",
        "            )\n",
        "\n",
        "        # 如果温度大于0，应用温度缩放\n",
        "        if temperature > 0.0:\n",
        "            # 对logits进行温度缩放\n",
        "            logits = logits / temperature\n",
        "            # 转换为概率分布\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            # 从概率分布中采样\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "        else:\n",
        "            # 否则，使用贪婪解码\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "\n",
        "        # 如果生成了结束token，提前停止生成\n",
        "        if idx_next == eos_id:\n",
        "            break\n",
        "\n",
        "        # 将新生成的token添加到序列中\n",
        "        idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "    # 返回生成的序列\n",
        "    return idx"
      ],
      "metadata": {
        "id": "J5zmS9hYibrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置随机种子，确保结果可复现\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 生成文本\n",
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
        "    top_k=25,\n",
        "    temperature=1.4\n",
        ")\n",
        "\n",
        "# 将生成的token ID解码为文本并打印\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "hBoeWg76iq96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a81d7035-fd07-46f4-8b92-50eea5f8d86d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you know I meant to a little wild--I was such struck by his last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.4  Loading and saving model weights in PyTorch"
      ],
      "metadata": {
        "id": "SuLwtl70iz8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")"
      ],
      "metadata": {
        "id": "zve4ktPGiwXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 初始化GPT模型\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "\n",
        "# 加载预训练的模型权重\n",
        "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
        "\n",
        "# 设置模型为评估模式\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "YZlHah7Ei463",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3cb03d3-6a55-478d-9ac5-2306e88dbb2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 311
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 保存模型和优化器的状态\n",
        "torch.save({\n",
        "    # 模型的状态字典\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    # 优化器的状态字典\n",
        "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "}, \"model_and_optimizer.pth\")"
      ],
      "metadata": {
        "id": "gAYoO1QZjQDM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "470d6146-1d5c-4f7e-ca28-d2c8e647d098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-355934333.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 保存模型和优化器的状态\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m torch.save({\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# 模型的状态字典\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"model_state_dict\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# 优化器的状态字典\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 加载保存的模型和优化器状态\n",
        "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
        "\n",
        "# 初始化GPT模型\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "\n",
        "# 加载模型的状态字典\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "# 初始化优化器\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
        "\n",
        "# 加载优化器的状态字典\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "\n",
        "# 设置模型为训练模式\n",
        "model.train()"
      ],
      "metadata": {
        "id": "3_-0ksQhjXBl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "836220bf-a7d2-4225-ebab-4b27de475c62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.5  Loading pretrained weights from OpenAI"
      ],
      "metadata": {
        "id": "d9R1GbYLj39T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow>=2.15.0  tqdm>=4.66"
      ],
      "metadata": {
        "id": "GpECNcYGj0hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 导入urllib.request模块，用于处理URL请求\n",
        "import urllib.request\n",
        "\n",
        "# 定义要下载的文件的URL\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/rasbt/\"\n",
        "    \"LLMs-from-scratch/main/ch05/\"\n",
        "    \"01_main-chapter-code/gpt_download.py\"\n",
        ")\n",
        "\n",
        "# 从URL中提取文件名\n",
        "filename = url.split('/')[-1]\n",
        "\n",
        "# 下载文件并保存到本地\n",
        "urllib.request.urlretrieve(url, filename)"
      ],
      "metadata": {
        "id": "HLSuakjjj-Bh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d5cea87-c65d-49f0-bc59-d9a2d0d512fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('gpt_download.py', <http.client.HTTPMessage at 0x79fe876fdd10>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 从gpt_download模块中导入download_and_load_gpt2函数\n",
        "from gpt_download import download_and_load_gpt2\n",
        "\n",
        "# 下载并加载GPT-2模型的设置和参数\n",
        "settings, params = download_and_load_gpt2(\n",
        "    model_size=\"124M\",  # 指定模型大小为124M\n",
        "    models_dir=\"gpt2\"    # 指定模型保存的目录为gpt2\n",
        ")"
      ],
      "metadata": {
        "id": "2sZ16r-ukFfi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6c55cb9-a50a-4dcd-d957-aa3f857b69e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 80.7kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 3.69MiB/s]\n",
            "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 111kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:34<00:00, 14.3MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 8.40MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 1.91MiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.89MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Settings:\", settings)\n",
        "print(\"Parameter dictionary keys:\", params.keys())"
      ],
      "metadata": {
        "id": "sSduHwxwkMBT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5648f4a7-d611-4f3b-ad06-047d81ceaebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
            "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(params[\"wte\"])\n",
        "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
      ],
      "metadata": {
        "id": "FuXMfndYkYJE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "865f8377-f05f-4467-fd64-6d307aef0d24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
            "   0.04531523]\n",
            " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
            "   0.04318958]\n",
            " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
            "  -0.08785918]\n",
            " ...\n",
            " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
            "  -0.06952604]\n",
            " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
            "  -0.02245961]\n",
            " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
            "   0.12067825]]\n",
            "Token embedding weight tensor dimensions: (50257, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_configs = {\n",
        "    # GPT-2 Small 模型配置\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    # GPT-2 Medium 模型配置\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    # GPT-2 Large 模型配置\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    # GPT-2 XL 模型配置\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}"
      ],
      "metadata": {
        "id": "c8q9wZ2ckffR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义模型名称\n",
        "model_name = \"gpt2-small (124M)\"\n",
        "\n",
        "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
        "\n",
        "# 更新新的配置字典，添加指定模型的配置信息\n",
        "NEW_CONFIG.update(model_configs[model_name])"
      ],
      "metadata": {
        "id": "ucTyGBLhkl7g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "5c65b084-4d2b-4fba-e8b9-00d71bafaaef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'GPT_CONFIG_124M' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2937646512.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gpt2-small (124M)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mNEW_CONFIG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT_CONFIG_124M\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 更新新的配置字典，添加指定模型的配置信息\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'GPT_CONFIG_124M' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NEW_CONFIG.update({\"context_length\": 1024})"
      ],
      "metadata": {
        "id": "FeReezFnkrrg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "7368b6d0-b978-47f4-b190-fef31c920aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'NEW_CONFIG' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3850528037.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNEW_CONFIG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"context_length\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'NEW_CONFIG' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NEW_CONFIG.update({\"qkv_bias\": True})"
      ],
      "metadata": {
        "id": "ULClUfcukueT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用新的配置创建 GPT 模型\n",
        "# NEW_CONFIG\n",
        "gpt = GPTModel(NEW_CONFIG)\n",
        "\n",
        "# 设置模型为评估模式\n",
        "gpt.eval()"
      ],
      "metadata": {
        "id": "bLcChPabkxOW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "efe9487e-14b7-4d47-9b92-f2b1b1fa1113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'GPTModel' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-775730301.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 使用新的配置创建 GPT 模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# NEW_CONFIG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPTModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNEW_CONFIG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 设置模型为评估模式\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'GPTModel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def assign(left, right):\n",
        "    # 检查左侧和右侧张量的形状是否一致\n",
        "    if left.shape != right.shape:\n",
        "        # 如果形状不一致，抛出 ValueError 异常\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "\n",
        "    # 将右侧张量转换为 Parameter 类型并返回\n",
        "    return torch.nn.Parameter(torch.tensor(right))"
      ],
      "metadata": {
        "id": "1Ip_-3c5k1IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    # 加载位置嵌入权重\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params[\"wpe\"])\n",
        "    # 加载词嵌入权重\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params[\"wte\"])\n",
        "\n",
        "    # 遍历每个 Transformer 块\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        # 分割注意力权重为查询、键和值三部分\n",
        "        q_w, k_w, v_w = np.split(params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"w\"], 3, axis=-1)\n",
        "        # 加载查询权重\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        # 加载键权重\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        # 加载值权重\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        # 分割注意力偏置为查询、键和值三部分\n",
        "        q_b, k_b, v_b = np.split(params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"b\"], 3, axis=-1)\n",
        "        # 加载查询偏置\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        # 加载键偏置\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        # 加载值偏置\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        # 加载输出投影权重\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        # 加载输出投影偏置\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        # 加载前馈网络第一层权重\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        # 加载前馈网络第一层偏置\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        # 加载前馈网络第二层权重\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        # 加载前馈网络第二层偏置\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        # 加载第一层归一化的缩放参数\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        # 加载第一层归一化的移位参数\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        # 加载第二层归一化的缩放参数\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        # 加载第二层归一化的移位参数\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    # 加载最终归一化的缩放参数\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    # 加载最终归一化的移位参数\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    # 加载输出头权重（权重绑定）\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
      ],
      "metadata": {
        "id": "SiuTqh6cmRwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_weights_into_gpt(gpt, params)\n",
        "gpt.to(device)"
      ],
      "metadata": {
        "id": "vopcdJzTmjMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee2dcbda-a0f1-4bfe-fb24-0adaaee0f1fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 326
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置随机种子，确保结果可复现\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 生成文本\n",
        "token_ids = generate(\n",
        "    model=gpt,  # 使用的模型\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),  # 输入文本的token ID\n",
        "    max_new_tokens=25,  # 生成的最大新token数\n",
        "    context_size=NEW_CONFIG[\"context_length\"],  # 上下文长度\n",
        "    top_k=50,  # top_k采样的k值\n",
        "    temperature=1.5  # 温度参数\n",
        ")\n",
        "\n",
        "# 将生成的token ID解码为文本并打印\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "32ldVU5Pml-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8167da29-976b-428a-f9a0-19e5a0997d25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you toward an equal share for each vote plus half. Inequality is often not an accurate representation of human worth; to know the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 Fine-tuning for classification"
      ],
      "metadata": {
        "id": "CprsxBJHnbYf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1  Different categories of fine-tuning"
      ],
      "metadata": {
        "id": "ANkYMYifLzwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2  Preparing the dataset"
      ],
      "metadata": {
        "id": "zLf1Up8EL31c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# 定义数据集的 URL 和路径\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
        "    # 检查数据文件是否已存在\n",
        "    if data_file_path.exists():\n",
        "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
        "        return\n",
        "\n",
        "    # 下载数据集\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        with open(zip_path, \"wb\") as out_file:\n",
        "            out_file.write(response.read())\n",
        "\n",
        "    # 解压数据集\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extracted_path)\n",
        "\n",
        "    # 重命名文件并添加 .tsv 扩展名\n",
        "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "    os.rename(original_file_path, data_file_path)\n",
        "\n",
        "    print(f\"File downloaded and saved as {data_file_path}\")\n",
        "\n",
        "# 调用函数下载并解压数据集\n",
        "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
      ],
      "metadata": {
        "id": "VvnPRJCsmxQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51a9b2e1-a88e-4596-e5b6-108dfa1b5ec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 读取数据集\n",
        "df = pd.read_csv(\n",
        "    data_file_path,  # 数据集文件路径\n",
        "    sep=\"\\t\",        # 分隔符为制表符\n",
        "    header=None,     # 文件没有表头\n",
        "    names=[\"Label\", \"Text\"]  # 指定列名\n",
        ")\n",
        "\n",
        "# 显示 DataFrame\n",
        "df"
      ],
      "metadata": {
        "id": "6BFtfmhyMFRO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "6d343332-c112-49c1-b567-824ee53bdf4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Label                                               Text\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham               Will ü b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e5129909-305d-433e-bbd8-7029ca81cc81\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5129909-305d-433e-bbd8-7029ca81cc81')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e5129909-305d-433e-bbd8-7029ca81cc81 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e5129909-305d-433e-bbd8-7029ca81cc81');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6a38b60c-9398-40b9-be39-7c389fbb5d35\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6a38b60c-9398-40b9-be39-7c389fbb5d35')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6a38b60c-9398-40b9-be39-7c389fbb5d35 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_65604e0a-26bb-47ce-9d82-83a613ba14d5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_65604e0a-26bb-47ce-9d82-83a613ba14d5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 329
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "id": "W9Km1CGDMOfh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7aafa91-4192-43eb-e20c-fd08086b7be2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_balanced_dataset(df):\n",
        "    # 计算 \"spam\" 类别的样本数量\n",
        "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
        "\n",
        "    # 随机采样 \"ham\" 类别的样本，数量与 \"spam\" 类别相同\n",
        "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(\n",
        "        num_spam,  # 采样数量\n",
        "        random_state=123  # 随机种子，确保结果可复现\n",
        "    )\n",
        "\n",
        "    # 合并采样后的 \"ham\" 子集和 \"spam\" 类别\n",
        "    balanced_df = pd.concat([\n",
        "        ham_subset,  # 采样后的 \"ham\" 子集\n",
        "        df[df[\"Label\"] == \"spam\"]  # \"spam\" 类别\n",
        "    ])\n",
        "\n",
        "    # 返回平衡的数据集\n",
        "    return balanced_df\n",
        "\n",
        "# 创建平衡的数据集\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "\n",
        "# 打印每个类别的样本数量\n",
        "print(balanced_df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "id": "sSLLGqgYMR9K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc5ace43-ae69-44e6-d306-49e99252a83c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     747\n",
            "spam    747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 将 \"Label\" 列中的类别标签映射为数字\n",
        "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
      ],
      "metadata": {
        "id": "i_Gbt5FoMY01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_split(df, train_frac, validation_frac):\n",
        "    # 打乱数据集\n",
        "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "\n",
        "    # 计算分割索引\n",
        "    train_end = int(len(df) * train_frac)\n",
        "    validation_end = train_end + int(len(df) * validation_frac)\n",
        "\n",
        "    # 分割数据集\n",
        "    train_df = df[:train_end]\n",
        "    validation_df = df[train_end:validation_end]\n",
        "    test_df = df[validation_end:]\n",
        "\n",
        "    # 返回分割后的数据集\n",
        "    return train_df, validation_df, test_df\n",
        "\n",
        "# 分割数据集\n",
        "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)"
      ],
      "metadata": {
        "id": "M1w6CG-WMh_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 将训练集保存为 CSV 文件\n",
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "\n",
        "# 将验证集保存为 CSV 文件\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "\n",
        "# 将测试集保存为 CSV 文件\n",
        "test_df.to_csv(\"test.csv\", index=None)"
      ],
      "metadata": {
        "id": "BOGSa5Z9MotG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.3  Creating data loaders"
      ],
      "metadata": {
        "id": "cOuHFzsxMvKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "# 获取 GPT-2 的分词器\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "# 编码特殊文本 `<|endoftext|>`\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ],
      "metadata": {
        "id": "pzeQw2RcMuHS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e593649-2592-4a38-8568-7eb370713683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SpamDataset(Dataset):\n",
        "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
        "        # 读取 CSV 文件\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "\n",
        "        # 编码文本\n",
        "        self.encoded_texts = [\n",
        "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
        "        ]\n",
        "\n",
        "        # 确定最大长度\n",
        "        if max_length is None:\n",
        "            self.max_length = self._longest_encoded_length()\n",
        "        else:\n",
        "            self.max_length = max_length\n",
        "\n",
        "        # 截断和填充文本\n",
        "        self.encoded_texts = [\n",
        "            encoded_text[:self.max_length]\n",
        "            for encoded_text in self.encoded_texts\n",
        "        ]\n",
        "        self.encoded_texts = [\n",
        "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
        "            for encoded_text in self.encoded_texts\n",
        "        ]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # 获取编码后的文本和标签\n",
        "        encoded = self.encoded_texts[index]\n",
        "        label = self.data.iloc[index][\"Label\"]\n",
        "        return (\n",
        "            torch.tensor(encoded, dtype=torch.long),\n",
        "            torch.tensor(label, dtype=torch.long)\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        # 返回数据集的大小\n",
        "        return len(self.data)\n",
        "\n",
        "    def _longest_encoded_length(self):\n",
        "        # 计算最长编码文本的长度\n",
        "        max_length = 0\n",
        "        for encoded_text in self.encoded_texts:\n",
        "            encoded_length = len(encoded_text)\n",
        "            if encoded_length > max_length:\n",
        "                max_length = encoded_length\n",
        "        return max_length"
      ],
      "metadata": {
        "id": "6oIjSfy5M2tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SpamDataset(\n",
        "    csv_file=\"train.csv\",  # 训练集 CSV 文件路径\n",
        "    max_length=None,       # 最大长度（None 表示自动计算）\n",
        "    tokenizer=tokenizer    # 分词器\n",
        ")"
      ],
      "metadata": {
        "id": "f-NVHCvtNBS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset.max_length)"
      ],
      "metadata": {
        "id": "wzEkt2HCNIrs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "661f6aa7-71b6-4fe0-e02a-a7fd25bfb23d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建验证集数据集\n",
        "val_dataset = SpamDataset(\n",
        "    csv_file=\"validation.csv\",  # 验证集 CSV 文件路径\n",
        "    max_length=train_dataset.max_length,  # 最大长度与训练集一致\n",
        "    tokenizer=tokenizer  # 分词器\n",
        ")\n",
        "\n",
        "# 创建测试集数据集\n",
        "test_dataset = SpamDataset(\n",
        "    csv_file=\"test.csv\",  # 测试集 CSV 文件路径\n",
        "    max_length=train_dataset.max_length,  # 最大长度与训练集一致\n",
        "    tokenizer=tokenizer  # 分词器\n",
        ")"
      ],
      "metadata": {
        "id": "joko52grNK5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 设置参数\n",
        "num_workers = 0  # 工作进程数，0 表示不使用多进程\n",
        "batch_size = 8  # 批大小\n",
        "torch.manual_seed(123)  # 设置随机种子，确保结果可复现\n",
        "\n",
        "# 创建训练集数据加载器\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,  # 训练集数据集\n",
        "    batch_size=batch_size,  # 批大小\n",
        "    shuffle=True,  # 打乱数据\n",
        "    num_workers=num_workers,  # 工作进程数\n",
        "    drop_last=True  # 丢弃最后一个不完整的批次\n",
        ")\n",
        "\n",
        "# 创建验证集数据加载器\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,  # 验证集数据集\n",
        "    batch_size=batch_size,  # 批大小\n",
        "    num_workers=num_workers,  # 工作进程数\n",
        "    drop_last=False  # 不丢弃最后一个不完整的批次\n",
        ")\n",
        "\n",
        "# 创建测试集数据加载器\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,  # 测试集数据集\n",
        "    batch_size=batch_size,  # 批大小\n",
        "    num_workers=num_workers,  # 工作进程数\n",
        "    drop_last=False  # 不丢弃最后一个不完整的批次\n",
        ")"
      ],
      "metadata": {
        "id": "oTdnmz92NR1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 遍历训练集数据加载器\n",
        "for input_batch, target_batch in train_loader:\n",
        "    pass  # 占位符，实际代码中可以处理批次数据\n",
        "\n",
        "# 打印输入批次的维度\n",
        "print(\"Input batch dimensions:\", input_batch.shape)\n",
        "\n",
        "# 打印标签批次的维度\n",
        "print(\"Label batch dimensions\", target_batch.shape)"
      ],
      "metadata": {
        "id": "A9otRapsNZKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afe1bcf8-4ea3-4eb1-f778-ca579881b2ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch dimensions: torch.Size([8, 120])\n",
            "Label batch dimensions torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 打印训练集的批次数量\n",
        "print(f\"{len(train_loader)} training batches\")\n",
        "\n",
        "# 打印验证集的批次数量\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "\n",
        "# 打印测试集的批次数量\n",
        "print(f\"{len(test_loader)} test batches\")"
      ],
      "metadata": {
        "id": "J7HrmhujNeaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee99c311-5b28-4d96-8d3b-9606934c576b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130 training batches\n",
            "19 validation batches\n",
            "38 test batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.4  Initializing a model with pretrained weights"
      ],
      "metadata": {
        "id": "gJA0f_egNnGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 选择的模型\n",
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "# 输入提示\n",
        "INPUT_PROMPT = \"Every effort moves\"\n",
        "\n",
        "# 基础配置\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,  # 词汇表大小\n",
        "    \"context_length\": 1024,  # 上下文长度\n",
        "    \"drop_rate\": 0.0,  # Dropout 率\n",
        "    \"qkv_bias\": True  # 查询-键-值偏置\n",
        "}\n",
        "\n",
        "# 模型配置\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "# 更新基础配置\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
      ],
      "metadata": {
        "id": "lFBTSxjBNl4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 从自定义模块导入函数\n",
        "from gpt_download import download_and_load_gpt2\n",
        "# from chapter05 import GPTModel, load_weights_into_gpt\n",
        "\n",
        "# 解析模型大小\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "\n",
        "# 下载并加载 GPT-2 模型\n",
        "settings, params = download_and_load_gpt2(\n",
        "  model_size=model_size, models_dir=\"gpt2\"\n",
        ")\n",
        "\n",
        "# 初始化模型\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "\n",
        "# 加载权重\n",
        "load_weights_into_gpt(model, params)\n",
        "\n",
        "# 设置模型为评估模式\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "cdRYlg7GNw0M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "abd09ef3-8d02-4860-bc34-cf1f6915a807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 73.8kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 3.33MiB/s]\n",
            "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 102kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:27<00:00, 18.1MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 8.20MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 1.95MiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.90MiB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'GPTModel' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2096767329.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 初始化模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPTModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_CONFIG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# 加载权重\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'GPTModel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 从自定义模块导入函数\n",
        "# from chapter04 import generate_text_simple\n",
        "# from chapter05 import text_to_token_ids, token_ids_to_text\n",
        "\n",
        "# 输入文本\n",
        "text_1 = \"Every effort moves you\"\n",
        "\n",
        "# 生成文本\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,  # 使用的模型\n",
        "    idx=text_to_token_ids(text_1, tokenizer),  # 输入文本的 token ID\n",
        "    max_new_tokens=15,  # 生成的最大新 token 数\n",
        "    context_size=BASE_CONFIG[\"context_length\"]  # 上下文长度\n",
        ")\n",
        "\n",
        "# 将生成的 token ID 解码为文本并打印\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "a-w4Xtq0N4i1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 输入文本\n",
        "text_2 = (\n",
        "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\\n\"\n",
        "    \"You are a winner you have been specially selected to receive $1000 cash or a $2000 award.\"\n",
        ")\n",
        "\n",
        "# 生成文本\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,  # 使用的模型\n",
        "    idx=text_to_token_ids(text_2, tokenizer),  # 输入文本的 token ID\n",
        "    max_new_tokens=23,  # 生成的最大新 token 数\n",
        "    context_size=BASE_CONFIG[\"context_length\"]  # 上下文长度\n",
        ")\n",
        "\n",
        "# 将生成的 token ID 解码为文本并打印\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "fg6eA-P1ZgPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.5 Adding a classification head"
      ],
      "metadata": {
        "id": "hru2311ofnjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "FzGufsZ4cnvS",
        "outputId": "083976b6-8c3d-4dbd-df40-2459558b25f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2474145594.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 冻结模型的所有参数\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "OnitUl0Fft3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置随机种子\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 分类类别数量\n",
        "num_classes = 2\n",
        "\n",
        "# 添加输出层\n",
        "model.out_head = torch.nn.Linear(\n",
        "    in_features=BASE_CONFIG[\"emb_dim\"],  # 输入特征维度（嵌入维度）\n",
        "    out_features=num_classes  # 输出特征维度（类别数量）\n",
        ")"
      ],
      "metadata": {
        "id": "T4Z433vCiTsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 解冻最后一个 Transformer 块的参数\n",
        "for param in model.trf_blocks[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# 解冻最终归一化层的参数\n",
        "for param in model.final_norm.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "0yBScm7mlQ-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 编码输入文本\n",
        "inputs = tokenizer.encode(\"Do you have time\")\n",
        "\n",
        "# 转换为 PyTorch 张量，并添加批次维度\n",
        "inputs = torch.tensor(inputs).unsqueeze(0)\n",
        "\n",
        "# 打印输入的形状\n",
        "print(\"Inputs:\", inputs)\n",
        "print(\"Inputs dimensions:\", inputs.shape)"
      ],
      "metadata": {
        "id": "vDe1lDhVn-8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 在不计算梯度的上下文中进行推理\n",
        "with torch.no_grad():\n",
        "    outputs = model(inputs)  # 使用模型进行推理\n",
        "\n",
        "# 打印输出结果和维度\n",
        "print(\"Outputs:\", outputs)\n",
        "print(\"Outputs dimensions:\", outputs.shape)"
      ],
      "metadata": {
        "id": "W4C-4K4ioEX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Last output token:\", outputs[:, -1, :])"
      ],
      "metadata": {
        "id": "KUU5goVRoMoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  6.6 Calculating the classification loss and accuracy"
      ],
      "metadata": {
        "id": "zAiHnCawoRT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Last output token:\", outputs[:, -1, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "8RKQw6mgoQuJ",
        "outputId": "7eb06862-8fd8-4e32-920e-89cf6266c1ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'outputs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4015562627.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Last output token:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 提取最后一个时间步的输出，并应用 softmax 函数\n",
        "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
        "\n",
        "# 预测类别标签\n",
        "label = torch.argmax(probas).item()\n",
        "\n",
        "# 打印类别标签\n",
        "print(\"Class label:\", label)"
      ],
      "metadata": {
        "id": "tD1QhrcErS3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 提取最后一个时间步的 logits\n",
        "logits = outputs[:, -1, :]\n",
        "\n",
        "# 预测类别标签\n",
        "label = torch.argmax(logits)\n",
        "\n",
        "# 打印类别标签\n",
        "print(\"Class label:\", label.item())"
      ],
      "metadata": {
        "id": "mGsrDlyfrZig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
        "    # 设置模型为评估模式\n",
        "    model.eval()\n",
        "    correct_predictions, num_examples = 0, 0\n",
        "\n",
        "    # 确定要处理的批次数量\n",
        "    if num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "    # 遍历数据加载器\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            # 将输入和目标张量移动到指定设备\n",
        "            input_batch = input_batch.to(device)\n",
        "            target_batch = target_batch.to(device)\n",
        "\n",
        "            # 在不计算梯度的上下文中进行推理\n",
        "            with torch.no_grad():\n",
        "                # 获取模型输出\n",
        "                logits = model(input_batch)[:, -1, :]\n",
        "                # 预测类别标签\n",
        "                predicted_labels = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            # 更新统计信息\n",
        "            num_examples += predicted_labels.shape[0]\n",
        "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # 返回准确率\n",
        "    return correct_predictions / num_examples"
      ],
      "metadata": {
        "id": "Ds-Vqltyrd7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 确定设备（GPU 或 CPU）\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 将模型移动到指定设备\n",
        "model.to(device)\n",
        "\n",
        "# 设置随机种子\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 计算训练集准确率\n",
        "train_accuracy = calc_accuracy_loader(\n",
        "    train_loader, model, device, num_batches=10\n",
        ")\n",
        "\n",
        "# 计算验证集准确率\n",
        "val_accuracy = calc_accuracy_loader(\n",
        "    val_loader, model, device, num_batches=10\n",
        ")\n",
        "\n",
        "# 计算测试集准确率\n",
        "test_accuracy = calc_accuracy_loader(\n",
        "    test_loader, model, device, num_batches=10\n",
        ")\n",
        "\n",
        "# 打印准确率\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "id": "skh47G7grkr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    # 将输入和目标张量移动到指定设备\n",
        "    input_batch = input_batch.to(device)\n",
        "    target_batch = target_batch.to(device)\n",
        "\n",
        "    # 获取模型输出\n",
        "    logits = model(input_batch)[:, -1, :]\n",
        "\n",
        "    # 计算交叉熵损失\n",
        "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
        "\n",
        "    # 返回损失\n",
        "    return loss"
      ],
      "metadata": {
        "id": "dqtaV5ICrqbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    # 初始化总损失\n",
        "    total_loss = 0\n",
        "\n",
        "    # 处理空数据加载器\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "\n",
        "    # 确定要处理的批次数量\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "    # 遍历数据加载器\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            # 计算一个批次的损失\n",
        "            loss = calc_loss_batch(\n",
        "                input_batch, target_batch, model, device\n",
        "            )\n",
        "            # 累加损失\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # 返回平均损失\n",
        "    return total_loss / num_batches"
      ],
      "metadata": {
        "id": "6206QxBWrxDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 在不计算梯度的上下文中计算损失\n",
        "with torch.no_grad():\n",
        "    # 计算训练集损失\n",
        "    train_loss = calc_loss_loader(\n",
        "        train_loader, model, device, num_batches=5\n",
        "    )\n",
        "\n",
        "    # 计算验证集损失\n",
        "    val_loss = calc_loss_loader(\n",
        "        val_loader, model, device, num_batches=5\n",
        "    )\n",
        "\n",
        "    # 计算测试集损失\n",
        "    test_loss = calc_loss_loader(\n",
        "        test_loader, model, device, num_batches=5\n",
        "    )\n",
        "\n",
        "# 打印损失\n",
        "print(f\"Training loss: {train_loss:.3f}\")\n",
        "print(f\"Validation loss: {val_loss:.3f}\")\n",
        "print(f\"Test loss: {test_loss:.3f}\")"
      ],
      "metadata": {
        "id": "eS1nFKo1r5ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  6.7 Fine-tuning the model on supervised data"
      ],
      "metadata": {
        "id": "_ClAxqDRr_5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifier_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs, eval_freq, eval_iter\n",
        "):\n",
        "    # 初始化统计信息列表\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    examples_seen, global_step = 0, -1\n",
        "\n",
        "    # 主训练循环\n",
        "    for epoch in range(num_epochs):\n",
        "        # 设置模型为训练模式\n",
        "        model.train()\n",
        "\n",
        "        # 遍历训练集\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            # 重置梯度\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 计算损失\n",
        "            loss = calc_loss_batch(\n",
        "                input_batch, target_batch, model, device\n",
        "            )\n",
        "\n",
        "            # 反向传播\n",
        "            loss.backward()\n",
        "\n",
        "            # 更新参数\n",
        "            optimizer.step()\n",
        "\n",
        "            # 更新统计信息\n",
        "            examples_seen += input_batch.shape[0]\n",
        "            global_step += 1\n",
        "\n",
        "            # 评估模型\n",
        "            if global_step % eval_freq == 0:\n",
        "                # 计算训练集和验证集损失\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter\n",
        "                )\n",
        "\n",
        "                # 记录损失\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "\n",
        "                # 打印损失\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, \"\n",
        "                      f\"Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # 计算准确率\n",
        "        train_accuracy = calc_accuracy_loader(\n",
        "            train_loader, model, device, num_batches=eval_iter\n",
        "        )\n",
        "        val_accuracy = calc_accuracy_loader(\n",
        "            val_loader, model, device, num_batches=eval_iter\n",
        "        )\n",
        "\n",
        "        # 打印准确率\n",
        "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "\n",
        "        # 记录准确率\n",
        "        train_accs.append(train_accuracy)\n",
        "        val_accs.append(val_accuracy)\n",
        "\n",
        "    # 返回统计信息\n",
        "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
      ],
      "metadata": {
        "id": "YJ2asc1ur-7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    # 设置模型为评估模式\n",
        "    model.eval()\n",
        "\n",
        "    # 在不计算梯度的上下文中进行评估\n",
        "    with torch.no_grad():\n",
        "        # 计算训练集损失\n",
        "        train_loss = calc_loss_loader(\n",
        "            train_loader, model, device, num_batches=eval_iter\n",
        "        )\n",
        "\n",
        "        # 计算验证集损失\n",
        "        val_loss = calc_loss_loader(\n",
        "            val_loader, model, device, num_batches=eval_iter\n",
        "        )\n",
        "\n",
        "    # 设置模型为训练模式\n",
        "    model.train()\n",
        "\n",
        "    # 返回损失\n",
        "    return train_loss, val_loss"
      ],
      "metadata": {
        "id": "-mliG3DAsJcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# 记录开始时间\n",
        "start_time = time.time()\n",
        "\n",
        "# 设置随机种子\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# 初始化优化器\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "\n",
        "# 训练轮数\n",
        "num_epochs = 5\n",
        "\n",
        "# 训练模型\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = \\\n",
        "    train_classifier_simple(\n",
        "        model, train_loader, val_loader, optimizer, device,\n",
        "        num_epochs=num_epochs, eval_freq=50,\n",
        "        eval_iter=5\n",
        "    )\n",
        "\n",
        "# 记录结束时间\n",
        "end_time = time.time()\n",
        "\n",
        "# 计算训练时间（分钟）\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "\n",
        "# 打印训练时间\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ],
      "metadata": {
        "id": "2ZtpfFzesRDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 导入绘图库\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# 定义绘图函数\n",
        "def plot_values(\n",
        "    epochs_seen, examples_seen, train_values, val_values,\n",
        "    label=\"loss\"\n",
        "):\n",
        "    # 创建绘图窗口和子图\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # 绘制训练和验证曲线\n",
        "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "    ax1.plot(\n",
        "        epochs_seen, val_values, linestyle=\"--\",\n",
        "        label=f\"Validation {label}\"\n",
        "    )\n",
        "\n",
        "    # 设置坐标轴标签和图例\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(label.capitalize())\n",
        "    ax1.legend()\n",
        "\n",
        "    # 创建第二个x轴\n",
        "    ax2 = ax1.twiny()\n",
        "    ax2.plot(examples_seen, train_values, alpha=0)\n",
        "    ax2.set_xlabel(\"Examples seen\")\n",
        "\n",
        "    # 调整布局并保存显示图表\n",
        "    fig.tight_layout()\n",
        "    plt.savefig(f\"{label}-plot.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "# 生成数据并调用绘图函数\n",
        "# 假设 num_epochs 和 examples_seen 已定义，train_losses 和 val_losses 包含损失值数据\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
      ],
      "metadata": {
        "id": "O0HIFFDIsYcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 生成准确率的 epochs 和 examples seen 张量\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
        "\n",
        "# 绘制准确率曲线\n",
        "plot_values(\n",
        "    epochs_tensor, examples_seen_tensor, train_accs, val_accs,\n",
        "    label=\"accuracy\"\n",
        ")"
      ],
      "metadata": {
        "id": "2rDYb-3gs5JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算训练集准确率\n",
        "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
        "\n",
        "# 计算验证集准确率\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
        "\n",
        "# 计算测试集准确率\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
        "\n",
        "# 打印准确率\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "id": "sb_qeB2-tAIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.8 Using the LLM as a spam classifier"
      ],
      "metadata": {
        "id": "zngBXtrutGfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_review(\n",
        "    text, model, tokenizer, device, max_length=None,\n",
        "    pad_token_id=50256\n",
        "):\n",
        "    # 设置模型为评估模式\n",
        "    model.eval()\n",
        "\n",
        "    # 编码输入文本\n",
        "    input_ids = tokenizer.encode(text)\n",
        "\n",
        "    # 获取模型支持的上下文长度\n",
        "    supported_context_length = model.pos_emb.weight.shape[1]\n",
        "\n",
        "    # 截断输入序列（如果过长）\n",
        "    if max_length is not None:\n",
        "        input_ids = input_ids[:min(max_length, supported_context_length)]\n",
        "    else:\n",
        "        input_ids = input_ids[:supported_context_length]\n",
        "\n",
        "    # 填充输入序列\n",
        "    if max_length is not None:\n",
        "        input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
        "\n",
        "    # 转换为张量并添加批次维度\n",
        "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0)\n",
        "\n",
        "    # 在不计算梯度的上下文中进行推理\n",
        "    with torch.no_grad():\n",
        "        # 获取模型输出\n",
        "        logits = model(input_tensor)[:, -1, :]\n",
        "        # 预测类别标签\n",
        "        predicted_label = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "    # 返回分类结果\n",
        "    return \"spam\" if predicted_label == 1 else \"not spam\""
      ],
      "metadata": {
        "id": "kf3WSk81tGBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义输入文本\n",
        "text_1 = (\n",
        "    \"You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.\"\n",
        ")\n",
        "\n",
        "# 对输入文本进行分类并打印结果\n",
        "print(classify_review(\n",
        "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "id": "zbT1yY7FtQKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义输入文本\n",
        "text_2 = (\n",
        "    \"Hey, just wanted to check if we're still on\"\n",
        "    \" for dinner tonight? Let me know!\"\n",
        ")\n",
        "\n",
        "# 对输入文本进行分类并打印结果\n",
        "print(classify_review(\n",
        "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "id": "_QAmLee5tVF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 保存模型的状态字典\n",
        "torch.save(model.state_dict(), \"review_classifier.pth\")"
      ],
      "metadata": {
        "id": "gllwLV2NtaSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 加载模型的状态字典\n",
        "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device)\n",
        "\n",
        "# 将状态字典加载到模型中\n",
        "model.load_state_dict(model_state_dict)"
      ],
      "metadata": {
        "id": "xYgHYLEhthGg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}